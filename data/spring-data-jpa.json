{
  "topic": "Spring Data JPA",
  "questions": [
    {
      "id": 1,
      "question": "What is Spring Data JPA and why is it used?",
      "answer": "Spring Data JPA is part of the Spring Data family that simplifies data access layer implementation.\n\nKey features:\n• Repository abstraction\n• Query derivation from method names\n• Custom queries with @Query\n• Pagination and sorting\n• Auditing support\n• Specifications for dynamic queries\n• Reduces boilerplate code",
      "explanation": "Spring Data JPA builds on top of JPA (Hibernate) to provide a simplified data access layer with minimal code.",
      "difficulty": "Easy"
    },
    {
      "id": 2,
      "question": "What is the difference between JPA, Hibernate, and Spring Data JPA?",
      "answer": "JPA (Java Persistence API):\n• Specification/Standard\n• Defines interfaces and annotations\n• Not an implementation\n\nHibernate:\n• JPA implementation\n• ORM framework\n• Provides actual functionality\n\nSpring Data JPA:\n• Repository abstraction layer\n• Built on top of JPA\n• Simplifies data access code",
      "explanation": "JPA is the specification, Hibernate is the implementation, Spring Data JPA is the abstraction layer that simplifies usage.",
      "difficulty": "Easy",
      "code": "// JPA Entity\n@Entity\npublic class User { }\n\n// Hibernate is the provider\n// Spring Data JPA Repository\npublic interface UserRepository extends JpaRepository<User, Long> { }"
    },
    {
      "id": 3,
      "question": "What are the main repository interfaces in Spring Data JPA?",
      "answer": "Repository hierarchy:\n\n1. Repository<T, ID> - Marker interface\n2. CrudRepository<T, ID> - CRUD operations\n3. PagingAndSortingRepository<T, ID> - Pagination/sorting\n4. JpaRepository<T, ID> - JPA specific (most used)\n\nMethods count:\n• CrudRepository: ~12 methods\n• JpaRepository: ~18 methods + batch operations",
      "explanation": "Each interface extends the previous one, adding more functionality. JpaRepository is typically used as it provides all features.",
      "difficulty": "Easy",
      "code": "public interface UserRepository extends JpaRepository<User, Long> {\n    // Inherits:\n    // save(), findById(), findAll(), delete()\n    // saveAll(), flush(), deleteInBatch()\n    // etc.\n}"
    },
    {
      "id": 4,
      "question": "How do query derivation methods work in Spring Data JPA?",
      "answer": "Query methods are derived from method names:\n\nKeyword patterns:\n• findBy, getBy, queryBy, readBy\n• countBy, existsBy, deleteBy\n• And, Or\n• Between, LessThan, GreaterThan\n• Like, Containing, StartingWith\n• OrderBy, Top, First\n\nSpring Data parses method name and generates query automatically.",
      "explanation": "Method names follow specific patterns that Spring Data JPA translates into JPQL queries at runtime.",
      "difficulty": "Medium",
      "code": "public interface UserRepository extends JpaRepository<User, Long> {\n    // SELECT * FROM user WHERE email = ?\n    User findByEmail(String email);\n    \n    // SELECT * FROM user WHERE name = ? AND age = ?\n    List<User> findByNameAndAge(String name, int age);\n    \n    // SELECT * FROM user WHERE age > ?\n    List<User> findByAgeGreaterThan(int age);\n    \n    // SELECT * FROM user WHERE email LIKE %?%\n    List<User> findByEmailContaining(String email);\n    \n    // SELECT * FROM user ORDER BY name LIMIT 10\n    List<User> findTop10ByOrderByNameAsc();\n    \n    // SELECT COUNT(*) FROM user WHERE status = ?\n    long countByStatus(String status);\n    \n    // DELETE FROM user WHERE age < ?\n    void deleteByAgeLessThan(int age);\n}"
    },
    {
      "id": 5,
      "question": "How do you write custom queries using @Query annotation?",
      "answer": "@Query annotation for custom JPQL/SQL:\n\nFeatures:\n• JPQL queries (entity-based)\n• Native SQL queries\n• Named parameters\n• Positional parameters\n• Modifying queries\n• Projections\n\nUse when method names are too long or complex logic needed.",
      "explanation": "@Query provides flexibility for complex queries that can't be expressed through method names.",
      "difficulty": "Medium",
      "code": "public interface UserRepository extends JpaRepository<User, Long> {\n    // JPQL with named parameter\n    @Query(\"SELECT u FROM User u WHERE u.email = :email\")\n    User findByEmailAddress(@Param(\"email\") String email);\n    \n    // JPQL with positional parameter\n    @Query(\"SELECT u FROM User u WHERE u.age > ?1\")\n    List<User> findUsersOlderThan(int age);\n    \n    // Native SQL\n    @Query(value = \"SELECT * FROM users WHERE status = ?1\", \n           nativeQuery = true)\n    List<User> findByStatusNative(String status);\n    \n    // Modifying query\n    @Modifying\n    @Transactional\n    @Query(\"UPDATE User u SET u.status = :status WHERE u.id = :id\")\n    int updateUserStatus(@Param(\"id\") Long id, \n                        @Param(\"status\") String status);\n    \n    // DELETE query\n    @Modifying\n    @Query(\"DELETE FROM User u WHERE u.createdDate < :date\")\n    void deleteOldUsers(@Param(\"date\") LocalDate date);\n}"
    },
    {
      "id": 6,
      "question": "What are the different fetch types in JPA (LAZY vs EAGER)?",
      "answer": "Fetch types control when associated entities are loaded:\n\nLAZY (default for collections):\n• Loads data only when accessed\n• Improves performance\n• Can cause LazyInitializationException\n• Use for large collections\n\nEAGER (default for @ManyToOne, @OneToOne):\n• Loads data immediately with parent\n• Can cause performance issues\n• No LazyInitializationException\n• Use for small, frequently accessed data",
      "explanation": "LAZY is generally preferred for better performance, but requires active session. EAGER is simpler but can load too much data.",
      "difficulty": "Medium",
      "code": "@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    // EAGER - loaded immediately\n    @ManyToOne(fetch = FetchType.EAGER)\n    private Department department;\n    \n    // LAZY - loaded when accessed\n    @OneToMany(mappedBy = \"user\", fetch = FetchType.LAZY)\n    private List<Order> orders;\n}\n\n// Usage\nUser user = userRepository.findById(1L).get();\nSystem.out.println(user.getDepartment().getName()); // Already loaded\nSystem.out.println(user.getOrders().size()); // Triggers query if session active"
    },
    {
      "id": 7,
      "question": "How do you handle one-to-many relationships in Spring Data JPA?",
      "answer": "One-to-Many relationship: One parent has many children\n\nBest practices:\n• Use @OneToMany with mappedBy\n• Bidirectional relationship recommended\n• Use helper methods for consistency\n• Consider cascade types\n• Set orphanRemoval for dependent entities",
      "explanation": "OneToMany relationships are common in databases. mappedBy indicates the owning side of the relationship.",
      "difficulty": "Medium",
      "code": "@Entity\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    \n    @OneToMany(mappedBy = \"user\", \n               cascade = CascadeType.ALL,\n               orphanRemoval = true)\n    private List<Order> orders = new ArrayList<>();\n    \n    // Helper methods\n    public void addOrder(Order order) {\n        orders.add(order);\n        order.setUser(this);\n    }\n    \n    public void removeOrder(Order order) {\n        orders.remove(order);\n        order.setUser(null);\n    }\n}\n\n@Entity\npublic class Order {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private BigDecimal amount;\n    \n    @ManyToOne(fetch = FetchType.LAZY)\n    @JoinColumn(name = \"user_id\")\n    private User user;\n}"
    },
    {
      "id": 8,
      "question": "What is the N+1 query problem and how to solve it?",
      "answer": "N+1 Problem: Execute 1 query for parent + N queries for children\n\nExample: Load 100 users + 100 separate queries for their orders\n\nSolutions:\n1. @EntityGraph - Join fetch\n2. JOIN FETCH in JPQL\n3. Batch fetching\n4. DTO projections\n5. FetchType.EAGER (use carefully)",
      "explanation": "N+1 is a performance killer. Each lazy collection triggers a separate query. Use fetch joins to load data in one query.",
      "difficulty": "Hard",
      "code": "// Problem: N+1 queries\nList<User> users = userRepository.findAll();\nfor (User user : users) {\n    user.getOrders().size(); // Triggers separate query for each user!\n}\n\n// Solution 1: @EntityGraph\n@EntityGraph(attributePaths = {\"orders\"})\n@Query(\"SELECT u FROM User u\")\nList<User> findAllWithOrders();\n\n// Solution 2: JOIN FETCH\n@Query(\"SELECT u FROM User u JOIN FETCH u.orders\")\nList<User> findAllWithOrdersJoinFetch();\n\n// Solution 3: Batch fetch size\n@Entity\npublic class User {\n    @OneToMany(mappedBy = \"user\")\n    @BatchSize(size = 10) // Fetch 10 at a time\n    private List<Order> orders;\n}\n\n// Solution 4: DTO Projection\n@Query(\"SELECT new com.example.dto.UserDTO(u.id, u.name, o.amount) \" +\n       \"FROM User u JOIN u.orders o\")\nList<UserDTO> findAllUsersWithOrderAmount();"
    },
    {
      "id": 9,
      "question": "What is the difference between save() and saveAndFlush()?",
      "answer": "save():\n• Persists entity to persistence context\n• Doesn't immediately hit database\n• Executes on transaction commit\n• Returns managed entity\n\nsaveAndFlush():\n• Persists + immediately flushes to DB\n• Forces SQL execution\n• Useful for getting generated IDs immediately\n• Can affect performance",
      "explanation": "save() is normally sufficient. Use saveAndFlush() when you need immediate database execution.",
      "difficulty": "Easy",
      "code": "@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional\n    public void demonstrateSave() {\n        User user = new User(\"John\");\n        \n        // Persists in memory, SQL not executed yet\n        userRepository.save(user);\n        // user.getId() might be null if using GenerationType.IDENTITY\n        \n        // Immediately executes SQL\n        userRepository.saveAndFlush(user);\n        // user.getId() is guaranteed to be set\n        \n        // Both will be committed at end of transaction\n    }\n}"
    },
    {
      "id": 10,
      "question": "How do you implement pagination in Spring Data JPA?",
      "answer": "Pagination splits large result sets into pages:\n\nComponents:\n• Pageable - request parameters\n• Page - result with metadata\n• PageRequest - implementation\n• Sort - sorting specification\n\nBenefits:\n• Reduces memory usage\n• Improves performance\n• Better user experience",
      "explanation": "Pagination is essential for handling large datasets. Spring Data JPA provides built-in support.",
      "difficulty": "Easy",
      "code": "// Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    Page<User> findByStatus(String status, Pageable pageable);\n    \n    @Query(\"SELECT u FROM User u WHERE u.age > :age\")\n    Page<User> findUsersOlderThan(@Param(\"age\") int age, Pageable pageable);\n}\n\n// Service\n@Service\npublic class UserService {\n    public Page<User> getUsers(int page, int size, String sortBy) {\n        Pageable pageable = PageRequest.of(page, size, \n            Sort.by(sortBy).descending());\n        return userRepository.findAll(pageable);\n    }\n}\n\n// Controller\n@GetMapping(\"/users\")\npublic Page<User> getUsers(\n        @RequestParam(defaultValue = \"0\") int page,\n        @RequestParam(defaultValue = \"10\") int size,\n        @RequestParam(defaultValue = \"id\") String sortBy) {\n    return userService.getUsers(page, size, sortBy);\n}\n\n// Response includes:\n// - content: List of entities\n// - totalElements: Total count\n// - totalPages: Number of pages\n// - number: Current page\n// - size: Page size"
    },
    {
      "id": 11,
      "question": "What are JPA entity lifecycle states?",
      "answer": "Entity lifecycle states:\n\n1. Transient (New):\n   • Not associated with persistence context\n   • Not in database\n\n2. Managed (Persistent):\n   • Associated with persistence context\n   • Changes tracked automatically\n\n3. Detached:\n   • Was managed, session closed\n   • Changes not tracked\n\n4. Removed:\n   • Marked for deletion\n   • Deleted on commit",
      "explanation": "Understanding entity states is crucial for proper JPA usage and avoiding common pitfalls.",
      "difficulty": "Medium",
      "code": "@Service\npublic class UserService {\n    @Autowired\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void demonstrateLifecycle() {\n        // 1. TRANSIENT - new entity\n        User user = new User(\"John\");\n        \n        // 2. MANAGED - persist makes it managed\n        entityManager.persist(user);\n        user.setName(\"Jane\"); // Change tracked, will be saved\n        \n        // After transaction commits, entity becomes DETACHED\n    }\n    \n    public void workWithDetached() {\n        User user = entityManager.find(User.class, 1L);\n        entityManager.close();\n        \n        // 3. DETACHED - session closed\n        user.setName(\"Bob\"); // Change NOT tracked\n        \n        // 4. Merge to reattach\n        User managed = entityManager.merge(user);\n        \n        // 5. REMOVED - mark for deletion\n        entityManager.remove(managed);\n    }\n}"
    },
    {
      "id": 12,
      "question": "What is the difference between find() and getReference() in JPA?",
      "answer": "find():\n• Loads entity immediately\n• Returns null if not found\n• Hits database\n• Use when you need the entity\n\ngetReference():\n• Returns proxy (lazy)\n• Throws exception if not found\n• May not hit database immediately\n• Use for setting relationships",
      "explanation": "find() loads data, getReference() creates a proxy. Use getReference() when you only need the ID for relationships.",
      "difficulty": "Medium",
      "code": "@Service\npublic class OrderService {\n    @Autowired\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void demonstrateFindVsGetReference() {\n        // find() - Immediate database hit\n        User user1 = entityManager.find(User.class, 1L);\n        System.out.println(user1.getName()); // Data loaded\n        \n        // getReference() - Returns proxy\n        User user2 = entityManager.getReference(User.class, 1L);\n        System.out.println(user2.getId()); // No DB hit, proxy\n        System.out.println(user2.getName()); // NOW hits database\n        \n        // Practical use case\n        Order order = new Order();\n        order.setAmount(new BigDecimal(\"100.00\"));\n        \n        // Efficient: No need to load entire user\n        order.setUser(entityManager.getReference(User.class, 1L));\n        entityManager.persist(order);\n    }\n}"
    },
    {
      "id": 13,
      "question": "How do you handle many-to-many relationships in JPA?",
      "answer": "Many-to-Many: Multiple entities on both sides\n\nImplementation:\n• @ManyToMany annotation\n• @JoinTable for join table\n• Bidirectional with mappedBy\n• Consider using two @OneToMany with association entity for complex cases",
      "explanation": "ManyToMany creates a join table. For additional attributes in join table, use association entity pattern.",
      "difficulty": "Medium",
      "code": "// Simple ManyToMany\n@Entity\npublic class Student {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String name;\n    \n    @ManyToMany\n    @JoinTable(\n        name = \"student_course\",\n        joinColumns = @JoinColumn(name = \"student_id\"),\n        inverseJoinColumns = @JoinColumn(name = \"course_id\")\n    )\n    private Set<Course> courses = new HashSet<>();\n}\n\n@Entity\npublic class Course {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String name;\n    \n    @ManyToMany(mappedBy = \"courses\")\n    private Set<Student> students = new HashSet<>();\n}\n\n// Better approach with association entity (when you need extra fields)\n@Entity\npublic class StudentCourse {\n    @EmbeddedId\n    private StudentCourseId id;\n    \n    @ManyToOne\n    @MapsId(\"studentId\")\n    private Student student;\n    \n    @ManyToOne\n    @MapsId(\"courseId\")\n    private Course course;\n    \n    private LocalDate enrolledDate;\n    private Integer grade;\n}\n\n@Embeddable\npublic class StudentCourseId implements Serializable {\n    private Long studentId;\n    private Long courseId;\n}"
    },
    {
      "id": 14,
      "question": "What is @Transactional and how does it work in Spring Data JPA?",
      "answer": "@Transactional manages database transactions:\n\nFeatures:\n• Automatic transaction management\n• Rollback on exceptions\n• Propagation control\n• Isolation levels\n• Read-only optimization\n\nDefault behavior:\n• Starts transaction\n• Commits on success\n• Rolls back on RuntimeException",
      "explanation": "@Transactional ensures data consistency. Spring creates proxy to manage transaction lifecycle.",
      "difficulty": "Medium",
      "code": "@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    @Autowired\n    private AuditRepository auditRepository;\n    \n    // Basic transaction\n    @Transactional\n    public void createUser(User user) {\n        userRepository.save(user);\n        auditRepository.log(\"User created\");\n        // Both operations in same transaction\n        // If audit fails, user creation rolls back\n    }\n    \n    // Read-only transaction (optimization)\n    @Transactional(readOnly = true)\n    public List<User> getAllUsers() {\n        return userRepository.findAll();\n    }\n    \n    // Custom configuration\n    @Transactional(\n        propagation = Propagation.REQUIRES_NEW,\n        isolation = Isolation.READ_COMMITTED,\n        timeout = 30,\n        rollbackFor = Exception.class,\n        noRollbackFor = CustomException.class\n    )\n    public void complexOperation() {\n        // Custom transaction behavior\n    }\n}\n\n// Propagation types:\n// REQUIRED (default) - Use existing or create new\n// REQUIRES_NEW - Always create new transaction\n// NESTED - Nested transaction with savepoint\n// MANDATORY - Must run in existing transaction\n// SUPPORTS - Use if exists, else non-transactional\n// NOT_SUPPORTED - Suspend current transaction\n// NEVER - Throw exception if transaction exists"
    },
    {
      "id": 15,
      "question": "How do you implement auditing in Spring Data JPA?",
      "answer": "Auditing tracks who/when entities are created/modified:\n\nSetup:\n1. Enable with @EnableJpaAuditing\n2. Use @CreatedBy, @CreatedDate\n3. Use @LastModifiedBy, @LastModifiedDate\n4. Implement AuditorAware for user\n5. Extend from base audit class\n\nAutomatic population of audit fields.",
      "explanation": "Auditing is crucial for compliance and tracking changes. Spring Data JPA provides automatic auditing.",
      "difficulty": "Easy",
      "code": "// 1. Enable auditing\n@Configuration\n@EnableJpaAuditing(auditorAwareRef = \"auditorProvider\")\npublic class JpaConfig { }\n\n// 2. Implement AuditorAware\n@Component\npublic class AuditorAwareImpl implements AuditorAware<String> {\n    @Override\n    public Optional<String> getCurrentAuditor() {\n        // Get current user from security context\n        Authentication auth = SecurityContextHolder.getContext()\n            .getAuthentication();\n        if (auth != null) {\n            return Optional.of(auth.getName());\n        }\n        return Optional.of(\"system\");\n    }\n}\n\n// 3. Base auditable entity\n@MappedSuperclass\n@EntityListeners(AuditingEntityListener.class)\npublic abstract class Auditable {\n    @CreatedBy\n    @Column(updatable = false)\n    private String createdBy;\n    \n    @CreatedDate\n    @Column(updatable = false)\n    private LocalDateTime createdDate;\n    \n    @LastModifiedBy\n    private String lastModifiedBy;\n    \n    @LastModifiedDate\n    private LocalDateTime lastModifiedDate;\n}\n\n// 4. Entity extends base\n@Entity\npublic class User extends Auditable {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String name;\n    // Audit fields inherited\n}"
    },
    {
      "id": 16,
      "question": "What are JPA Specifications and how to use them?",
      "answer": "Specifications enable type-safe dynamic queries:\n\nBenefits:\n• Build queries programmatically\n• Combine predicates dynamically\n• Type-safe\n• Reusable query logic\n• Alternative to Criteria API\n\nUse for complex search filters.",
      "explanation": "Specifications provide a clean way to build dynamic queries without string concatenation.",
      "difficulty": "Hard",
      "code": "// 1. Entity\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n    private String email;\n    private Integer age;\n    private String status;\n}\n\n// 2. Repository extends JpaSpecificationExecutor\npublic interface UserRepository extends JpaRepository<User, Long>,\n                                        JpaSpecificationExecutor<User> {\n}\n\n// 3. Specification class\npublic class UserSpecifications {\n    \n    public static Specification<User> hasName(String name) {\n        return (root, query, cb) -> \n            name == null ? null : cb.equal(root.get(\"name\"), name);\n    }\n    \n    public static Specification<User> hasEmail(String email) {\n        return (root, query, cb) -> \n            email == null ? null : cb.like(root.get(\"email\"), \"%\" + email + \"%\");\n    }\n    \n    public static Specification<User> ageGreaterThan(Integer age) {\n        return (root, query, cb) -> \n            age == null ? null : cb.greaterThan(root.get(\"age\"), age);\n    }\n    \n    public static Specification<User> hasStatus(String status) {\n        return (root, query, cb) -> \n            status == null ? null : cb.equal(root.get(\"status\"), status);\n    }\n}\n\n// 4. Service using specifications\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    public List<User> searchUsers(String name, String email, \n                                 Integer minAge, String status) {\n        Specification<User> spec = Specification.where(null);\n        \n        if (name != null) {\n            spec = spec.and(UserSpecifications.hasName(name));\n        }\n        if (email != null) {\n            spec = spec.and(UserSpecifications.hasEmail(email));\n        }\n        if (minAge != null) {\n            spec = spec.and(UserSpecifications.ageGreaterThan(minAge));\n        }\n        if (status != null) {\n            spec = spec.and(UserSpecifications.hasStatus(status));\n        }\n        \n        return userRepository.findAll(spec);\n    }\n}"
    },
    {
      "id": 17,
      "question": "What are Projections in Spring Data JPA?",
      "answer": "Projections load partial entity data:\n\nTypes:\n1. Interface-based (closed)\n2. Interface-based (open with @Value)\n3. Class-based (DTO)\n4. Dynamic projections\n\nBenefits:\n• Reduced memory usage\n• Better performance\n• Only needed fields loaded",
      "explanation": "Projections prevent loading entire entities when you only need few fields. Improves performance significantly.",
      "difficulty": "Medium",
      "code": "// Entity\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    private String firstName;\n    private String lastName;\n    private String email;\n    private String address;\n    private LocalDate birthDate;\n}\n\n// 1. Closed Interface Projection\npublic interface UserNameOnly {\n    String getFirstName();\n    String getLastName();\n}\n\n// 2. Open Projection with SpEL\npublic interface UserFullName {\n    @Value(\"#{target.firstName + ' ' + target.lastName}\")\n    String getFullName();\n}\n\n// 3. Class-based DTO Projection\npublic class UserDTO {\n    private Long id;\n    private String firstName;\n    private String email;\n    \n    public UserDTO(Long id, String firstName, String email) {\n        this.id = id;\n        this.firstName = firstName;\n        this.email = email;\n    }\n}\n\n// 4. Repository with projections\npublic interface UserRepository extends JpaRepository<User, Long> {\n    // Returns proxy with only firstName, lastName\n    List<UserNameOnly> findAllBy();\n    \n    // Open projection\n    List<UserFullName> findByAgeLessThan(int age);\n    \n    // DTO projection\n    @Query(\"SELECT new com.example.UserDTO(u.id, u.firstName, u.email) \" +\n           \"FROM User u\")\n    List<UserDTO> findAllUserDTOs();\n    \n    // Dynamic projection\n    <T> List<T> findByEmail(String email, Class<T> type);\n}\n\n// Usage\n@Service\npublic class UserService {\n    public void demonstrateProjections() {\n        // Interface projection\n        List<UserNameOnly> names = userRepository.findAllBy();\n        names.forEach(u -> System.out.println(u.getFirstName()));\n        \n        // Dynamic projection\n        List<UserNameOnly> result1 = \n            userRepository.findByEmail(\"test@test.com\", UserNameOnly.class);\n        List<UserDTO> result2 = \n            userRepository.findByEmail(\"test@test.com\", UserDTO.class);\n    }\n}"
    },
    {
      "id": 18,
      "question": "How do you implement soft delete in Spring Data JPA?",
      "answer": "Soft delete marks records as deleted instead of removing them:\n\nImplementation:\n1. Add deleted flag/timestamp\n2. Use @Where for filtering\n3. Use @SQLDelete for delete\n4. Create custom repository methods\n\nBenefits:\n• Data recovery possible\n• Audit trail maintained\n• Referential integrity preserved",
      "explanation": "Soft delete is essential for data compliance and recovery. Entities remain in database but hidden from queries.",
      "difficulty": "Hard",
      "code": "// 1. Entity with soft delete\n@Entity\n@SQLDelete(sql = \"UPDATE user SET deleted = true WHERE id = ?\")\n@Where(clause = \"deleted = false\")\npublic class User {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String name;\n    private String email;\n    \n    private boolean deleted = false;\n    \n    @Column(name = \"deleted_at\")\n    private LocalDateTime deletedAt;\n    \n    @Column(name = \"deleted_by\")\n    private String deletedBy;\n}\n\n// 2. Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    // Finds only non-deleted (due to @Where)\n    List<User> findAll();\n    \n    // Find including deleted\n    @Query(\"SELECT u FROM User u\")\n    List<User> findAllIncludingDeleted();\n    \n    // Find only deleted\n    @Query(\"SELECT u FROM User u WHERE u.deleted = true\")\n    List<User> findDeleted();\n    \n    // Restore deleted user\n    @Modifying\n    @Query(\"UPDATE User u SET u.deleted = false, u.deletedAt = null \" +\n           \"WHERE u.id = :id\")\n    void restoreById(@Param(\"id\") Long id);\n    \n    // Hard delete (permanent)\n    @Modifying\n    @Query(\"DELETE FROM User u WHERE u.id = :id\")\n    void hardDeleteById(@Param(\"id\") Long id);\n}\n\n// 3. Service with soft delete logic\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional\n    public void softDelete(Long userId) {\n        User user = userRepository.findById(userId)\n            .orElseThrow();\n        \n        user.setDeleted(true);\n        user.setDeletedAt(LocalDateTime.now());\n        user.setDeletedBy(getCurrentUsername());\n        \n        userRepository.save(user);\n    }\n    \n    @Transactional\n    public void restore(Long userId) {\n        userRepository.restoreById(userId);\n    }\n}"
    },
    {
      "id": 19,
      "question": "What is the difference between persist() and merge() in JPA?",
      "answer": "persist():\n• For new (transient) entities\n• Throws exception if entity exists\n• Entity becomes managed\n• Returns void\n• Use for INSERT operations\n\nmerge():\n• For detached entities\n• Creates new managed entity\n• Can handle new or existing\n• Returns managed entity\n• Use for UPDATE operations",
      "explanation": "persist() is for new entities, merge() is for reattaching detached entities. Understand the difference to avoid issues.",
      "difficulty": "Medium",
      "code": "@Service\npublic class UserService {\n    @Autowired\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void demonstratePersist() {\n        User user = new User(\"John\");\n        \n        // persist() - for new entities\n        entityManager.persist(user);\n        // user is now managed\n        // Changes to user will be tracked\n        user.setEmail(\"john@example.com\"); // Will be saved\n        \n        // Error: Detached entity passed to persist\n        // entityManager.persist(existingUser);\n    }\n    \n    @Transactional\n    public void demonstrateMerge() {\n        User user = new User(\"Jane\");\n        user.setId(1L); // Detached entity with existing ID\n        \n        // merge() - for detached entities\n        User managedUser = entityManager.merge(user);\n        // managedUser is now managed\n        // user is still detached!\n        \n        managedUser.setEmail(\"jane@example.com\"); // Will be saved\n        user.setEmail(\"test@test.com\"); // Will NOT be saved\n    }\n    \n    // Spring Data JPA's save() uses merge internally\n    @Transactional\n    public void springSave() {\n        User user = new User(\"Bob\");\n        \n        // save() uses merge logic\n        // Works for both new and existing entities\n        User saved = userRepository.save(user);\n        \n        // Always use the returned entity\n        saved.setEmail(\"bob@example.com\");\n    }\n}"
    },
    {
      "id": 20,
      "question": "How do you handle composite primary keys in JPA?",
      "answer": "Composite keys: Multiple columns as primary key\n\nTwo approaches:\n1. @IdClass - Separate class for ID\n2. @EmbeddedId - Embedded ID class\n\nRequirements:\n• ID class must be Serializable\n• Implement equals() and hashCode()\n• No-arg constructor\n• Public fields or getters",
      "explanation": "Composite keys are common in legacy databases. JPA provides two ways to handle them.",
      "difficulty": "Hard",
      "code": "// Approach 1: @IdClass\n@Entity\n@IdClass(OrderItemId.class)\npublic class OrderItem {\n    @Id\n    private Long orderId;\n    \n    @Id\n    private Long productId;\n    \n    private Integer quantity;\n    private BigDecimal price;\n}\n\npublic class OrderItemId implements Serializable {\n    private Long orderId;\n    private Long productId;\n    \n    // Must implement equals and hashCode\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (!(o instanceof OrderItemId)) return false;\n        OrderItemId that = (OrderItemId) o;\n        return Objects.equals(orderId, that.orderId) &&\n               Objects.equals(productId, that.productId);\n    }\n    \n    @Override\n    public int hashCode() {\n        return Objects.hash(orderId, productId);\n    }\n}\n\n// Approach 2: @EmbeddedId (Recommended)\n@Entity\npublic class OrderItem {\n    @EmbeddedId\n    private OrderItemId id;\n    \n    private Integer quantity;\n    private BigDecimal price;\n}\n\n@Embeddable\npublic class OrderItemId implements Serializable {\n    private Long orderId;\n    private Long productId;\n    \n    // equals, hashCode, constructors\n}\n\n// Repository\npublic interface OrderItemRepository \n        extends JpaRepository<OrderItem, OrderItemId> {\n    \n    List<OrderItem> findByIdOrderId(Long orderId);\n    \n    @Query(\"SELECT oi FROM OrderItem oi WHERE oi.id.orderId = :orderId\")\n    List<OrderItem> findByOrderId(@Param(\"orderId\") Long orderId);\n}\n\n// Usage\nOrderItemId id = new OrderItemId(1L, 100L);\nOptional<OrderItem> item = repository.findById(id);"
    },
    {
      "id": 21,
      "question": "What is @EntityGraph and how does it solve the N+1 problem?",
      "answer": "@EntityGraph defines fetch plan for entities:\n\nFeatures:\n• Specify which associations to load\n• Override default fetch types\n• Multiple graphs per entity\n• Type: FETCH or LOAD\n• Better than JOIN FETCH for complex cases\n\nSolves N+1 by eagerly loading specified associations.",
      "explanation": "@EntityGraph provides fine-grained control over entity fetching, solving performance issues elegantly.",
      "difficulty": "Hard",
      "code": "// 1. Define named entity graphs\n@Entity\n@NamedEntityGraph(\n    name = \"User.orders\",\n    attributeNodes = @NamedAttributeNode(\"orders\")\n)\n@NamedEntityGraph(\n    name = \"User.full\",\n    attributeNodes = {\n        @NamedAttributeNode(\"orders\"),\n        @NamedAttributeNode(\"address\"),\n        @NamedAttributeNode(\"roles\")\n    }\n)\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n    \n    @OneToMany(mappedBy = \"user\", fetch = FetchType.LAZY)\n    private List<Order> orders;\n    \n    @OneToOne(fetch = FetchType.LAZY)\n    private Address address;\n    \n    @ManyToMany(fetch = FetchType.LAZY)\n    private Set<Role> roles;\n}\n\n// 2. Repository with entity graphs\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // Use named graph\n    @EntityGraph(value = \"User.orders\")\n    List<User> findAll();\n    \n    // Ad-hoc graph\n    @EntityGraph(attributePaths = {\"orders\", \"address\"})\n    Optional<User> findById(Long id);\n    \n    // Multiple associations\n    @EntityGraph(attributePaths = {\"orders\", \"orders.items\", \"address\"})\n    @Query(\"SELECT u FROM User u WHERE u.status = :status\")\n    List<User> findByStatus(@Param(\"status\") String status);\n    \n    // FETCH vs LOAD type\n    @EntityGraph(value = \"User.full\", type = EntityGraph.EntityGraphType.FETCH)\n    List<User> findByNameContaining(String name);\n}\n\n// FETCH: Eager load specified, lazy load others\n// LOAD: Eager load specified, use default for others"
    },
    {
      "id": 22,
      "question": "How do you implement optimistic locking in JPA?",
      "answer": "Optimistic locking prevents lost updates:\n\nImplementation:\n• @Version annotation\n• Version column (number or timestamp)\n• Auto-incremented on update\n• Throws OptimisticLockException on conflict\n\nUse when:\n• Low conflict probability\n• Better performance than pessimistic\n• Multiple users editing same data",
      "explanation": "Optimistic locking assumes conflicts are rare. Detects conflicts at commit time using version numbers.",
      "difficulty": "Medium",
      "code": "@Entity\npublic class Product {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String name;\n    private BigDecimal price;\n    private Integer stock;\n    \n    @Version\n    private Long version; // Auto-managed by JPA\n}\n\n// Service with conflict handling\n@Service\npublic class ProductService {\n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Transactional\n    public void updateStock(Long productId, Integer quantity) {\n        try {\n            Product product = productRepository.findById(productId)\n                .orElseThrow();\n            \n            product.setStock(product.getStock() - quantity);\n            productRepository.save(product);\n            // Version automatically incremented\n            \n        } catch (OptimisticLockException e) {\n            // Another transaction modified the product\n            throw new StockUpdateException(\n                \"Product was modified by another user. Please retry.\");\n        }\n    }\n    \n    // With retry logic\n    @Transactional\n    public void updateWithRetry(Long productId, Integer quantity) {\n        int maxRetries = 3;\n        int attempt = 0;\n        \n        while (attempt < maxRetries) {\n            try {\n                Product product = productRepository.findById(productId)\n                    .orElseThrow();\n                product.setStock(product.getStock() - quantity);\n                productRepository.save(product);\n                return; // Success\n                \n            } catch (OptimisticLockException e) {\n                attempt++;\n                if (attempt >= maxRetries) {\n                    throw new StockUpdateException(\n                        \"Failed after \" + maxRetries + \" attempts\");\n                }\n                // Wait before retry\n                Thread.sleep(100 * attempt);\n            }\n        }\n    }\n}"
    },
    {
      "id": 23,
      "question": "What is pessimistic locking and how to implement it?",
      "answer": "Pessimistic locking prevents concurrent access:\n\nLock modes:\n• PESSIMISTIC_READ - Shared lock\n• PESSIMISTIC_WRITE - Exclusive lock\n• PESSIMISTIC_FORCE_INCREMENT - Lock + version\n\nUse when:\n• High conflict probability\n• Critical operations\n• Must prevent conflicts\n\nNote: Database-level locks, may cause deadlocks",
      "explanation": "Pessimistic locking acquires database locks immediately. Use for critical operations where conflicts must be prevented.",
      "difficulty": "Hard",
      "code": "public interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    // PESSIMISTIC_WRITE - Exclusive lock\n    @Lock(LockModeType.PESSIMISTIC_WRITE)\n    @Query(\"SELECT p FROM Product p WHERE p.id = :id\")\n    Optional<Product> findByIdForUpdate(@Param(\"id\") Long id);\n    \n    // PESSIMISTIC_READ - Shared lock\n    @Lock(LockModeType.PESSIMISTIC_READ)\n    @Query(\"SELECT p FROM Product p WHERE p.category = :category\")\n    List<Product> findByCategoryWithReadLock(@Param(\"category\") String category);\n    \n    // With timeout\n    @Lock(LockModeType.PESSIMISTIC_WRITE)\n    @QueryHints({@QueryHint(name = \"javax.persistence.lock.timeout\", value = \"5000\")})\n    Optional<Product> findByIdWithTimeout(Long id);\n}\n\n// Service using pessimistic locks\n@Service\npublic class InventoryService {\n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Autowired\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void reserveStock(Long productId, Integer quantity) {\n        // Lock product for update\n        Product product = productRepository.findByIdForUpdate(productId)\n            .orElseThrow();\n        \n        if (product.getStock() < quantity) {\n            throw new InsufficientStockException();\n        }\n        \n        product.setStock(product.getStock() - quantity);\n        // Lock held until transaction commits\n    }\n    \n    // Using EntityManager\n    @Transactional\n    public void updateWithEntityManager(Long productId) {\n        Product product = entityManager.find(\n            Product.class, \n            productId,\n            LockModeType.PESSIMISTIC_WRITE\n        );\n        \n        // Or lock existing entity\n        // entityManager.lock(product, LockModeType.PESSIMISTIC_WRITE);\n        \n        product.setPrice(product.getPrice().multiply(new BigDecimal(\"1.1\")));\n    }\n    \n    // Deadlock handling\n    @Transactional\n    public void handleDeadlock(Long id1, Long id2) {\n        try {\n            // Always lock in same order to prevent deadlocks\n            Long first = Math.min(id1, id2);\n            Long second = Math.max(id1, id2);\n            \n            Product p1 = productRepository.findByIdForUpdate(first).orElseThrow();\n            Product p2 = productRepository.findByIdForUpdate(second).orElseThrow();\n            \n            // Update products\n            \n        } catch (PessimisticLockException e) {\n            throw new ResourceLockedException(\"Could not acquire lock\");\n        }\n    }\n}"
    },
    {
      "id": 24,
      "question": "How do you implement custom repository methods in Spring Data JPA?",
      "answer": "Custom repository implementation for complex logic:\n\nSteps:\n1. Create custom interface\n2. Implement with 'Impl' suffix\n3. Main repository extends both\n4. Use EntityManager or Spring Data utilities\n\nUse for:\n• Complex queries\n• Bulk operations\n• Custom logic",
      "explanation": "Custom repositories allow extending Spring Data JPA with your own implementations when needed.",
      "difficulty": "Medium",
      "code": "// 1. Custom interface\npublic interface UserRepositoryCustom {\n    List<User> findUsersWithComplexCriteria(SearchCriteria criteria);\n    void bulkUpdateStatus(List<Long> userIds, String status);\n}\n\n// 2. Implementation (must end with 'Impl')\n@Repository\npublic class UserRepositoryImpl implements UserRepositoryCustom {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public List<User> findUsersWithComplexCriteria(SearchCriteria criteria) {\n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<User> query = cb.createQuery(User.class);\n        Root<User> root = query.from(User.class);\n        \n        List<Predicate> predicates = new ArrayList<>();\n        \n        if (criteria.getName() != null) {\n            predicates.add(cb.like(root.get(\"name\"), \"%\" + criteria.getName() + \"%\"));\n        }\n        \n        if (criteria.getMinAge() != null) {\n            predicates.add(cb.greaterThanOrEqualTo(root.get(\"age\"), criteria.getMinAge()));\n        }\n        \n        if (criteria.getStatuses() != null && !criteria.getStatuses().isEmpty()) {\n            predicates.add(root.get(\"status\").in(criteria.getStatuses()));\n        }\n        \n        query.where(predicates.toArray(new Predicate[0]));\n        query.orderBy(cb.desc(root.get(\"createdDate\")));\n        \n        return entityManager.createQuery(query)\n            .setMaxResults(100)\n            .getResultList();\n    }\n    \n    @Override\n    @Transactional\n    public void bulkUpdateStatus(List<Long> userIds, String status) {\n        entityManager.createQuery(\n            \"UPDATE User u SET u.status = :status WHERE u.id IN :ids\")\n            .setParameter(\"status\", status)\n            .setParameter(\"ids\", userIds)\n            .executeUpdate();\n    }\n}\n\n// 3. Main repository extends both\npublic interface UserRepository extends JpaRepository<User, Long>,\n                                        UserRepositoryCustom {\n    // Standard Spring Data methods\n    List<User> findByName(String name);\n    \n    // Custom methods available here too\n}\n\n// 4. Usage\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    public void demonstrateCustomMethods() {\n        // Standard method\n        List<User> users1 = userRepository.findByName(\"John\");\n        \n        // Custom method\n        SearchCriteria criteria = new SearchCriteria();\n        criteria.setName(\"John\");\n        criteria.setMinAge(25);\n        List<User> users2 = userRepository.findUsersWithComplexCriteria(criteria);\n        \n        // Bulk update\n        userRepository.bulkUpdateStatus(Arrays.asList(1L, 2L, 3L), \"ACTIVE\");\n    }\n}"
    },
    {
      "id": 25,
      "question": "How do you implement second-level caching in Spring Data JPA?",
      "answer": "Second-level cache improves performance:\n\nLevels:\n• First-level (persistence context) - automatic\n• Second-level (SessionFactory) - configuration needed\n• Query cache - caches query results\n\nProviders:\n• EhCache (most common)\n• Hazelcast\n• Redis\n• Infinispan\n\nCache strategies:\n• READ_ONLY\n• READ_WRITE\n• NONSTRICT_READ_WRITE\n• TRANSACTIONAL",
      "explanation": "Second-level cache shares data across sessions. Significantly improves performance for read-heavy applications.",
      "difficulty": "Hard",
      "code": "// 1. Dependencies (pom.xml)\n// <dependency>\n//     <groupId>org.hibernate</groupId>\n//     <artifactId>hibernate-ehcache</artifactId>\n// </dependency>\n\n// 2. application.yml\n// spring:\n//   jpa:\n//     properties:\n//       hibernate:\n//         cache:\n//           use_second_level_cache: true\n//           use_query_cache: true\n//           region.factory_class: org.hibernate.cache.jcache.JCacheRegionFactory\n//       javax:\n//         persistence:\n//           sharedCache:\n//             mode: ENABLE_SELECTIVE\n\n// 3. ehcache.xml\n// <config>\n//   <cache alias=\"users\">\n//     <expiry><ttl unit=\"minutes\">10</ttl></expiry>\n//     <heap unit=\"entries\">1000</heap>\n//   </cache>\n// </config>\n\n// 4. Cacheable entities\n@Entity\n@Cacheable\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.READ_WRITE,\n    region = \"users\"\n)\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n    \n    @OneToMany(mappedBy = \"user\")\n    @org.hibernate.annotations.Cache(\n        usage = CacheConcurrencyStrategy.READ_WRITE\n    )\n    private List<Order> orders;\n}\n\n// 5. Query cache\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    @QueryHints(@QueryHint(name = \"org.hibernate.cacheable\", value = \"true\"))\n    @Query(\"SELECT u FROM User u WHERE u.status = :status\")\n    List<User> findByStatusCached(@Param(\"status\") String status);\n}\n\n// 6. Programmatic cache control\n@Service\npublic class UserService {\n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public void evictCache() {\n        Cache cache = entityManager.getEntityManagerFactory()\n            .getCache();\n        \n        // Evict specific entity\n        cache.evict(User.class, 1L);\n        \n        // Evict all users\n        cache.evict(User.class);\n        \n        // Evict entire cache\n        cache.evictAll();\n    }\n    \n    public boolean isInCache(Long userId) {\n        return entityManager.getEntityManagerFactory()\n            .getCache()\n            .contains(User.class, userId);\n    }\n}"
    },
    {
      "id": 26,
      "question": "What is @Modifying annotation and when to use it?",
      "answer": "@Modifying for UPDATE/DELETE queries:\n\nFeatures:\n• Required for modifying queries\n• Works with @Query\n• Clears persistence context\n• Returns affected row count\n• Can set clearAutomatically\n\nImportant:\n• Use with @Transactional\n• Bypasses entity lifecycle\n• More efficient than load-modify-save",
      "explanation": "@Modifying tells Spring Data the query modifies data. Essential for bulk UPDATE/DELETE operations.",
      "difficulty": "Medium",
      "code": "public interface UserRepository extends JpaRepository<User, Long> {\n    \n    // UPDATE query\n    @Modifying\n    @Transactional\n    @Query(\"UPDATE User u SET u.status = :status WHERE u.lastLogin < :date\")\n    int updateInactiveUsers(\n        @Param(\"status\") String status, \n        @Param(\"date\") LocalDateTime date\n    );\n    \n    // DELETE query\n    @Modifying\n    @Query(\"DELETE FROM User u WHERE u.confirmed = false AND u.createdDate < :date\")\n    void deleteUnconfirmedUsers(@Param(\"date\") LocalDateTime date);\n    \n    // Clear persistence context after\n    @Modifying(clearAutomatically = true)\n    @Query(\"UPDATE User u SET u.lastLogin = :now WHERE u.id = :id\")\n    void updateLastLogin(@Param(\"id\") Long id, @Param(\"now\") LocalDateTime now);\n    \n    // Native SQL\n    @Modifying\n    @Query(value = \"UPDATE users SET status = ?1 WHERE age < ?2\", \n           nativeQuery = true)\n    int updateStatusByAge(String status, int age);\n    \n    // Flush changes before\n    @Modifying(flushAutomatically = true, clearAutomatically = true)\n    @Query(\"UPDATE User u SET u.email = :email WHERE u.id = :id\")\n    void updateEmail(@Param(\"id\") Long id, @Param(\"email\") String email);\n}\n\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional\n    public void demonstrateModifying() {\n        // Efficient bulk update\n        int updated = userRepository.updateInactiveUsers(\n            \"INACTIVE\", \n            LocalDateTime.now().minusDays(30)\n        );\n        System.out.println(\"Updated \" + updated + \" users\");\n        \n        // Important: Persistence context not updated!\n        User user = userRepository.findById(1L).get();\n        // user.getStatus() might still be old value\n        \n        // Solution: Refresh or clear context\n        entityManager.refresh(user);\n        // OR use clearAutomatically = true\n    }\n    \n    // Compare: Load-modify-save approach (less efficient)\n    @Transactional\n    public void updateOneByOne() {\n        List<User> users = userRepository.findByLastLoginBefore(\n            LocalDateTime.now().minusDays(30)\n        );\n        \n        users.forEach(u -> u.setStatus(\"INACTIVE\"));\n        userRepository.saveAll(users);\n        // Many individual UPDATE statements!\n    }\n}"
    },
    {
      "id": 27,
      "question": "How do you implement database schema generation and migration?",
      "answer": "Schema management approaches:\n\n1. JPA auto-generation (development only):\n   • hibernate.ddl-auto\n   • validate, update, create, create-drop\n\n2. Flyway (recommended for production):\n   • Version control for DB\n   • SQL-based migrations\n   • Rollback support\n\n3. Liquibase:\n   • XML/YAML/JSON format\n   • Database-agnostic\n   • Advanced features",
      "explanation": "Use hibernate.ddl-auto for development, but always use migration tools like Flyway for production.",
      "difficulty": "Medium",
      "code": "// 1. JPA Auto-generation (application.yml)\n// spring:\n//   jpa:\n//     hibernate:\n//       ddl-auto: validate  # Production\n//       # ddl-auto: update   # Development (careful!)\n//       # ddl-auto: create   # Testing\n//       # ddl-auto: create-drop  # Integration tests\n//     properties:\n//       hibernate:\n//         format_sql: true\n//         show_sql: true\n\n// 2. Flyway setup (pom.xml)\n// <dependency>\n//     <groupId>org.flywaydb</groupId>\n//     <artifactId>flyway-core</artifactId>\n// </dependency>\n\n// application.yml\n// spring:\n//   flyway:\n//     enabled: true\n//     baseline-on-migrate: true\n//     locations: classpath:db/migration\n\n// 3. Migration files (src/main/resources/db/migration)\n\n// V1__Create_user_table.sql\n/*\nCREATE TABLE users (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    name VARCHAR(255) NOT NULL,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n*/\n\n// V2__Add_status_to_user.sql\n/*\nALTER TABLE users ADD COLUMN status VARCHAR(50) DEFAULT 'ACTIVE';\nCREATE INDEX idx_users_status ON users(status);\n*/\n\n// V3__Create_order_table.sql\n/*\nCREATE TABLE orders (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    user_id BIGINT NOT NULL,\n    amount DECIMAL(10,2) NOT NULL,\n    created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n*/\n\n// 4. Java-based migrations\n@Component\npublic class V4__Insert_initial_data implements JavaMigration {\n    \n    @Override\n    public void migrate(Context context) throws Exception {\n        try (Statement statement = context.getConnection().createStatement()) {\n            statement.execute(\n                \"INSERT INTO users (name, email, status) \" +\n                \"VALUES ('Admin', 'admin@example.com', 'ACTIVE')\"\n            );\n        }\n    }\n}\n\n// 5. Configuration\n@Configuration\npublic class FlywayConfig {\n    \n    @Bean\n    public FlywayMigrationStrategy cleanMigrateStrategy() {\n        return flyway -> {\n            // Repair if needed\n            flyway.repair();\n            // Run migrations\n            flyway.migrate();\n        };\n    }\n}\n\n// 6. Testing with separate schema\n@SpringBootTest\n@TestPropertySource(locations = \"classpath:application-test.yml\")\npublic class UserRepositoryTest {\n    // Uses H2 in-memory database with Flyway migrations\n}"
    },
    {
      "id": 28,
      "question": "How do you handle inheritance mapping in JPA?",
      "answer": "JPA inheritance strategies:\n\n1. SINGLE_TABLE (default):\n   • One table for hierarchy\n   • Discriminator column\n   • Fast, but nullable columns\n\n2. JOINED:\n   • Table per class\n   • Normalized\n   • Slower (joins required)\n\n3. TABLE_PER_CLASS:\n   • Concrete tables only\n   • No discriminator\n   • Union queries (slow)",
      "explanation": "Choose strategy based on needs: SINGLE_TABLE for performance, JOINED for normalization.",
      "difficulty": "Hard",
      "code": "// Strategy 1: SINGLE_TABLE\n@Entity\n@Inheritance(strategy = InheritanceType.SINGLE_TABLE)\n@DiscriminatorColumn(name = \"user_type\", discriminatorType = DiscriminatorType.STRING)\npublic abstract class User {\n    @Id\n    @GeneratedValue\n    private Long id;\n    private String name;\n    private String email;\n}\n\n@Entity\n@DiscriminatorValue(\"EMPLOYEE\")\npublic class Employee extends User {\n    private String department;\n    private BigDecimal salary;\n}\n\n@Entity\n@DiscriminatorValue(\"CUSTOMER\")\npublic class Customer extends User {\n    private String loyaltyNumber;\n    private Integer points;\n}\n\n// Result: One table 'user' with columns:\n// id, name, email, user_type, department, salary, loyalty_number, points\n\n// Strategy 2: JOINED\n@Entity\n@Inheritance(strategy = InheritanceType.JOINED)\npublic abstract class Vehicle {\n    @Id\n    @GeneratedValue\n    private Long id;\n    private String manufacturer;\n    private String model;\n}\n\n@Entity\n@PrimaryKeyJoinColumn(name = \"vehicle_id\")\npublic class Car extends Vehicle {\n    private Integer doors;\n    private String fuelType;\n}\n\n@Entity\n@PrimaryKeyJoinColumn(name = \"vehicle_id\")\npublic class Motorcycle extends Vehicle {\n    private Integer engineCapacity;\n    private boolean hasSidecar;\n}\n\n// Result: Three tables\n// vehicle: id, manufacturer, model\n// car: vehicle_id, doors, fuel_type\n// motorcycle: vehicle_id, engine_capacity, has_sidecar\n\n// Strategy 3: TABLE_PER_CLASS\n@Entity\n@Inheritance(strategy = InheritanceType.TABLE_PER_CLASS)\npublic abstract class Payment {\n    @Id\n    @GeneratedValue(strategy = GenerationType.TABLE)\n    private Long id;\n    private BigDecimal amount;\n    private LocalDateTime paymentDate;\n}\n\n@Entity\npublic class CreditCardPayment extends Payment {\n    private String cardNumber;\n    private String cvv;\n}\n\n@Entity\npublic class BankTransferPayment extends Payment {\n    private String accountNumber;\n    private String bankCode;\n}\n\n// Result: Two separate tables with all columns\n// credit_card_payment: id, amount, payment_date, card_number, cvv\n// bank_transfer_payment: id, amount, payment_date, account_number, bank_code\n\n// Repositories\npublic interface UserRepository extends JpaRepository<User, Long> {\n    List<Employee> findAllEmployees();\n}\n\npublic interface EmployeeRepository extends JpaRepository<Employee, Long> {\n    List<Employee> findByDepartment(String department);\n}"
    },
    {
      "id": 29,
      "question": "What are embedded objects and how to use @Embeddable?",
      "answer": "@Embeddable for value objects:\n\nFeatures:\n• Reusable components\n• No separate table\n• No primary key\n• Columns in parent table\n• @AttributeOverride for customization\n\nUse for:\n• Address, name, money\n• Common field groups\n• Domain-driven design value objects",
      "explanation": "Embeddable objects group related fields together, improving code organization without creating separate tables.",
      "difficulty": "Easy",
      "code": "// 1. Embeddable class\n@Embeddable\npublic class Address {\n    private String street;\n    private String city;\n    private String state;\n    private String zipCode;\n    private String country;\n    \n    // Constructors, getters, setters\n}\n\n@Embeddable\npublic class Money {\n    private BigDecimal amount;\n    private String currency;\n    \n    public Money add(Money other) {\n        if (!this.currency.equals(other.currency)) {\n            throw new IllegalArgumentException(\"Currency mismatch\");\n        }\n        return new Money(this.amount.add(other.amount), this.currency);\n    }\n}\n\n// 2. Entity using embeddable\n@Entity\npublic class User {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String name;\n    \n    @Embedded\n    private Address address;\n    \n    // Multiple embeddables with attribute override\n    @Embedded\n    @AttributeOverrides({\n        @AttributeOverride(name = \"street\", column = @Column(name = \"shipping_street\")),\n        @AttributeOverride(name = \"city\", column = @Column(name = \"shipping_city\")),\n        @AttributeOverride(name = \"zipCode\", column = @Column(name = \"shipping_zip\"))\n    })\n    private Address shippingAddress;\n}\n\n@Entity\npublic class Order {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    @Embedded\n    private Money totalAmount;\n    \n    @Embedded\n    @AttributeOverrides({\n        @AttributeOverride(name = \"amount\", column = @Column(name = \"tax_amount\")),\n        @AttributeOverride(name = \"currency\", column = @Column(name = \"tax_currency\"))\n    })\n    private Money taxAmount;\n}\n\n// 3. Repository queries with embeddables\npublic interface UserRepository extends JpaRepository<User, Long> {\n    // Query embeddable fields\n    List<User> findByAddressCity(String city);\n    \n    @Query(\"SELECT u FROM User u WHERE u.address.city = :city AND u.address.state = :state\")\n    List<User> findByCityAndState(@Param(\"city\") String city, \n                                   @Param(\"state\") String state);\n    \n    // With null handling\n    @Query(\"SELECT u FROM User u WHERE u.shippingAddress IS NOT NULL\")\n    List<User> findUsersWithShippingAddress();\n}\n\n// Result: Single table 'user' with columns:\n// id, name, street, city, state, zip_code, country,\n// shipping_street, shipping_city, shipping_zip, ..."
    },
    {
      "id": 30,
      "question": "How do you implement batch processing in Spring Data JPA?",
      "answer": "Batch processing for bulk operations:\n\nConfiguration:\n• hibernate.jdbc.batch_size\n• hibernate.order_inserts\n• hibernate.order_updates\n• hibernate.jdbc.batch_versioned_data\n\nBenefits:\n• Reduced database round trips\n• Better performance\n• Efficient bulk operations\n\nUse saveAll(), flush() appropriately.",
      "explanation": "Batch processing groups multiple SQL statements together, significantly improving performance for bulk operations.",
      "difficulty": "Hard",
      "code": "// 1. Configuration (application.yml)\n// spring:\n//   jpa:\n//     properties:\n//       hibernate:\n//         jdbc:\n//           batch_size: 20\n//         order_inserts: true\n//         order_updates: true\n//         batch_versioned_data: true\n//         generate_statistics: true\n\n// 2. Efficient batch insert\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    @Autowired\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void batchInsertUsers(List<User> users) {\n        int batchSize = 20;\n        \n        for (int i = 0; i < users.size(); i++) {\n            entityManager.persist(users.get(i));\n            \n            if (i > 0 && i % batchSize == 0) {\n                // Flush and clear to prevent memory issues\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n        entityManager.flush();\n        entityManager.clear();\n    }\n    \n    // Using saveAll (less control)\n    @Transactional\n    public void batchSave(List<User> users) {\n        userRepository.saveAll(users);\n        // Batching happens automatically if configured\n    }\n    \n    // Efficient batch update\n    @Transactional\n    public void batchUpdate(List<User> users) {\n        int batchSize = 20;\n        \n        for (int i = 0; i < users.size(); i++) {\n            User user = users.get(i);\n            user.setLastModified(LocalDateTime.now());\n            entityManager.merge(user);\n            \n            if (i > 0 && i % batchSize == 0) {\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n    }\n    \n    // Large dataset processing\n    @Transactional\n    public void processLargeDataset() {\n        int pageSize = 100;\n        int pageNumber = 0;\n        Page<User> page;\n        \n        do {\n            page = userRepository.findAll(\n                PageRequest.of(pageNumber, pageSize)\n            );\n            \n            // Process page\n            page.getContent().forEach(user -> {\n                // Update user\n                user.setProcessed(true);\n            });\n            \n            entityManager.flush();\n            entityManager.clear();\n            pageNumber++;\n            \n        } while (page.hasNext());\n    }\n}\n\n// 3. Batch delete (careful with relationships)\n@Service\npublic class BatchDeleteService {\n    \n    @Transactional\n    public void batchDelete(List<Long> ids) {\n        // Efficient bulk delete\n        userRepository.deleteAllByIdInBatch(ids);\n        \n        // Or with query\n        // @Query(\"DELETE FROM User u WHERE u.id IN :ids\")\n        // @Modifying\n        // void deleteByIds(@Param(\"ids\") List<Long> ids);\n    }\n}\n\n// 4. Important notes\n/*\n * Batching won't work if:\n * - Using GenerationType.IDENTITY (use SEQUENCE or TABLE)\n * - Entities have different types in saveAll()\n * - Cascading operations involved\n * - Using versioned entities without batch_versioned_data\n */"
    },
    {
      "id": 31,
      "question": "What is the Criteria API and when to use it?",
      "answer": "Criteria API for type-safe dynamic queries:\n\nFeatures:\n• Type-safe queries\n• No string concatenation\n• Compile-time checking\n• Programmatic query building\n• Complex dynamic conditions\n\nUse when:\n• Dynamic search forms\n• Complex filter logic\n• Type safety important\n\nAlternative: Spring Data Specifications",
      "explanation": "Criteria API builds queries programmatically with type safety. More verbose than JPQL but safer for dynamic queries.",
      "difficulty": "Hard",
      "code": "@Repository\npublic class UserCriteriaRepository {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<User> findByCriteria(UserSearchCriteria criteria) {\n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<User> query = cb.createQuery(User.class);\n        Root<User> user = query.from(User.class);\n        \n        List<Predicate> predicates = new ArrayList<>();\n        \n        // Dynamic conditions\n        if (criteria.getName() != null) {\n            predicates.add(cb.like(\n                cb.lower(user.get(\"name\")), \n                \"%\" + criteria.getName().toLowerCase() + \"%\"\n            ));\n        }\n        \n        if (criteria.getMinAge() != null) {\n            predicates.add(cb.greaterThanOrEqualTo(\n                user.get(\"age\"), \n                criteria.getMinAge()\n            ));\n        }\n        \n        if (criteria.getStatuses() != null && !criteria.getStatuses().isEmpty()) {\n            predicates.add(user.get(\"status\").in(criteria.getStatuses()));\n        }\n        \n        if (criteria.getStartDate() != null && criteria.getEndDate() != null) {\n            predicates.add(cb.between(\n                user.get(\"createdDate\"),\n                criteria.getStartDate(),\n                criteria.getEndDate()\n            ));\n        }\n        \n        // Combine predicates\n        query.where(cb.and(predicates.toArray(new Predicate[0])));\n        \n        // Sorting\n        if (criteria.getSortBy() != null) {\n            if (\"DESC\".equals(criteria.getSortOrder())) {\n                query.orderBy(cb.desc(user.get(criteria.getSortBy())));\n            } else {\n                query.orderBy(cb.asc(user.get(criteria.getSortBy())));\n            }\n        }\n        \n        TypedQuery<User> typedQuery = entityManager.createQuery(query);\n        \n        // Pagination\n        if (criteria.getPageNumber() != null && criteria.getPageSize() != null) {\n            typedQuery.setFirstResult(criteria.getPageNumber() * criteria.getPageSize());\n            typedQuery.setMaxResults(criteria.getPageSize());\n        }\n        \n        return typedQuery.getResultList();\n    }\n    \n    // Complex join query\n    public List<User> findUsersWithOrders(BigDecimal minOrderAmount) {\n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<User> query = cb.createQuery(User.class);\n        Root<User> user = query.from(User.class);\n        Join<User, Order> orders = user.join(\"orders\");\n        \n        query.where(cb.greaterThan(orders.get(\"amount\"), minOrderAmount));\n        query.distinct(true);\n        \n        return entityManager.createQuery(query).getResultList();\n    }\n    \n    // Aggregate query\n    public Map<String, Long> getUserCountByStatus() {\n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<Object[]> query = cb.createQuery(Object[].class);\n        Root<User> user = query.from(User.class);\n        \n        query.multiselect(\n            user.get(\"status\"),\n            cb.count(user)\n        );\n        query.groupBy(user.get(\"status\"));\n        \n        List<Object[]> results = entityManager.createQuery(query).getResultList();\n        \n        return results.stream()\n            .collect(Collectors.toMap(\n                row -> (String) row[0],\n                row -> (Long) row[1]\n            ));\n    }\n    \n    // Subquery\n    public List<User> findUsersWithHighValueOrders() {\n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<User> query = cb.createQuery(User.class);\n        Root<User> user = query.from(User.class);\n        \n        // Subquery\n        Subquery<BigDecimal> subquery = query.subquery(BigDecimal.class);\n        Root<Order> order = subquery.from(Order.class);\n        subquery.select(cb.avg(order.get(\"amount\")));\n        \n        // Main query\n        Join<User, Order> userOrders = user.join(\"orders\");\n        query.where(cb.greaterThan(\n            userOrders.get(\"amount\"),\n            subquery\n        ));\n        \n        return entityManager.createQuery(query).getResultList();\n    }\n}"
    },
    {
      "id": 32,
      "question": "How do you implement database views in Spring Data JPA?",
      "answer": "Database views as read-only entities:\n\nApproaches:\n1. @Immutable annotation\n2. @Subselect for Hibernate\n3. Native queries\n4. Projections\n\nBenefits:\n• Complex queries performance\n• Denormalization\n• Legacy database integration\n• Reporting",
      "explanation": "Views provide read-only access to complex queries. Map them as immutable entities in JPA.",
      "difficulty": "Medium",
      "code": "// 1. Create view in database\n// CREATE VIEW user_order_summary AS\n// SELECT u.id as user_id, \n//        u.name as user_name,\n//        COUNT(o.id) as order_count,\n//        SUM(o.amount) as total_amount,\n//        MAX(o.created_date) as last_order_date\n// FROM users u\n// LEFT JOIN orders o ON u.id = o.user_id\n// GROUP BY u.id, u.name;\n\n// 2. Entity mapping for view\n@Entity\n@Immutable\n@Table(name = \"user_order_summary\")\npublic class UserOrderSummary {\n    \n    @Id\n    @Column(name = \"user_id\")\n    private Long userId;\n    \n    @Column(name = \"user_name\")\n    private String userName;\n    \n    @Column(name = \"order_count\")\n    private Long orderCount;\n    \n    @Column(name = \"total_amount\")\n    private BigDecimal totalAmount;\n    \n    @Column(name = \"last_order_date\")\n    private LocalDateTime lastOrderDate;\n    \n    // Getters only (immutable)\n}\n\n// 3. Repository\npublic interface UserOrderSummaryRepository \n        extends JpaRepository<UserOrderSummary, Long> {\n    \n    List<UserOrderSummary> findByOrderCountGreaterThan(Long count);\n    \n    @Query(\"SELECT s FROM UserOrderSummary s WHERE s.totalAmount > :amount\")\n    List<UserOrderSummary> findHighValueCustomers(\n        @Param(\"amount\") BigDecimal amount\n    );\n}\n\n// 4. Alternative: @Subselect for Hibernate-specific views\n@Entity\n@Immutable\n@Subselect(\n    \"SELECT u.id as user_id, \" +\n    \"u.name as user_name, \" +\n    \"COUNT(o.id) as order_count \" +\n    \"FROM users u \" +\n    \"LEFT JOIN orders o ON u.id = o.user_id \" +\n    \"GROUP BY u.id, u.name\"\n)\npublic class UserStats {\n    @Id\n    private Long userId;\n    private String userName;\n    private Long orderCount;\n}\n\n// 5. Complex view with joins\n@Entity\n@Immutable\n@Table(name = \"product_sales_view\")\npublic class ProductSalesView {\n    @Id\n    private Long productId;\n    private String productName;\n    private String categoryName;\n    private Long totalSales;\n    private BigDecimal revenue;\n    private BigDecimal averagePrice;\n    \n    @Column(name = \"top_customer_name\")\n    private String topCustomerName;\n}\n\n// 6. Service using views\n@Service\npublic class ReportService {\n    @Autowired\n    private UserOrderSummaryRepository summaryRepository;\n    \n    @Transactional(readOnly = true)\n    public List<UserOrderSummary> getTopCustomers(int limit) {\n        return summaryRepository.findAll(\n            PageRequest.of(0, limit, \n                Sort.by(\"totalAmount\").descending())\n        ).getContent();\n    }\n    \n    @Transactional(readOnly = true)\n    public Map<String, Object> getCustomerStats() {\n        List<UserOrderSummary> summaries = summaryRepository.findAll();\n        \n        return Map.of(\n            \"totalCustomers\", summaries.size(),\n            \"totalRevenue\", summaries.stream()\n                .map(UserOrderSummary::getTotalAmount)\n                .reduce(BigDecimal.ZERO, BigDecimal::add),\n            \"averageOrders\", summaries.stream()\n                .mapToLong(UserOrderSummary::getOrderCount)\n                .average()\n                .orElse(0.0)\n        );\n    }\n}"
    },
    {
      "id": 33,
      "question": "How do you handle enum types in JPA?",
      "answer": "Enum mapping strategies:\n\n1. @Enumerated(EnumType.STRING):\n   • Stores enum name\n   • Database-readable\n   • Refactoring-safe (can rename)\n   • Recommended\n\n2. @Enumerated(EnumType.ORDINAL):\n   • Stores ordinal (0, 1, 2...)\n   • Compact\n   • Fragile (order matters)\n   • Avoid!\n\n3. @Convert with AttributeConverter:\n   • Custom mapping\n   • Full control",
      "explanation": "Always use STRING for enums. ORDINAL breaks if enum order changes. Use converters for complex cases.",
      "difficulty": "Easy",
      "code": "// 1. Enum definition\npublic enum UserStatus {\n    ACTIVE,\n    INACTIVE,\n    SUSPENDED,\n    DELETED\n}\n\npublic enum OrderStatus {\n    PENDING(\"P\", \"Pending\"),\n    CONFIRMED(\"C\", \"Confirmed\"),\n    SHIPPED(\"S\", \"Shipped\"),\n    DELIVERED(\"D\", \"Delivered\"),\n    CANCELLED(\"X\", \"Cancelled\");\n    \n    private final String code;\n    private final String description;\n    \n    OrderStatus(String code, String description) {\n        this.code = code;\n        this.description = description;\n    }\n    \n    public String getCode() { return code; }\n    public String getDescription() { return description; }\n    \n    public static OrderStatus fromCode(String code) {\n        return Arrays.stream(values())\n            .filter(s -> s.code.equals(code))\n            .findFirst()\n            .orElseThrow(() -> new IllegalArgumentException(\n                \"Invalid status code: \" + code\n            ));\n    }\n}\n\n// 2. Entity with STRING enum (recommended)\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    @Enumerated(EnumType.STRING)\n    @Column(length = 20)\n    private UserStatus status;\n    // Stores: \"ACTIVE\", \"INACTIVE\", etc.\n}\n\n// 3. Entity with ORDINAL enum (avoid!)\n@Entity\npublic class BadExample {\n    @Enumerated(EnumType.ORDINAL)\n    private UserStatus status;\n    // Stores: 0, 1, 2, 3\n    // PROBLEM: If enum order changes, data corrupted!\n}\n\n// 4. Custom converter for complex enums\n@Converter(autoApply = true)\npublic class OrderStatusConverter \n        implements AttributeConverter<OrderStatus, String> {\n    \n    @Override\n    public String convertToDatabaseColumn(OrderStatus status) {\n        if (status == null) {\n            return null;\n        }\n        return status.getCode();\n    }\n    \n    @Override\n    public OrderStatus convertToEntityAttribute(String code) {\n        if (code == null) {\n            return null;\n        }\n        return OrderStatus.fromCode(code);\n    }\n}\n\n@Entity\npublic class Order {\n    @Id\n    private Long id;\n    \n    @Convert(converter = OrderStatusConverter.class)\n    private OrderStatus status;\n    // Stores: \"P\", \"C\", \"S\", \"D\", \"X\"\n}\n\n// 5. Repository queries with enums\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    List<User> findByStatus(UserStatus status);\n    \n    @Query(\"SELECT u FROM User u WHERE u.status IN :statuses\")\n    List<User> findByStatuses(@Param(\"statuses\") List<UserStatus> statuses);\n    \n    @Query(\"SELECT u FROM User u WHERE u.status = :status \" +\n           \"AND u.createdDate > :date\")\n    List<User> findByStatusAndDate(\n        @Param(\"status\") UserStatus status,\n        @Param(\"date\") LocalDateTime date\n    );\n}\n\n// 6. Service usage\n@Service\npublic class UserService {\n    public void demonstrateEnums() {\n        User user = new User();\n        user.setStatus(UserStatus.ACTIVE);\n        userRepository.save(user);\n        \n        // Query by enum\n        List<User> activeUsers = userRepository.findByStatus(UserStatus.ACTIVE);\n        \n        // Multiple statuses\n        List<User> users = userRepository.findByStatuses(\n            Arrays.asList(UserStatus.ACTIVE, UserStatus.SUSPENDED)\n        );\n    }\n}"
    },
    {
      "id": 34,
      "question": "What are AttributeConverters and how to use them?",
      "answer": "AttributeConverter for custom type mapping:\n\nFeatures:\n• Convert entity attribute to DB column\n• Bidirectional conversion\n• Type-safe\n• Reusable\n• Auto-apply option\n\nUse cases:\n• Custom types (Money, Email)\n• Enum with values\n• Encryption\n• JSON columns",
      "explanation": "AttributeConverters allow custom mapping between Java types and database columns, encapsulating conversion logic.",
      "difficulty": "Medium",
      "code": "// 1. Simple converter\n@Converter\npublic class BooleanToYNConverter \n        implements AttributeConverter<Boolean, String> {\n    \n    @Override\n    public String convertToDatabaseColumn(Boolean value) {\n        if (value == null) {\n            return null;\n        }\n        return value ? \"Y\" : \"N\";\n    }\n    \n    @Override\n    public Boolean convertToEntityAttribute(String dbData) {\n        if (dbData == null) {\n            return null;\n        }\n        return \"Y\".equals(dbData);\n    }\n}\n\n// 2. JSON converter\n@Converter\npublic class JsonConverter \n        implements AttributeConverter<Map<String, Object>, String> {\n    \n    private final ObjectMapper objectMapper = new ObjectMapper();\n    \n    @Override\n    public String convertToDatabaseColumn(Map<String, Object> attribute) {\n        try {\n            return objectMapper.writeValueAsString(attribute);\n        } catch (JsonProcessingException e) {\n            throw new RuntimeException(\"Error converting to JSON\", e);\n        }\n    }\n    \n    @Override\n    public Map<String, Object> convertToEntityAttribute(String dbData) {\n        try {\n            return objectMapper.readValue(dbData, \n                new TypeReference<Map<String, Object>>() {});\n        } catch (IOException e) {\n            throw new RuntimeException(\"Error parsing JSON\", e);\n        }\n    }\n}\n\n// 3. Encryption converter\n@Converter\npublic class CryptoConverter \n        implements AttributeConverter<String, String> {\n    \n    @Autowired\n    private EncryptionService encryptionService;\n    \n    @Override\n    public String convertToDatabaseColumn(String attribute) {\n        if (attribute == null) {\n            return null;\n        }\n        return encryptionService.encrypt(attribute);\n    }\n    \n    @Override\n    public String convertToEntityAttribute(String dbData) {\n        if (dbData == null) {\n            return null;\n        }\n        return encryptionService.decrypt(dbData);\n    }\n}\n\n// 4. Entity using converters\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String name;\n    \n    // Manual converter application\n    @Convert(converter = BooleanToYNConverter.class)\n    private Boolean active;\n    \n    // Encrypted field\n    @Convert(converter = CryptoConverter.class)\n    private String ssn;\n    \n    // JSON field\n    @Convert(converter = JsonConverter.class)\n    @Column(columnDefinition = \"TEXT\")\n    private Map<String, Object> metadata;\n}\n\n// 5. Auto-apply converter\n@Converter(autoApply = true)\npublic class LocalDateTimeConverter \n        implements AttributeConverter<LocalDateTime, Timestamp> {\n    \n    @Override\n    public Timestamp convertToDatabaseColumn(LocalDateTime locDateTime) {\n        return locDateTime == null ? null : Timestamp.valueOf(locDateTime);\n    }\n    \n    @Override\n    public LocalDateTime convertToEntityAttribute(Timestamp sqlTimestamp) {\n        return sqlTimestamp == null ? null : sqlTimestamp.toLocalDateTime();\n    }\n}\n// With autoApply=true, applied to ALL LocalDateTime fields automatically\n\n// 6. List converter\n@Converter\npublic class StringListConverter \n        implements AttributeConverter<List<String>, String> {\n    \n    private static final String DELIMITER = \",\";\n    \n    @Override\n    public String convertToDatabaseColumn(List<String> list) {\n        if (list == null || list.isEmpty()) {\n            return null;\n        }\n        return String.join(DELIMITER, list);\n    }\n    \n    @Override\n    public List<String> convertToEntityAttribute(String joined) {\n        if (joined == null || joined.isEmpty()) {\n            return new ArrayList<>();\n        }\n        return Arrays.asList(joined.split(DELIMITER));\n    }\n}\n\n@Entity\npublic class Product {\n    @Id\n    private Long id;\n    \n    @Convert(converter = StringListConverter.class)\n    private List<String> tags;\n    // Stores: \"electronics,mobile,smartphone\"\n}"
    },
    {
      "id": 35,
      "question": "How do you implement multi-tenancy in Spring Data JPA?",
      "answer": "Multi-tenancy strategies:\n\n1. Separate Database:\n   • Database per tenant\n   • Complete isolation\n   • Complex management\n\n2. Separate Schema:\n   • Schema per tenant\n   • Same database\n   • Good isolation\n\n3. Discriminator Column:\n   • Shared tables\n   • tenant_id column\n   • Simple, less isolated\n\n4. Hibernate MultiTenancy support",
      "explanation": "Multi-tenancy allows serving multiple tenants from single application. Choose strategy based on isolation needs.",
      "difficulty": "Hard",
      "code": "// Strategy 1: Discriminator Column (Shared Database)\n\n// 1. Tenant context holder\npublic class TenantContext {\n    private static ThreadLocal<String> currentTenant = new ThreadLocal<>();\n    \n    public static void setTenantId(String tenantId) {\n        currentTenant.set(tenantId);\n    }\n    \n    public static String getTenantId() {\n        return currentTenant.get();\n    }\n    \n    public static void clear() {\n        currentTenant.remove();\n    }\n}\n\n// 2. Base entity with tenant\n@MappedSuperclass\npublic abstract class TenantAware {\n    @Column(name = \"tenant_id\")\n    private String tenantId;\n    \n    @PrePersist\n    public void prePersist() {\n        this.tenantId = TenantContext.getTenantId();\n    }\n}\n\n@Entity\n@FilterDef(name = \"tenantFilter\", \n           parameters = @ParamDef(name = \"tenantId\", type = \"string\"))\n@Filter(name = \"tenantFilter\", \n        condition = \"tenant_id = :tenantId\")\npublic class User extends TenantAware {\n    @Id\n    @GeneratedValue\n    private Long id;\n    private String name;\n}\n\n// 3. Tenant filter interceptor\n@Component\npublic class TenantInterceptor implements HandlerInterceptor {\n    \n    @Override\n    public boolean preHandle(HttpServletRequest request,\n                           HttpServletResponse response,\n                           Object handler) {\n        String tenantId = request.getHeader(\"X-Tenant-ID\");\n        if (tenantId == null) {\n            throw new IllegalArgumentException(\"Tenant ID required\");\n        }\n        TenantContext.setTenantId(tenantId);\n        return true;\n    }\n    \n    @Override\n    public void afterCompletion(HttpServletRequest request,\n                               HttpServletResponse response,\n                               Object handler, Exception ex) {\n        TenantContext.clear();\n    }\n}\n\n// 4. Repository aspect to enable filter\n@Aspect\n@Component\npublic class TenantFilterAspect {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Before(\"execution(* com.example.repository..*.*(..))\")\n    public void enableTenantFilter() {\n        String tenantId = TenantContext.getTenantId();\n        if (tenantId != null) {\n            Filter filter = entityManager.unwrap(Session.class)\n                .enableFilter(\"tenantFilter\");\n            filter.setParameter(\"tenantId\", tenantId);\n        }\n    }\n}\n\n// Strategy 2: Separate Schema/Database\n\n// 5. Tenant data source configuration\n@Configuration\npublic class MultiTenantConfiguration {\n    \n    @Bean\n    public DataSource dataSource() {\n        return new TenantRoutingDataSource();\n    }\n}\n\npublic class TenantRoutingDataSource \n        extends AbstractRoutingDataSource {\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return TenantContext.getTenantId();\n    }\n}\n\n// 6. Dynamic data source management\n@Service\npublic class TenantDataSourceService {\n    \n    private Map<String, DataSource> dataSources = new ConcurrentHashMap<>();\n    \n    public void addTenant(String tenantId, DataSourceProperties properties) {\n        DataSourceBuilder<?> builder = DataSourceBuilder.create();\n        builder.url(properties.getUrl());\n        builder.username(properties.getUsername());\n        builder.password(properties.getPassword());\n        \n        DataSource dataSource = builder.build();\n        dataSources.put(tenantId, dataSource);\n    }\n    \n    public DataSource getDataSource(String tenantId) {\n        return dataSources.get(tenantId);\n    }\n}\n\n// 7. Service with tenant awareness\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional\n    public User createUser(User user) {\n        // tenantId automatically set via @PrePersist\n        // Filter automatically applied via aspect\n        return userRepository.save(user);\n    }\n    \n    @Transactional(readOnly = true)\n    public List<User> getAllUsers() {\n        // Only returns users for current tenant\n        return userRepository.findAll();\n    }\n}"
    },
    {
      "id": 36,
      "question": "How do you implement query hints in Spring Data JPA?",
      "answer": "Query hints optimize query execution:\n\nCommon hints:\n• javax.persistence.query.timeout\n• javax.persistence.lock.timeout\n• javax.persistence.fetchgraph\n• javax.persistence.loadgraph\n• org.hibernate.cacheable\n• org.hibernate.fetchSize\n• org.hibernate.readOnly\n• org.hibernate.comment\n\nUse @QueryHints annotation.",
      "explanation": "Query hints provide execution metadata to JPA provider (Hibernate). Used for optimization and configuration.",
      "difficulty": "Medium",
      "code": "public interface UserRepository extends JpaRepository<User, Long> {\n    \n    // 1. Query timeout\n    @QueryHints(@QueryHint(\n        name = \"javax.persistence.query.timeout\", \n        value = \"5000\" // milliseconds\n    ))\n    @Query(\"SELECT u FROM User u WHERE u.status = :status\")\n    List<User> findByStatus(@Param(\"status\") String status);\n    \n    // 2. Read-only hint (performance optimization)\n    @QueryHints(@QueryHint(\n        name = \"org.hibernate.readOnly\", \n        value = \"true\"\n    ))\n    List<User> findByAge(int age);\n    // Entities not tracked in persistence context\n    \n    // 3. Fetch size hint\n    @QueryHints(@QueryHint(\n        name = \"org.hibernate.fetchSize\", \n        value = \"50\"\n    ))\n    @Query(\"SELECT u FROM User u\")\n    List<User> findAllWithFetchSize();\n    \n    // 4. Cache hint\n    @QueryHints({\n        @QueryHint(\n            name = \"org.hibernate.cacheable\", \n            value = \"true\"\n        ),\n        @QueryHint(\n            name = \"org.hibernate.cacheRegion\", \n            value = \"users\"\n        )\n    })\n    List<User> findByEmailContaining(String email);\n    \n    // 5. Comment hint (for SQL logging/tracing)\n    @QueryHints(@QueryHint(\n        name = \"org.hibernate.comment\", \n        value = \"Finding active users for dashboard\"\n    ))\n    @Query(\"SELECT u FROM User u WHERE u.active = true\")\n    List<User> findActiveUsers();\n    // SQL will include: /* Finding active users for dashboard */\n    \n    // 6. Flush mode hint\n    @QueryHints(@QueryHint(\n        name = \"org.hibernate.flushMode\", \n        value = \"COMMIT\"\n    ))\n    List<User> findByName(String name);\n    // Don't auto-flush before query\n    \n    // 7. Entity graph hint\n    @QueryHints(@QueryHint(\n        name = \"javax.persistence.fetchgraph\",\n        value = \"User.orders\"\n    ))\n    Optional<User> findById(Long id);\n    \n    // 8. Multiple hints\n    @QueryHints({\n        @QueryHint(name = \"javax.persistence.query.timeout\", value = \"10000\"),\n        @QueryHint(name = \"org.hibernate.readOnly\", value = \"true\"),\n        @QueryHint(name = \"org.hibernate.fetchSize\", value = \"100\"),\n        @QueryHint(name = \"org.hibernate.comment\", value = \"Heavy reporting query\")\n    })\n    @Query(\"SELECT u FROM User u JOIN FETCH u.orders WHERE u.registeredDate > :date\")\n    List<User> findRecentUsersWithOrders(@Param(\"date\") LocalDate date);\n}\n\n// 9. Programmatic hints with EntityManager\n@Repository\npublic class CustomUserRepository {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<User> findWithHints() {\n        TypedQuery<User> query = entityManager.createQuery(\n            \"SELECT u FROM User u\", User.class\n        );\n        \n        // Set hints programmatically\n        query.setHint(\"javax.persistence.query.timeout\", 5000);\n        query.setHint(\"org.hibernate.readOnly\", true);\n        query.setHint(\"org.hibernate.fetchSize\", 50);\n        query.setHint(\"org.hibernate.comment\", \"Custom query with hints\");\n        \n        return query.getResultList();\n    }\n    \n    public List<User> findWithLockTimeout(Long id) {\n        Map<String, Object> hints = new HashMap<>();\n        hints.put(\"javax.persistence.lock.timeout\", 5000);\n        \n        User user = entityManager.find(\n            User.class, \n            id, \n            LockModeType.PESSIMISTIC_WRITE,\n            hints\n        );\n        \n        return List.of(user);\n    }\n}\n\n// 10. Configuration hints\n@Configuration\npublic class HibernateConfig {\n    \n    @Bean\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory() {\n        LocalContainerEntityManagerFactoryBean em = \n            new LocalContainerEntityManagerFactoryBean();\n        \n        Properties properties = new Properties();\n        // Global hints\n        properties.put(\"hibernate.query.default_flush_mode\", \"COMMIT\");\n        properties.put(\"hibernate.jdbc.fetch_size\", 20);\n        properties.put(\"hibernate.jdbc.batch_size\", 20);\n        \n        em.setJpaProperties(properties);\n        return em;\n    }\n}"
    },
    {
      "id": 37,
      "question": "What is @Formula annotation and how to use it?",
      "answer": "@Formula for calculated/derived fields:\n\nFeatures:\n• SQL expression as field\n• Calculated at load time\n• Read-only\n• No database column needed\n• Can use SQL functions\n• Joins other tables\n\nUse for:\n• Derived values\n• Aggregates\n• Concatenations",
      "explanation": "@Formula allows defining fields calculated by SQL expressions instead of stored columns.",
      "difficulty": "Medium",
      "code": "@Entity\npublic class User {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String firstName;\n    private String lastName;\n    private LocalDate birthDate;\n    \n    // 1. Simple concatenation\n    @Formula(\"CONCAT(first_name, ' ', last_name)\")\n    private String fullName;\n    \n    // 2. Calculation\n    @Formula(\"YEAR(CURRENT_DATE) - YEAR(birth_date)\")\n    private Integer age;\n    \n    // 3. Conditional expression\n    @Formula(\"CASE WHEN birth_date < DATE_SUB(CURRENT_DATE, INTERVAL 18 YEAR) \" +\n             \"THEN 'ADULT' ELSE 'MINOR' END\")\n    private String ageGroup;\n    \n    // 4. Subquery for aggregate\n    @Formula(\"(SELECT COUNT(*) FROM orders o WHERE o.user_id = id)\")\n    private Long orderCount;\n    \n    // 5. Subquery for sum\n    @Formula(\"(SELECT COALESCE(SUM(o.amount), 0) FROM orders o WHERE o.user_id = id)\")\n    private BigDecimal totalSpent;\n    \n    // 6. Complex calculation\n    @Formula(\"(SELECT AVG(o.amount) FROM orders o \" +\n             \"WHERE o.user_id = id AND o.status = 'COMPLETED')\")\n    private BigDecimal averageOrderValue;\n    \n    // Getters (no setters for formula fields)\n}\n\n@Entity\npublic class Order {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private BigDecimal baseAmount;\n    private BigDecimal taxRate;\n    \n    // Calculate total with tax\n    @Formula(\"base_amount * (1 + tax_rate / 100)\")\n    private BigDecimal totalAmount;\n    \n    // Discount percentage\n    @Formula(\"CASE \" +\n             \"WHEN base_amount > 1000 THEN 10 \" +\n             \"WHEN base_amount > 500 THEN 5 \" +\n             \"ELSE 0 END\")\n    private Integer discountPercentage;\n}\n\n@Entity\npublic class Product {\n    @Id\n    private Long id;\n    \n    private String name;\n    private BigDecimal price;\n    private Integer stockQuantity;\n    \n    // Stock status\n    @Formula(\"CASE \" +\n             \"WHEN stock_quantity = 0 THEN 'OUT_OF_STOCK' \" +\n             \"WHEN stock_quantity < 10 THEN 'LOW_STOCK' \" +\n             \"ELSE 'IN_STOCK' END\")\n    private String stockStatus;\n    \n    // Rating from reviews\n    @Formula(\"(SELECT AVG(r.rating) FROM reviews r WHERE r.product_id = id)\")\n    private Double averageRating;\n    \n    // Review count\n    @Formula(\"(SELECT COUNT(*) FROM reviews r WHERE r.product_id = id)\")\n    private Long reviewCount;\n}\n\n// Repository queries\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // Query using formula field\n    @Query(\"SELECT u FROM User u WHERE u.age >= :minAge\")\n    List<User> findAdults(@Param(\"minAge\") int minAge);\n    \n    // Order by formula field\n    @Query(\"SELECT u FROM User u ORDER BY u.totalSpent DESC\")\n    List<User> findTopSpenders(Pageable pageable);\n}\n\n// Important notes:\n/*\n * 1. Formula fields are ALWAYS calculated on load\n * 2. Cannot query formula fields with criteria API\n * 3. Database-specific SQL (portability issue)\n * 4. Performance impact for complex formulas\n * 5. Cannot use in WHERE clause of query methods\n * 6. Can use in JPQL SELECT and ORDER BY\n */"
    },
    {
      "id": 38,
      "question": "How do you implement dynamic sorting in Spring Data JPA?",
      "answer": "Dynamic sorting for flexible queries:\n\nApproaches:\n1. Sort parameter in methods\n2. Pageable with sort\n3. @QuerydslPredicate\n4. Specifications\n5. Criteria API\n\nFeatures:\n• Multiple sort fields\n• ASC/DESC direction\n• Null handling\n• Case sensitivity",
      "explanation": "Spring Data JPA provides flexible sorting through Sort and Pageable abstractions.",
      "difficulty": "Easy",
      "code": "// 1. Repository with Sort parameter\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // Simple sort\n    List<User> findByStatus(String status, Sort sort);\n    \n    // With pagination\n    Page<User> findByAge(int age, Pageable pageable);\n    \n    // Query with sort\n    @Query(\"SELECT u FROM User u WHERE u.active = true\")\n    List<User> findActiveUsers(Sort sort);\n}\n\n// 2. Service with dynamic sorting\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n    \n    public List<User> getUsers(String sortBy, String direction) {\n        Sort sort = Sort.by(\n            \"DESC\".equals(direction) ? \n                Sort.Direction.DESC : Sort.Direction.ASC,\n            sortBy\n        );\n        return userRepository.findAll(sort);\n    }\n    \n    // Multiple sort fields\n    public List<User> getUsersSorted() {\n        Sort sort = Sort.by(\n            Sort.Order.desc(\"createdDate\"),\n            Sort.Order.asc(\"name\")\n        );\n        return userRepository.findAll(sort);\n    }\n    \n    // Null handling\n    public List<User> getUsersWithNullHandling() {\n        Sort sort = Sort.by(\n            Sort.Order.asc(\"lastLogin\")\n                .nullsLast()\n        );\n        return userRepository.findAll(sort);\n    }\n    \n    // Case-insensitive sorting\n    public List<User> getUsersCaseInsensitive() {\n        Sort sort = Sort.by(\n            Sort.Order.asc(\"name\")\n                .ignoreCase()\n        );\n        return userRepository.findAll(sort);\n    }\n}\n\n// 3. Controller with dynamic sorting\n@RestController\n@RequestMapping(\"/api/users\")\npublic class UserController {\n    @Autowired\n    private UserService userService;\n    \n    // Using @SortDefault\n    @GetMapping\n    public List<User> getUsers(\n            @SortDefault(sort = \"name\", direction = Sort.Direction.ASC) \n            Sort sort) {\n        return userRepository.findAll(sort);\n    }\n    \n    // Custom sort parsing\n    @GetMapping(\"/search\")\n    public Page<User> searchUsers(\n            @RequestParam(required = false) String status,\n            @RequestParam(defaultValue = \"0\") int page,\n            @RequestParam(defaultValue = \"10\") int size,\n            @RequestParam(defaultValue = \"id\") String sortBy,\n            @RequestParam(defaultValue = \"asc\") String direction) {\n        \n        Sort sort = Sort.by(\n            \"desc\".equalsIgnoreCase(direction) ? \n                Sort.Direction.DESC : Sort.Direction.ASC,\n            sortBy\n        );\n        \n        Pageable pageable = PageRequest.of(page, size, sort);\n        return userRepository.findByStatus(status, pageable);\n    }\n    \n    // Multiple sort parameters\n    @GetMapping(\"/advanced\")\n    public Page<User> advancedSearch(\n            @RequestParam(required = false) List<String> sortFields,\n            @RequestParam(required = false) List<String> sortDirections,\n            Pageable pageable) {\n        \n        if (sortFields != null && !sortFields.isEmpty()) {\n            List<Sort.Order> orders = new ArrayList<>();\n            \n            for (int i = 0; i < sortFields.size(); i++) {\n                String field = sortFields.get(i);\n                String direction = (sortDirections != null && \n                                   i < sortDirections.size()) ?\n                    sortDirections.get(i) : \"asc\";\n                \n                orders.add(\"desc\".equalsIgnoreCase(direction) ?\n                    Sort.Order.desc(field) : Sort.Order.asc(field));\n            }\n            \n            Sort sort = Sort.by(orders);\n            pageable = PageRequest.of(\n                pageable.getPageNumber(),\n                pageable.getPageSize(),\n                sort\n            );\n        }\n        \n        return userRepository.findAll(pageable);\n    }\n}\n\n// 4. Sort validation\n@Component\npublic class SortValidator {\n    \n    private static final Set<String> ALLOWED_SORT_FIELDS = Set.of(\n        \"id\", \"name\", \"email\", \"createdDate\", \"status\"\n    );\n    \n    public Sort validateAndCreateSort(String sortBy, String direction) {\n        if (!ALLOWED_SORT_FIELDS.contains(sortBy)) {\n            throw new IllegalArgumentException(\n                \"Invalid sort field: \" + sortBy\n            );\n        }\n        \n        Sort.Direction dir = \"desc\".equalsIgnoreCase(direction) ?\n            Sort.Direction.DESC : Sort.Direction.ASC;\n        \n        return Sort.by(dir, sortBy);\n    }\n}\n\n// Usage in URL:\n// GET /api/users?sort=name,asc\n// GET /api/users?sort=createdDate,desc&sort=name,asc\n// GET /api/users?page=0&size=20&sortBy=age&direction=desc"
    },
    {
      "id": 39,
      "question": "How do you implement database sequences in JPA?",
      "answer": "ID generation strategies:\n\n1. GenerationType.AUTO:\n   • Provider chooses\n   • Default\n\n2. GenerationType.IDENTITY:\n   • Auto-increment\n   • DB generates\n   • No batching\n\n3. GenerationType.SEQUENCE:\n   • Uses DB sequence\n   • Efficient\n   • Pre-allocation\n\n4. GenerationType.TABLE:\n   • Sequence table\n   • Portable\n   • Slower",
      "explanation": "Sequences are efficient for ID generation. SEQUENCE is preferred over IDENTITY for batch operations.",
      "difficulty": "Medium",
      "code": "// 1. Default AUTO strategy\n@Entity\npublic class User {\n    @Id\n    @GeneratedValue // AUTO by default\n    private Long id;\n}\n\n// 2. IDENTITY strategy (MySQL/PostgreSQL auto_increment)\n@Entity\npublic class Product {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    // Pros: Simple, DB handles it\n    // Cons: Breaks batch inserts, ID not known until flush\n}\n\n// 3. SEQUENCE strategy with default sequence\n@Entity\npublic class Order {\n    @Id\n    @GeneratedValue(strategy = GenerationType.SEQUENCE)\n    private Long id;\n    // Uses default sequence: hibernate_sequence\n}\n\n// 4. SEQUENCE with custom sequence\n@Entity\npublic class Customer {\n    @Id\n    @GeneratedValue(\n        strategy = GenerationType.SEQUENCE,\n        generator = \"customer_seq_generator\"\n    )\n    @SequenceGenerator(\n        name = \"customer_seq_generator\",\n        sequenceName = \"customer_sequence\",\n        initialValue = 1000,\n        allocationSize = 50\n    )\n    private Long id;\n    // Sequence starts at 1000\n    // Pre-allocates 50 IDs at once (performance)\n}\n\n// 5. TABLE strategy (portable but slower)\n@Entity\npublic class Invoice {\n    @Id\n    @GeneratedValue(\n        strategy = GenerationType.TABLE,\n        generator = \"invoice_gen\"\n    )\n    @TableGenerator(\n        name = \"invoice_gen\",\n        table = \"id_generator\",\n        pkColumnName = \"gen_name\",\n        valueColumnName = \"gen_value\",\n        pkColumnValue = \"invoice_id\",\n        initialValue = 1,\n        allocationSize = 10\n    )\n    private Long id;\n}\n\n// 6. Custom generator\npublic class CustomIdGenerator implements IdentifierGenerator {\n    \n    @Override\n    public Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        String prefix = \"USR\";\n        \n        String query = \"SELECT MAX(CAST(SUBSTRING(id, 4) AS UNSIGNED)) \" +\n                      \"FROM user\";\n        \n        Long maxId = (Long) session.createNativeQuery(query)\n            .uniqueResult();\n        \n        long nextId = (maxId != null) ? maxId + 1 : 1;\n        \n        return prefix + String.format(\"%08d\", nextId);\n    }\n}\n\n@Entity\npublic class User {\n    @Id\n    @GeneratedValue(generator = \"custom_id\")\n    @GenericGenerator(\n        name = \"custom_id\",\n        strategy = \"com.example.CustomIdGenerator\"\n    )\n    private String id; // USR00000001, USR00000002, ...\n}\n\n// 7. UUID generator\n@Entity\npublic class Document {\n    @Id\n    @GeneratedValue(generator = \"uuid2\")\n    @GenericGenerator(\n        name = \"uuid2\",\n        strategy = \"uuid2\"\n    )\n    @Column(columnDefinition = \"BINARY(16)\")\n    private UUID id;\n}\n\n// 8. Composite key with sequence\n@Entity\npublic class OrderItem {\n    @EmbeddedId\n    private OrderItemId id;\n    \n    @PrePersist\n    public void generateId() {\n        if (id == null) {\n            id = new OrderItemId();\n        }\n        if (id.getItemSequence() == null) {\n            // Generate sequence part\n            id.setItemSequence(generateSequence());\n        }\n    }\n    \n    private Long generateSequence() {\n        // Custom logic\n        return System.currentTimeMillis();\n    }\n}\n\n@Embeddable\npublic class OrderItemId implements Serializable {\n    private Long orderId;\n    private Long itemSequence;\n}\n\n// 9. Creating sequence in database\n// PostgreSQL:\n// CREATE SEQUENCE customer_sequence START 1000 INCREMENT 50;\n\n// Oracle:\n// CREATE SEQUENCE customer_sequence\n//   START WITH 1000\n//   INCREMENT BY 50\n//   CACHE 20;\n\n// 10. Configuration comparison\n/*\n * IDENTITY:\n * - Best for: Single inserts\n * - Avoid for: Batch operations\n * - Databases: MySQL, PostgreSQL, SQL Server\n * \n * SEQUENCE:\n * - Best for: Batch operations, performance\n * - Avoid for: MySQL < 8.0\n * - Databases: PostgreSQL, Oracle, DB2\n * \n * TABLE:\n * - Best for: Database portability\n * - Avoid for: High performance needs\n * - Databases: All\n * \n * UUID:\n * - Best for: Distributed systems, no central sequence\n * - Avoid for: Performance-critical (larger keys)\n * - Databases: All\n */"
    },
    {
      "id": 40,
      "question": "How do you implement native queries in Spring Data JPA?",
      "answer": "Native SQL queries for database-specific features:\n\nFeatures:\n• Direct SQL execution\n• Database-specific syntax\n• Stored procedures\n• Complex queries\n• Raw result mapping\n\nUse when:\n• JPA limitations\n• Performance optimization\n• Legacy database\n• Database-specific features",
      "explanation": "Native queries bypass JPA abstraction, allowing direct SQL. Use for complex or database-specific operations.",
      "difficulty": "Medium",
      "code": "public interface UserRepository extends JpaRepository<User, Long> {\n    \n    // 1. Simple native query\n    @Query(value = \"SELECT * FROM users WHERE status = ?1\", \n           nativeQuery = true)\n    List<User> findByStatusNative(String status);\n    \n    // 2. Named parameters\n    @Query(value = \"SELECT * FROM users WHERE name LIKE %:name% \" +\n                   \"AND age > :age\",\n           nativeQuery = true)\n    List<User> searchUsers(@Param(\"name\") String name, \n                          @Param(\"age\") int age);\n    \n    // 3. Projection with native query\n    @Query(value = \"SELECT u.id, u.name, u.email FROM users u \" +\n                   \"WHERE u.created_date > :date\",\n           nativeQuery = true)\n    List<Object[]> findUserProjection(@Param(\"date\") LocalDate date);\n    \n    // 4. Interface projection\n    @Query(value = \"SELECT u.id as id, u.name as name, u.email as email \" +\n                   \"FROM users u WHERE u.age > :age\",\n           nativeQuery = true)\n    List<UserProjection> findUserInfo(@Param(\"age\") int age);\n    \n    // 5. Modifying native query\n    @Modifying\n    @Query(value = \"UPDATE users SET last_login = NOW() WHERE id = :id\",\n           nativeQuery = true)\n    void updateLastLogin(@Param(\"id\") Long id);\n    \n    // 6. Pagination with native query\n    @Query(value = \"SELECT * FROM users WHERE status = :status\",\n           countQuery = \"SELECT COUNT(*) FROM users WHERE status = :status\",\n           nativeQuery = true)\n    Page<User> findByStatusPaged(\n        @Param(\"status\") String status,\n        Pageable pageable\n    );\n    \n    // 7. Complex join query\n    @Query(value = \n        \"SELECT u.*, COUNT(o.id) as order_count, SUM(o.amount) as total_amount \" +\n        \"FROM users u \" +\n        \"LEFT JOIN orders o ON u.id = o.user_id \" +\n        \"WHERE o.created_date > :date \" +\n        \"GROUP BY u.id \" +\n        \"HAVING COUNT(o.id) > :minOrders\",\n        nativeQuery = true)\n    List<Object[]> findUsersWithOrderStats(\n        @Param(\"date\") LocalDate date,\n        @Param(\"minOrders\") int minOrders\n    );\n    \n    // 8. Database-specific function\n    @Query(value = \n        \"SELECT * FROM users \" +\n        \"WHERE MATCH(name, bio) AGAINST(:searchTerm IN BOOLEAN MODE)\",\n        nativeQuery = true)\n    List<User> fullTextSearch(@Param(\"searchTerm\") String searchTerm);\n}\n\n// 9. Interface for projection\npublic interface UserProjection {\n    Long getId();\n    String getName();\n    String getEmail();\n}\n\n// 10. Named native query in entity\n@Entity\n@NamedNativeQueries({\n    @NamedNativeQuery(\n        name = \"User.findByStatusNamed\",\n        query = \"SELECT * FROM users WHERE status = :status\",\n        resultClass = User.class\n    ),\n    @NamedNativeQuery(\n        name = \"User.findUserStats\",\n        query = \"SELECT u.id, u.name, COUNT(o.id) as orderCount \" +\n                \"FROM users u LEFT JOIN orders o ON u.id = o.user_id \" +\n                \"GROUP BY u.id, u.name\",\n        resultSetMapping = \"UserStatsMapping\"\n    )\n})\n@SqlResultSetMapping(\n    name = \"UserStatsMapping\",\n    classes = @ConstructorResult(\n        targetClass = UserStats.class,\n        columns = {\n            @ColumnResult(name = \"id\", type = Long.class),\n            @ColumnResult(name = \"name\", type = String.class),\n            @ColumnResult(name = \"orderCount\", type = Long.class)\n        }\n    )\n)\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n    private String status;\n}\n\npublic class UserStats {\n    private Long id;\n    private String name;\n    private Long orderCount;\n    \n    public UserStats(Long id, String name, Long orderCount) {\n        this.id = id;\n        this.name = name;\n        this.orderCount = orderCount;\n    }\n}\n\n// 11. Using EntityManager for native queries\n@Repository\npublic class CustomUserRepository {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<User> executeNativeQuery(String sql, Map<String, Object> params) {\n        Query query = entityManager.createNativeQuery(sql, User.class);\n        \n        params.forEach(query::setParameter);\n        \n        return query.getResultList();\n    }\n    \n    // Stored procedure\n    @Transactional\n    public void callStoredProcedure(Long userId) {\n        StoredProcedureQuery query = entityManager\n            .createStoredProcedureQuery(\"update_user_stats\");\n        \n        query.registerStoredProcedureParameter(\n            \"user_id\", Long.class, ParameterMode.IN\n        );\n        query.registerStoredProcedureParameter(\n            \"result\", String.class, ParameterMode.OUT\n        );\n        \n        query.setParameter(\"user_id\", userId);\n        query.execute();\n        \n        String result = (String) query.getOutputParameterValue(\"result\");\n    }\n}"
    },
    {
      "id": 41,
      "question": "How do you configure @Transactional in Spring Data JPA?",
      "answer": "@Transactional manages transaction boundaries:\n\nFeatures:\n• Declarative transactions\n• Automatic commit/rollback\n• Propagation control\n• Isolation levels\n• Timeout management\n• Read-only optimization\n\nDefault behavior:\n• Commits on success\n• Rolls back on RuntimeException\n• Applied at method/class level",
      "explanation": "@Transactional provides declarative transaction management, handling commit/rollback automatically based on method outcome.",
      "difficulty": "Medium",
      "code": "// 1. Basic @Transactional usage\n@Service\npublic class UserService {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    // Simple transaction\n    @Transactional\n    public User createUser(User user) {\n        return userRepository.save(user);\n        // Auto-commit on success\n        // Auto-rollback on exception\n    }\n    \n    // Multiple operations in one transaction\n    @Transactional\n    public void processOrder(Long userId, Order order) {\n        User user = userRepository.findById(userId)\n            .orElseThrow();\n        \n        user.setLastOrderDate(LocalDateTime.now());\n        userRepository.save(user);\n        \n        order.setUser(user);\n        orderRepository.save(order);\n        \n        // Both operations committed together\n        // If any fails, both roll back\n    }\n    \n    // 2. Rollback configuration\n    @Transactional(rollbackFor = Exception.class)\n    public void createUserWithRollback(User user) {\n        userRepository.save(user);\n        // Rolls back on any Exception (checked or unchecked)\n    }\n    \n    @Transactional(noRollbackFor = CustomBusinessException.class)\n    public void createUserNoRollback(User user) {\n        userRepository.save(user);\n        // Won't rollback for CustomBusinessException\n    }\n    \n    // 3. Read-only transactions (performance optimization)\n    @Transactional(readOnly = true)\n    public List<User> getAllUsers() {\n        return userRepository.findAll();\n        // Hibernate skips dirty checking\n        // Database can optimize for read-only\n    }\n    \n    // 4. Timeout configuration\n    @Transactional(timeout = 5) // 5 seconds\n    public void slowOperation() {\n        // Throws TransactionTimedOutException if exceeds 5 seconds\n        userRepository.findAll();\n    }\n    \n    // 5. Transaction isolation level\n    @Transactional(isolation = Isolation.READ_COMMITTED)\n    public User getUserWithIsolation(Long id) {\n        return userRepository.findById(id).orElse(null);\n        // Prevents dirty reads\n        // Default is database default (usually READ_COMMITTED)\n    }\n}\n\n// 6. Class-level transaction\n@Service\n@Transactional // Applied to all public methods\npublic class OrderService {\n    \n    // This method is transactional\n    public Order createOrder(Order order) {\n        return orderRepository.save(order);\n    }\n    \n    // Override class-level with method-level\n    @Transactional(readOnly = true)\n    public List<Order> getAllOrders() {\n        return orderRepository.findAll();\n    }\n    \n    // Disable transaction for specific method\n    @Transactional(propagation = Propagation.NOT_SUPPORTED)\n    public void nonTransactionalMethod() {\n        // Executes without transaction\n    }\n}\n\n// 7. Configuration in application.properties\n/*\nspring.jpa.properties.hibernate.jdbc.batch_size=20\nspring.jpa.properties.hibernate.order_inserts=true\nspring.jpa.properties.hibernate.order_updates=true\nspring.jpa.properties.hibernate.connection.autocommit=false\n\n# Transaction timeout (global)\nspring.transaction.default-timeout=30\n*/\n\n// 8. Programmatic transaction management\n@Service\npublic class ProgrammaticTransactionService {\n    \n    @Autowired\n    private PlatformTransactionManager transactionManager;\n    \n    public void executeWithProgrammaticTransaction() {\n        TransactionDefinition def = new DefaultTransactionDefinition();\n        TransactionStatus status = transactionManager.getTransaction(def);\n        \n        try {\n            // Your transactional code\n            userRepository.save(new User());\n            \n            transactionManager.commit(status);\n        } catch (Exception e) {\n            transactionManager.rollback(status);\n            throw e;\n        }\n    }\n    \n    // Using TransactionTemplate\n    @Autowired\n    private TransactionTemplate transactionTemplate;\n    \n    public User createUserWithTemplate(User user) {\n        return transactionTemplate.execute(status -> {\n            return userRepository.save(user);\n        });\n    }\n}\n\n// 9. Transaction event listeners\n@Component\npublic class TransactionEventListener {\n    \n    @TransactionalEventListener(phase = TransactionPhase.BEFORE_COMMIT)\n    public void beforeCommit(UserCreatedEvent event) {\n        // Executed before transaction commits\n        log.info(\"About to commit user: \" + event.getUserId());\n    }\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)\n    public void afterCommit(UserCreatedEvent event) {\n        // Executed after successful commit\n        // Good for sending notifications, cache updates\n        emailService.sendWelcomeEmail(event.getUserId());\n    }\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_ROLLBACK)\n    public void afterRollback(UserCreatedEvent event) {\n        // Executed after rollback\n        log.error(\"User creation rolled back: \" + event.getUserId());\n    }\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMPLETION)\n    public void afterCompletion(UserCreatedEvent event) {\n        // Executed after commit or rollback\n        cleanupService.cleanup();\n    }\n}\n\n// 10. Common pitfalls and solutions\n@Service\npublic class TransactionPitfalls {\n    \n    @Autowired\n    private UserService userService;\n    \n    // âŒ WRONG: Self-invocation bypasses proxy\n    @Transactional\n    public void outerMethod() {\n        // Transaction starts here\n        innerMethod(); // @Transactional NOT applied!\n    }\n    \n    @Transactional\n    private void innerMethod() {\n        // This won't have a transaction\n    }\n    \n    // âœ… CORRECT: Use self-injection or separate bean\n    @Autowired\n    private ApplicationContext context;\n    \n    public void outerMethodFixed() {\n        TransactionPitfalls self = context.getBean(TransactionPitfalls.class);\n        self.innerMethod(); // Now @Transactional works\n    }\n    \n    // âŒ WRONG: Exception swallowed\n    @Transactional\n    public void wrongExceptionHandling() {\n        try {\n            userRepository.save(new User());\n        } catch (Exception e) {\n            // Transaction not rolled back!\n            log.error(\"Error\", e);\n        }\n    }\n    \n    // âœ… CORRECT: Re-throw or mark for rollback\n    @Transactional\n    public void correctExceptionHandling() {\n        try {\n            userRepository.save(new User());\n        } catch (Exception e) {\n            TransactionAspectSupport.currentTransactionStatus()\n                .setRollbackOnly();\n            log.error(\"Error\", e);\n        }\n    }\n}"
    },
    {
      "id": 42,
      "question": "What are transaction propagation types in Spring?",
      "answer": "Propagation defines transaction behavior when method calls another transactional method:\n\n1. REQUIRED: Join existing or create new (default)\n2. REQUIRES_NEW: Always create new, suspend current\n3. NESTED: Nested within existing\n4. MANDATORY: Must have existing transaction\n5. SUPPORTS: Use transaction if exists\n6. NOT_SUPPORTED: Execute without transaction\n7. NEVER: Throw exception if transaction exists",
      "explanation": "Propagation types control how transactions interact when methods call each other, crucial for complex business logic.",
      "difficulty": "Hard",
      "code": "// 1. REQUIRED (default) - Most common\n@Service\npublic class OrderService {\n    \n    @Autowired\n    private InventoryService inventoryService;\n    \n    @Transactional(propagation = Propagation.REQUIRED)\n    public void processOrder(Order order) {\n        orderRepository.save(order);\n        // Calls inventory service\n        inventoryService.updateStock(order.getProductId());\n        // Both operations in SAME transaction\n        // If inventory fails, order also rolls back\n    }\n}\n\n@Service\npublic class InventoryService {\n    \n    @Transactional(propagation = Propagation.REQUIRED)\n    public void updateStock(Long productId) {\n        Product product = productRepository.findById(productId).orElseThrow();\n        product.decrementStock();\n        productRepository.save(product);\n        // Joins existing transaction from processOrder()\n    }\n}\n\n// 2. REQUIRES_NEW - Independent transaction\n@Service\npublic class AuditService {\n    \n    @Transactional(propagation = Propagation.REQUIRES_NEW)\n    public void logAudit(String action) {\n        auditRepository.save(new AuditLog(action));\n        // Creates NEW transaction, suspends existing one\n        // Commits independently - even if caller rolls back\n    }\n}\n\n@Service\npublic class UserService {\n    \n    @Autowired\n    private AuditService auditService;\n    \n    @Transactional\n    public void deleteUser(Long userId) {\n        auditService.logAudit(\"Deleting user: \" + userId);\n        // Audit is committed immediately in separate transaction\n        \n        userRepository.deleteById(userId);\n        // If this fails, audit log remains (already committed)\n    }\n}\n\n// 3. NESTED - Savepoint within transaction\n@Service\npublic class PaymentService {\n    \n    @Autowired\n    private NotificationService notificationService;\n    \n    @Transactional(propagation = Propagation.REQUIRED)\n    public void processPayment(Payment payment) {\n        paymentRepository.save(payment);\n        \n        try {\n            // Try to send notification\n            notificationService.sendReceipt(payment);\n        } catch (Exception e) {\n            // Payment still succeeds even if notification fails\n            log.warn(\"Notification failed but payment processed\", e);\n        }\n    }\n}\n\n@Service\npublic class NotificationService {\n    \n    @Transactional(propagation = Propagation.NESTED)\n    public void sendReceipt(Payment payment) {\n        notificationRepository.save(new Notification(payment));\n        emailService.send(payment.getEmail(), \"Receipt\");\n        // Nested transaction - can rollback independently\n        // Savepoint created, rolls back to savepoint on exception\n    }\n}\n\n// 4. MANDATORY - Requires existing transaction\n@Service\npublic class ValidationService {\n    \n    @Transactional(propagation = Propagation.MANDATORY)\n    public void validateOrder(Order order) {\n        // Throws IllegalTransactionStateException if no transaction\n        if (order.getTotal() > 10000) {\n            throw new ValidationException(\"Order too large\");\n        }\n    }\n}\n\n@Service\npublic class OrderProcessingService {\n    \n    @Autowired\n    private ValidationService validationService;\n    \n    @Transactional\n    public void createOrder(Order order) {\n        validationService.validateOrder(order); // OK - transaction exists\n        orderRepository.save(order);\n    }\n    \n    public void directValidation(Order order) {\n        validationService.validateOrder(order); // ERROR - no transaction\n    }\n}\n\n// 5. SUPPORTS - Optional transaction\n@Service\npublic class ReportService {\n    \n    @Transactional(propagation = Propagation.SUPPORTS)\n    public List<Order> generateReport() {\n        // If called within transaction, uses it\n        // If called without transaction, executes without one\n        return orderRepository.findAll();\n    }\n}\n\n// 6. NOT_SUPPORTED - No transaction needed\n@Service\npublic class CacheService {\n    \n    @Transactional(propagation = Propagation.NOT_SUPPORTED)\n    public void updateCache(String key, Object value) {\n        // Suspends current transaction if exists\n        // Executes without transaction\n        redisTemplate.opsForValue().set(key, value);\n        // Cache operations don't need database transaction\n    }\n}\n\n// 7. NEVER - Must not have transaction\n@Service\npublic class FileService {\n    \n    @Transactional(propagation = Propagation.NEVER)\n    public void writeToFile(String content) {\n        // Throws exception if transaction exists\n        fileWriter.write(content);\n        // File operations shouldn't be in database transaction\n    }\n}\n\n// 8. Complex scenario with multiple propagations\n@Service\npublic class ComplexBusinessService {\n    \n    @Autowired\n    private OrderService orderService;\n    \n    @Autowired\n    private AuditService auditService;\n    \n    @Autowired\n    private EmailService emailService;\n    \n    @Transactional // Transaction T1 starts\n    public void complexOperation(Order order) {\n        // Save order in T1\n        orderService.saveOrder(order); // REQUIRED - joins T1\n        \n        // Log audit in separate transaction T2\n        auditService.logAudit(\"Order created\"); // REQUIRES_NEW - T2 commits\n        \n        // Send email without transaction\n        emailService.sendConfirmation(order); // NOT_SUPPORTED - no transaction\n        \n        // If exception here, T1 rolls back but T2 already committed\n        if (order.getTotal() < 0) {\n            throw new RuntimeException(\"Invalid order\");\n        }\n        \n        // T1 commits if no exception\n    }\n}\n\n// 9. Visual transaction flow\n/*\n * REQUIRED:\n * Outer Tx: [====================]\n * Inner Tx:     [joined same]\n * \n * REQUIRES_NEW:\n * Outer Tx: [======suspended======]\n * Inner Tx:     [====new====]\n * \n * NESTED:\n * Outer Tx: [====================]\n * Inner Tx:     [nested with savepoint]\n * \n * NOT_SUPPORTED:\n * Outer Tx: [======suspended======]\n * Inner:        no transaction\n * \n * MANDATORY:\n * Outer Tx: [====================]\n * Inner:        requires outer\n * \n * SUPPORTS:\n * With Tx:  [====================]\n * Without:  no transaction\n * \n * NEVER:\n * Must have no transaction, throws exception if exists\n */\n\n// 10. Best practices\n@Service\npublic class TransactionBestPractices {\n    \n    // âœ… Use REQUIRED for business logic (default)\n    @Transactional(propagation = Propagation.REQUIRED)\n    public void businessLogic() { }\n    \n    // âœ… Use REQUIRES_NEW for audit logs\n    @Transactional(propagation = Propagation.REQUIRES_NEW)\n    public void auditLog() { }\n    \n    // âœ… Use SUPPORTS for read-only without transaction requirement\n    @Transactional(propagation = Propagation.SUPPORTS, readOnly = true)\n    public List<Entity> flexibleRead() { return null; }\n    \n    // âœ… Use MANDATORY for methods that must be called in transaction\n    @Transactional(propagation = Propagation.MANDATORY)\n    public void mustBeInTransaction() { }\n    \n    // âœ… Use NOT_SUPPORTED for operations that shouldn't be transactional\n    @Transactional(propagation = Propagation.NOT_SUPPORTED)\n    public void cacheOperation() { }\n}"
    },
    {
      "id": 43,
      "question": "What are transaction isolation levels in JPA?",
      "answer": "Isolation levels control concurrent transaction behavior:\n\n1. READ_UNCOMMITTED: Dirty reads possible\n2. READ_COMMITTED: No dirty reads (default)\n3. REPEATABLE_READ: No non-repeatable reads\n4. SERIALIZABLE: Complete isolation\n\nHigher isolation = Better consistency, Lower performance\n\nProblems prevented:\n• Dirty read: Uncommitted changes visible\n• Non-repeatable read: Data changes between reads\n• Phantom read: New rows appear",
      "explanation": "Isolation levels balance data consistency vs. performance by controlling visibility of concurrent transactions.",
      "difficulty": "Hard",
      "code": "// 1. Isolation level configuration\n@Service\npublic class AccountService {\n    \n    // READ_UNCOMMITTED (Level 0) - Least restrictive\n    @Transactional(isolation = Isolation.READ_UNCOMMITTED)\n    public Account getAccountDirtyRead(Long id) {\n        // Can read uncommitted changes from other transactions\n        // PROBLEM: Dirty reads possible\n        return accountRepository.findById(id).orElse(null);\n        \n        /* Example scenario:\n         * T1: Updates balance to 1000 (not committed)\n         * T2: Reads balance as 1000 (dirty read)\n         * T1: Rolls back\n         * T2: Has invalid data (1000 never existed)\n         */\n    }\n    \n    // READ_COMMITTED (Level 1) - Default in most databases\n    @Transactional(isolation = Isolation.READ_COMMITTED)\n    public Account getAccountSafeRead(Long id) {\n        // Cannot read uncommitted changes\n        // PROBLEM: Non-repeatable reads possible\n        return accountRepository.findById(id).orElse(null);\n        \n        /* Example scenario:\n         * T1: Reads balance = 500\n         * T2: Updates balance to 1000 and commits\n         * T1: Reads balance = 1000 (different value!)\n         */\n    }\n    \n    // REPEATABLE_READ (Level 2)\n    @Transactional(isolation = Isolation.REPEATABLE_READ)\n    public BigDecimal calculateTotal(Long accountId) {\n        // Same data returned for multiple reads\n        // PROBLEM: Phantom reads possible\n        \n        Account account = accountRepository.findById(accountId).orElseThrow();\n        BigDecimal balance1 = account.getBalance();\n        \n        // Some processing...\n        \n        account = accountRepository.findById(accountId).orElseThrow();\n        BigDecimal balance2 = account.getBalance();\n        \n        // balance1 == balance2 (guaranteed)\n        // But COUNT queries might return different results\n        \n        /* Example scenario:\n         * T1: SELECT COUNT(*) FROM transactions = 10\n         * T2: INSERT new transaction and commits\n         * T1: SELECT COUNT(*) FROM transactions = 11 (phantom read!)\n         */\n        \n        return balance1;\n    }\n    \n    // SERIALIZABLE (Level 3) - Most restrictive\n    @Transactional(isolation = Isolation.SERIALIZABLE)\n    public void transferMoney(Long fromId, Long toId, BigDecimal amount) {\n        // Complete isolation - transactions execute as if serial\n        // NO dirty reads, non-repeatable reads, or phantom reads\n        \n        Account from = accountRepository.findById(fromId).orElseThrow();\n        Account to = accountRepository.findById(toId).orElseThrow();\n        \n        from.setBalance(from.getBalance().subtract(amount));\n        to.setBalance(to.getBalance().add(amount));\n        \n        accountRepository.save(from);\n        accountRepository.save(to);\n        \n        // Other transactions wait until this completes\n        // SLOWEST but SAFEST\n    }\n}\n\n// 2. Demonstrating read phenomena\n@Service\npublic class IsolationDemoService {\n    \n    @Autowired\n    private AccountRepository accountRepository;\n    \n    // Dirty read example\n    public void dirtyReadScenario() {\n        // Thread 1: READ_UNCOMMITTED\n        new Thread(() -> {\n            Account account = getAccountDirtyRead(1L);\n            System.out.println(\"Balance: \" + account.getBalance());\n            // Might read uncommitted value from Thread 2\n        }).start();\n        \n        // Thread 2: Updates but hasn't committed\n        new Thread(() -> {\n            Account account = accountRepository.findById(1L).orElseThrow();\n            account.setBalance(new BigDecimal(\"9999\"));\n            accountRepository.save(account);\n            // Sleep before commit\n            Thread.sleep(1000);\n            // Rollback or commit\n        }).start();\n    }\n    \n    // Non-repeatable read example\n    @Transactional(isolation = Isolation.READ_COMMITTED)\n    public void nonRepeatableReadScenario(Long accountId) {\n        // First read\n        Account account1 = accountRepository.findById(accountId).orElseThrow();\n        BigDecimal balance1 = account1.getBalance();\n        System.out.println(\"First read: \" + balance1);\n        \n        // Another transaction updates and commits here\n        try { Thread.sleep(2000); } catch (InterruptedException e) { }\n        \n        // Second read - might be different!\n        Account account2 = accountRepository.findById(accountId).orElseThrow();\n        BigDecimal balance2 = account2.getBalance();\n        System.out.println(\"Second read: \" + balance2);\n        \n        if (!balance1.equals(balance2)) {\n            System.out.println(\"Non-repeatable read occurred!\");\n        }\n    }\n    \n    // Phantom read example\n    @Transactional(isolation = Isolation.REPEATABLE_READ)\n    public void phantomReadScenario() {\n        // First count\n        long count1 = accountRepository.count();\n        System.out.println(\"First count: \" + count1);\n        \n        // Another transaction inserts and commits here\n        try { Thread.sleep(2000); } catch (InterruptedException e) { }\n        \n        // Second count - might be different!\n        long count2 = accountRepository.count();\n        System.out.println(\"Second count: \" + count2);\n        \n        if (count1 != count2) {\n            System.out.println(\"Phantom read occurred!\");\n        }\n    }\n}\n\n// 3. Isolation comparison table\n/*\n * Level            | Dirty | Non-Repeatable | Phantom | Performance\n * ------------------|-------|----------------|---------|------------\n * READ_UNCOMMITTED | Yes   | Yes            | Yes     | Fastest\n * READ_COMMITTED   | No    | Yes            | Yes     | Fast\n * REPEATABLE_READ  | No    | No             | Yes     | Slow\n * SERIALIZABLE     | No    | No             | No      | Slowest\n */\n\n// 4. Database default isolation levels\n/*\n * PostgreSQL: READ_COMMITTED\n * MySQL: REPEATABLE_READ\n * Oracle: READ_COMMITTED\n * SQL Server: READ_COMMITTED\n * H2: READ_COMMITTED\n */\n\n// 5. Choosing the right isolation level\n@Service\npublic class IsolationChoiceService {\n    \n    // Financial transactions: SERIALIZABLE\n    @Transactional(isolation = Isolation.SERIALIZABLE)\n    public void bankTransfer(Long from, Long to, BigDecimal amount) {\n        // Critical: Must prevent all anomalies\n    }\n    \n    // Inventory management: REPEATABLE_READ\n    @Transactional(isolation = Isolation.REPEATABLE_READ)\n    public void reserveProduct(Long productId, int quantity) {\n        // Important: Quantity shouldn't change during transaction\n    }\n    \n    // User profile update: READ_COMMITTED\n    @Transactional(isolation = Isolation.READ_COMMITTED)\n    public void updateProfile(User user) {\n        // Standard: No dirty reads, but OK if data changes\n    }\n    \n    // Analytics/reporting: READ_UNCOMMITTED\n    @Transactional(\n        isolation = Isolation.READ_UNCOMMITTED,\n        readOnly = true\n    )\n    public ReportData generateApproximateReport() {\n        // Performance critical: Approximate data acceptable\n    }\n}\n\n// 6. Combining with locking\n@Service\npublic class IsolationWithLockingService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional(isolation = Isolation.SERIALIZABLE)\n    public void criticalOperation(Long accountId) {\n        // Isolation + pessimistic lock\n        Account account = entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_WRITE\n        );\n        \n        // Highest level of protection\n        account.setBalance(account.getBalance().add(new BigDecimal(\"100\")));\n    }\n}\n\n// 7. Configuration in application.properties\n/*\n# Set default isolation level\nspring.jpa.properties.hibernate.connection.isolation=2\n# 1 = READ_UNCOMMITTED\n# 2 = READ_COMMITTED (default)\n# 4 = REPEATABLE_READ\n# 8 = SERIALIZABLE\n*/\n\n// 8. Testing isolation levels\n@SpringBootTest\npublic class IsolationLevelTest {\n    \n    @Autowired\n    private AccountService accountService;\n    \n    @Test\n    public void testReadCommitted() throws InterruptedException {\n        // Create account\n        Account account = new Account();\n        account.setBalance(new BigDecimal(\"100\"));\n        accountRepository.save(account);\n        \n        CountDownLatch latch = new CountDownLatch(2);\n        \n        // Thread 1: Long running transaction\n        new Thread(() -> {\n            accountService.longRunningUpdate(account.getId());\n            latch.countDown();\n        }).start();\n        \n        Thread.sleep(100);\n        \n        // Thread 2: Read during Thread 1's transaction\n        new Thread(() -> {\n            Account read = accountService.getAccountSafeRead(account.getId());\n            // Should read old value (READ_COMMITTED)\n            assertEquals(new BigDecimal(\"100\"), read.getBalance());\n            latch.countDown();\n        }).start();\n        \n        latch.await();\n    }\n}\n\n// 9. Deadlock prevention\n@Service\npublic class DeadlockPreventionService {\n    \n    @Transactional(\n        isolation = Isolation.SERIALIZABLE,\n        timeout = 5 // Prevent indefinite wait\n    )\n    public void safeTransfer(Long from, Long to, BigDecimal amount) {\n        // Always acquire locks in same order to prevent deadlock\n        Long firstId = from < to ? from : to;\n        Long secondId = from < to ? to : from;\n        \n        Account first = accountRepository.findById(firstId).orElseThrow();\n        Account second = accountRepository.findById(secondId).orElseThrow();\n        \n        // Process transfer\n    }\n}\n\n// 10. Best practices\n/*\n * 1. Use READ_COMMITTED for most operations (default)\n * 2. Use SERIALIZABLE only for critical financial operations\n * 3. Combine with pessimistic locking for high contention\n * 4. Set timeout to prevent indefinite waits\n * 5. Test under concurrent load\n * 6. Monitor for deadlocks\n * 7. Consider optimistic locking for better performance\n * 8. Keep transactions short\n * 9. Avoid network calls within transactions\n * 10. Use read-only flag for queries\n */"
    },
    {
      "id": 44,
      "question": "How do you implement optimistic locking in JPA?",
      "answer": "Optimistic locking prevents lost updates using version field:\n\nMechanism:\n• @Version annotation on field\n• Version checked on update\n• OptimisticLockException if changed\n• No database locks\n\nBest for:\n• Low contention scenarios\n• Read-heavy applications\n• Long-running transactions\n• Better performance than pessimistic",
      "explanation": "Optimistic locking assumes conflicts are rare, checking version only at commit time. Throws exception if data changed.",
      "difficulty": "Medium",
      "code": "// 1. Basic optimistic locking\n@Entity\npublic class Product {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    \n    private BigDecimal price;\n    \n    private Integer stock;\n    \n    @Version // Optimistic lock field\n    private Long version;\n    \n    // When updating:\n    // UPDATE product SET name=?, price=?, stock=?, version=version+1\n    // WHERE id=? AND version=?\n    // If version doesn't match, OptimisticLockException thrown\n}\n\n// 2. Service with optimistic locking\n@Service\npublic class ProductService {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Transactional\n    public void updateProductPrice(Long productId, BigDecimal newPrice) {\n        Product product = productRepository.findById(productId)\n            .orElseThrow();\n        \n        // version = 1 (for example)\n        \n        product.setPrice(newPrice);\n        \n        productRepository.save(product);\n        // Executes: UPDATE product SET price=?, version=2 \n        //          WHERE id=? AND version=1\n        // If another transaction already updated (version=2),\n        // this will affect 0 rows -> OptimisticLockException\n    }\n    \n    // Handling optimistic lock exception\n    @Transactional\n    public void updateWithRetry(Long productId, BigDecimal newPrice) {\n        int maxRetries = 3;\n        int attempt = 0;\n        \n        while (attempt < maxRetries) {\n            try {\n                Product product = productRepository.findById(productId)\n                    .orElseThrow();\n                product.setPrice(newPrice);\n                productRepository.save(product);\n                return; // Success\n                \n            } catch (OptimisticLockingFailureException e) {\n                attempt++;\n                if (attempt >= maxRetries) {\n                    throw new BusinessException(\n                        \"Failed to update after \" + maxRetries + \" attempts\",\n                        e\n                    );\n                }\n                // Wait before retry\n                try {\n                    Thread.sleep(100 * attempt);\n                } catch (InterruptedException ie) {\n                    Thread.currentThread().interrupt();\n                    throw new RuntimeException(ie);\n                }\n            }\n        }\n    }\n}\n\n// 3. Different version field types\n@Entity\npublic class Document {\n    \n    @Id\n    private Long id;\n    \n    // Integer version\n    @Version\n    private Integer version;\n}\n\n@Entity\npublic class Invoice {\n    \n    @Id\n    private Long id;\n    \n    // Timestamp version\n    @Version\n    private LocalDateTime lastModified;\n    // Hibernate compares timestamp\n}\n\n@Entity\npublic class Order {\n    \n    @Id\n    private Long id;\n    \n    // Long version (most common)\n    @Version\n    @Column(nullable = false)\n    private Long version;\n}\n\n// 4. Explicit locking with EntityManager\n@Service\npublic class ExplicitLockingService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void updateWithOptimisticForceIncrement(Long productId) {\n        Product product = entityManager.find(\n            Product.class,\n            productId,\n            LockModeType.OPTIMISTIC_FORCE_INCREMENT\n        );\n        \n        // Forces version increment even if entity not modified\n        product.setName(\"Updated\");\n        \n        // Version incremented on commit\n    }\n    \n    @Transactional\n    public void updateWithOptimisticLock(Long productId) {\n        Product product = entityManager.find(\n            Product.class,\n            productId,\n            LockModeType.OPTIMISTIC\n        );\n        \n        // Version checked on commit\n        // Only incremented if entity modified\n        product.setPrice(new BigDecimal(\"99.99\"));\n    }\n    \n    // Lock after finding\n    @Transactional\n    public void lockAfterFind(Long productId) {\n        Product product = productRepository.findById(productId)\n            .orElseThrow();\n        \n        // Upgrade to optimistic lock\n        entityManager.lock(product, LockModeType.OPTIMISTIC);\n        \n        product.setStock(100);\n    }\n}\n\n// 5. Repository with locking\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    @Lock(LockModeType.OPTIMISTIC)\n    @Query(\"SELECT p FROM Product p WHERE p.id = :id\")\n    Optional<Product> findByIdWithOptimisticLock(@Param(\"id\") Long id);\n    \n    @Lock(LockModeType.OPTIMISTIC_FORCE_INCREMENT)\n    @Query(\"SELECT p FROM Product p WHERE p.category = :category\")\n    List<Product> findByCategoryWithLock(@Param(\"category\") String category);\n}\n\n// 6. Concurrent update scenario\n@Service\npublic class ConcurrentUpdateDemo {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    public void demonstrateConcurrentUpdate() {\n        // Initial state: Product(id=1, stock=100, version=1)\n        \n        // User 1: Read product\n        Product product1 = productRepository.findById(1L).orElseThrow();\n        // product1: stock=100, version=1\n        \n        // User 2: Read same product\n        Product product2 = productRepository.findById(1L).orElseThrow();\n        // product2: stock=100, version=1\n        \n        // User 1: Update stock\n        product1.setStock(90);\n        productRepository.save(product1);\n        // Success: stock=90, version=2\n        \n        // User 2: Try to update stock\n        product2.setStock(95);\n        productRepository.save(product2);\n        // OptimisticLockException! Version is 2, but User 2 has version 1\n    }\n}\n\n// 7. Global exception handler\n@ControllerAdvice\npublic class OptimisticLockingExceptionHandler {\n    \n    @ExceptionHandler(OptimisticLockingFailureException.class)\n    public ResponseEntity<ErrorResponse> handleOptimisticLock(\n            OptimisticLockingFailureException e) {\n        \n        ErrorResponse error = new ErrorResponse(\n            \"CONCURRENT_MODIFICATION\",\n            \"Data was modified by another user. Please refresh and try again.\",\n            HttpStatus.CONFLICT.value()\n        );\n        \n        return ResponseEntity\n            .status(HttpStatus.CONFLICT)\n            .body(error);\n    }\n}\n\n// 8. Testing optimistic locking\n@SpringBootTest\npublic class OptimisticLockingTest {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Autowired\n    private PlatformTransactionManager transactionManager;\n    \n    @Test\n    public void testOptimisticLockingException() {\n        // Create product\n        Product product = new Product();\n        product.setStock(100);\n        productRepository.save(product);\n        Long productId = product.getId();\n        \n        // Simulate concurrent modification\n        TransactionTemplate txTemplate = \n            new TransactionTemplate(transactionManager);\n        \n        // Transaction 1: Update stock\n        txTemplate.execute(status -> {\n            Product p = productRepository.findById(productId).orElseThrow();\n            p.setStock(90);\n            productRepository.save(p);\n            return null;\n        });\n        \n        // Transaction 2: Try to update with old version\n        Product staleProduct = productRepository.findById(productId)\n            .orElseThrow();\n        Long oldVersion = staleProduct.getVersion();\n        \n        // Modify in another transaction\n        txTemplate.execute(status -> {\n            Product p = productRepository.findById(productId).orElseThrow();\n            p.setStock(85);\n            productRepository.save(p);\n            return null;\n        });\n        \n        // This should throw OptimisticLockException\n        assertThrows(OptimisticLockingFailureException.class, () -> {\n            txTemplate.execute(status -> {\n                staleProduct.setStock(80);\n                productRepository.save(staleProduct);\n                return null;\n            });\n        });\n    }\n}\n\n// 9. Batch updates with optimistic locking\n@Service\npublic class BatchUpdateService {\n    \n    @Transactional\n    public void batchUpdatePrices(List<ProductPriceUpdate> updates) {\n        List<OptimisticLockingFailureException> failures = new ArrayList<>();\n        \n        for (ProductPriceUpdate update : updates) {\n            try {\n                Product product = productRepository\n                    .findById(update.getProductId())\n                    .orElseThrow();\n                \n                product.setPrice(update.getNewPrice());\n                productRepository.save(product);\n                \n            } catch (OptimisticLockingFailureException e) {\n                failures.add(e);\n                // Log and continue with next update\n            }\n        }\n        \n        if (!failures.isEmpty()) {\n            throw new BatchUpdateException(\n                \"Failed to update \" + failures.size() + \" products\",\n                failures\n            );\n        }\n    }\n}\n\n// 10. Best practices\n/*\n * âœ… DO:\n * • Use @Version on entity\n * • Handle OptimisticLockException gracefully\n * • Implement retry logic with exponential backoff\n * • Use for low-contention scenarios\n * • Combine with UI version display for user awareness\n * • Keep transactions short\n * • Fetch fresh data before update\n * \n * âŒ DON'T:\n * • Don't modify version field manually\n * • Don't use for high-contention scenarios (use pessimistic)\n * • Don't ignore OptimisticLockException\n * • Don't have multiple @Version fields\n * • Don't use in long-running background jobs (use pessimistic)\n * \n * When to use:\n * • Read >> Write ratio\n * • User-facing applications with \"save\" buttons\n * • RESTful APIs with entity versioning\n * • Distributed systems where locking is impractical\n */"
    },
    {
      "id": 45,
      "question": "How do you implement pessimistic locking in JPA?",
      "answer": "Pessimistic locking uses database locks to prevent concurrent access:\n\nLock Types:\n1. PESSIMISTIC_READ: Shared lock (multiple readers)\n2. PESSIMISTIC_WRITE: Exclusive lock (single user)\n3. PESSIMISTIC_FORCE_INCREMENT: Lock + version increment\n\nBest for:\n• High contention scenarios\n• Critical operations\n• Short transactions\n• When conflicts are expected",
      "explanation": "Pessimistic locking acquires database locks immediately, preventing other transactions from modifying data. Slower but guarantees no conflicts.",
      "difficulty": "Hard",
      "code": "// 1. Basic pessimistic locking\n@Service\npublic class AccountService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Autowired\n    private AccountRepository accountRepository;\n    \n    // PESSIMISTIC_WRITE - Exclusive lock\n    @Transactional\n    public void withdrawMoney(Long accountId, BigDecimal amount) {\n        Account account = entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_WRITE\n        );\n        // Database executes: SELECT ... FOR UPDATE\n        // Other transactions wait until this commits\n        \n        if (account.getBalance().compareTo(amount) < 0) {\n            throw new InsufficientFundsException();\n        }\n        \n        account.setBalance(account.getBalance().subtract(amount));\n        entityManager.persist(account);\n        // Lock released on commit\n    }\n    \n    // PESSIMISTIC_READ - Shared lock\n    @Transactional\n    public Account getAccountForRead(Long accountId) {\n        Account account = entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_READ\n        );\n        // Database executes: SELECT ... FOR SHARE (PostgreSQL)\n        // Multiple reads allowed, writes blocked\n        return account;\n    }\n    \n    // PESSIMISTIC_FORCE_INCREMENT\n    @Transactional\n    public void updateAccountWithVersionIncrement(Long accountId) {\n        Account account = entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_FORCE_INCREMENT\n        );\n        // Pessimistic lock + increments @Version field\n        account.setStatus(\"ACTIVE\");\n    }\n}\n\n// 2. Repository with pessimistic locking\npublic interface AccountRepository extends JpaRepository<Account, Long> {\n    \n    @Lock(LockModeType.PESSIMISTIC_WRITE)\n    @Query(\"SELECT a FROM Account a WHERE a.id = :id\")\n    Optional<Account> findByIdForUpdate(@Param(\"id\") Long id);\n    \n    @Lock(LockModeType.PESSIMISTIC_READ)\n    @Query(\"SELECT a FROM Account a WHERE a.userId = :userId\")\n    List<Account> findByUserIdForRead(@Param(\"userId\") Long userId);\n    \n    @Lock(LockModeType.PESSIMISTIC_WRITE)\n    @QueryHints({\n        @QueryHint(name = \"javax.persistence.lock.timeout\", value = \"5000\")\n    })\n    @Query(\"SELECT a FROM Account a WHERE a.accountNumber = :number\")\n    Optional<Account> findByAccountNumberWithTimeout(\n        @Param(\"number\") String accountNumber\n    );\n}\n\n// 3. Lock timeout configuration\n@Service\npublic class TimeoutLockingService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public Account lockWithTimeout(Long accountId) {\n        Map<String, Object> properties = new HashMap<>();\n        \n        // Timeout in milliseconds\n        properties.put(\"javax.persistence.lock.timeout\", 5000);\n        \n        // Will throw LockTimeoutException after 5 seconds\n        return entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_WRITE,\n            properties\n        );\n    }\n    \n    // NoWait - fail immediately if locked\n    @Transactional\n    public Account lockNoWait(Long accountId) {\n        Map<String, Object> properties = new HashMap<>();\n        properties.put(\"javax.persistence.lock.timeout\", 0);\n        \n        // Throws LockTimeoutException immediately if locked\n        return entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_WRITE,\n            properties\n        );\n    }\n}\n\n// 4. Money transfer with pessimistic locking\n@Service\npublic class TransferService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional(\n        isolation = Isolation.READ_COMMITTED,\n        timeout = 30\n    )\n    public void transferMoney(\n            Long fromAccountId,\n            Long toAccountId,\n            BigDecimal amount) {\n        \n        // Lock accounts in consistent order to prevent deadlock\n        Long firstId = fromAccountId < toAccountId ? \n            fromAccountId : toAccountId;\n        Long secondId = fromAccountId < toAccountId ? \n            toAccountId : fromAccountId;\n        \n        Account first = entityManager.find(\n            Account.class,\n            firstId,\n            LockModeType.PESSIMISTIC_WRITE\n        );\n        \n        Account second = entityManager.find(\n            Account.class,\n            secondId,\n            LockModeType.PESSIMISTIC_WRITE\n        );\n        \n        Account from = fromAccountId.equals(firstId) ? first : second;\n        Account to = fromAccountId.equals(firstId) ? second : first;\n        \n        if (from.getBalance().compareTo(amount) < 0) {\n            throw new InsufficientFundsException();\n        }\n        \n        from.setBalance(from.getBalance().subtract(amount));\n        to.setBalance(to.getBalance().add(amount));\n        \n        // Locks automatically released on commit\n    }\n}\n\n// 5. Lock scope configuration\n@Service\npublic class LockScopeService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void lockWithScope(Long orderId) {\n        Map<String, Object> properties = new HashMap<>();\n        \n        // NORMAL: Lock only the entity\n        properties.put(\"javax.persistence.lock.scope\", \n                      PessimisticLockScope.NORMAL);\n        \n        Order order = entityManager.find(\n            Order.class,\n            orderId,\n            LockModeType.PESSIMISTIC_WRITE,\n            properties\n        );\n        \n        // EXTENDED: Lock entity and joined tables\n        properties.put(\"javax.persistence.lock.scope\", \n                      PessimisticLockScope.EXTENDED);\n        \n        Order orderWithJoins = entityManager.find(\n            Order.class,\n            orderId,\n            LockModeType.PESSIMISTIC_WRITE,\n            properties\n        );\n        // Locks order AND order_items table\n    }\n}\n\n// 6. Upgrading locks\n@Service\npublic class LockUpgradeService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void upgradeLock(Long accountId) {\n        // First, read without lock\n        Account account = entityManager.find(Account.class, accountId);\n        \n        // Business logic...\n        \n        // Upgrade to pessimistic write lock\n        entityManager.lock(account, LockModeType.PESSIMISTIC_WRITE);\n        \n        // Now safe to modify\n        account.setBalance(account.getBalance().add(new BigDecimal(\"100\")));\n    }\n}\n\n// 7. Handling lock exceptions\n@Service\npublic class LockExceptionHandlingService {\n    \n    @Transactional\n    public void robustLocking(Long accountId) {\n        try {\n            Account account = entityManager.find(\n                Account.class,\n                accountId,\n                LockModeType.PESSIMISTIC_WRITE\n            );\n            \n            account.setBalance(account.getBalance().add(new BigDecimal(\"50\")));\n            \n        } catch (LockTimeoutException e) {\n            throw new ServiceBusyException(\n                \"Account is currently locked. Please try again.\",\n                e\n            );\n            \n        } catch (PessimisticLockException e) {\n            throw new ConcurrencyException(\n                \"Unable to acquire lock on account\",\n                e\n            );\n        }\n    }\n}\n\n// 8. Database-specific syntax\n/*\n * PostgreSQL:\n * • FOR UPDATE - Exclusive lock (PESSIMISTIC_WRITE)\n * • FOR SHARE - Shared lock (PESSIMISTIC_READ)\n * • FOR UPDATE NOWAIT - Fail immediately\n * • FOR UPDATE SKIP LOCKED - Skip locked rows\n * \n * MySQL:\n * • FOR UPDATE - Exclusive lock\n * • LOCK IN SHARE MODE - Shared lock\n * • FOR UPDATE NOWAIT - (MySQL 8.0+)\n * \n * Oracle:\n * • FOR UPDATE - Exclusive lock\n * • FOR UPDATE NOWAIT - Fail immediately\n * • FOR UPDATE WAIT n - Wait n seconds\n * \n * SQL Server:\n * • WITH (UPDLOCK) - Update lock\n * • WITH (HOLDLOCK) - Hold lock until transaction end\n * • WITH (ROWLOCK) - Row-level lock\n */\n\n// 9. Performance considerations\n@Service\npublic class PerformanceOptimizedLocking {\n    \n    // âŒ BAD: Holds lock too long\n    @Transactional\n    public void badLockingPractice(Long accountId) {\n        Account account = entityManager.find(\n            Account.class,\n            accountId,\n            LockModeType.PESSIMISTIC_WRITE\n        );\n        \n        // Expensive operation while holding lock\n        externalApiCall(); // BAD!\n        Thread.sleep(1000); // BAD!\n        \n        account.setBalance(account.getBalance().add(new BigDecimal(\"100\")));\n    }\n    \n    // âœ… GOOD: Minimal lock duration\n    public void goodLockingPractice(Long accountId) {\n        // Do expensive operations first\n        Data data = externalApiCall();\n        \n        // Lock only when needed\n        transactionTemplate.execute(status -> {\n            Account account = entityManager.find(\n                Account.class,\n                accountId,\n                LockModeType.PESSIMISTIC_WRITE\n            );\n            \n            account.setBalance(calculateNewBalance(account, data));\n            return null;\n        });\n    }\n}\n\n// 10. Pessimistic vs Optimistic comparison\n/*\n * Use PESSIMISTIC locking when:\n * âœ… High contention expected\n * âœ… Conflicts are expensive to resolve\n * âœ… Critical operations (financial transactions)\n * âœ… Short transactions\n * âœ… Must prevent conflicts at all costs\n * \n * Use OPTIMISTIC locking when:\n * âœ… Low contention expected\n * âœ… Read >> Write ratio\n * âœ… Long-running transactions\n * âœ… User-facing applications\n * âœ… Better performance needed\n * \n * Performance:\n * • Pessimistic: Slower (database locks), but guaranteed consistency\n * • Optimistic: Faster (no locks), but may need retries\n * \n * Deadlock risk:\n * • Pessimistic: Higher (can deadlock), use consistent lock ordering\n * • Optimistic: Lower (no locks)\n * \n * Scalability:\n * • Pessimistic: Lower (locks reduce concurrency)\n * • Optimistic: Higher (no locks)\n */"
    },
    {
      "id": 46,
      "question": "How do you configure JPA caching (first-level and second-level cache)?",
      "answer": "JPA caching improves performance by reducing database queries:\n\nFirst-Level Cache (Session Cache):\n• Enabled by default\n• EntityManager scope\n• Automatic\n• Cannot be disabled\n\nSecond-Level Cache:\n• Shared across EntityManagers\n• Application scope\n• Optional (EhCache, Hazelcast, Redis)\n• Configured per entity\n• Query cache available",
      "explanation": "First-level cache is mandatory and short-lived. Second-level cache is optional, shared, and improves performance across sessions.",
      "difficulty": "Hard",
      "code": "// 1. First-level cache (default, always enabled)\n@Service\npublic class FirstLevelCacheDemo {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void demonstrateFirstLevelCache(Long userId) {\n        // First query - hits database\n        User user1 = entityManager.find(User.class, userId);\n        System.out.println(\"First query executed\");\n        \n        // Second query - returns cached instance (NO database query)\n        User user2 = entityManager.find(User.class, userId);\n        System.out.println(\"Second query from cache\");\n        \n        // Same instance!\n        assert user1 == user2; // true\n        \n        // Modifying cached entity\n        user1.setName(\"Updated\");\n        // user2.getName() is also \"Updated\" (same instance)\n        \n        // Cache cleared on:\n        // 1. Transaction commit\n        // 2. entityManager.clear()\n        // 3. entityManager.close()\n    }\n    \n    @Transactional\n    public void clearFirstLevelCache() {\n        User user = entityManager.find(User.class, 1L);\n        \n        // Manually clear cache\n        entityManager.clear();\n        \n        // This will hit database again\n        User userAgain = entityManager.find(User.class, 1L);\n        \n        // Different instances now\n        assert user != userAgain; // true\n    }\n    \n    @Transactional\n    public void detachEntity(Long userId) {\n        User user = entityManager.find(User.class, userId);\n        \n        // Detach single entity from cache\n        entityManager.detach(user);\n        \n        // Entity no longer managed\n        user.setName(\"Updated\"); // Won't be persisted automatically\n    }\n}\n\n// 2. Second-level cache configuration\n@Entity\n@Cacheable // Enable second-level cache for this entity\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.READ_WRITE\n)\npublic class Product {\n    @Id\n    private Long id;\n    \n    private String name;\n    \n    private BigDecimal price;\n    \n    // Collections can also be cached\n    @OneToMany(mappedBy = \"product\")\n    @org.hibernate.annotations.Cache(\n        usage = CacheConcurrencyStrategy.READ_WRITE\n    )\n    private List<Review> reviews;\n}\n\n// 3. application.properties configuration\n/*\n# Enable second-level cache\nspring.jpa.properties.hibernate.cache.use_second_level_cache=true\n\n# Enable query cache\nspring.jpa.properties.hibernate.cache.use_query_cache=true\n\n# Cache provider (EhCache)\nspring.jpa.properties.hibernate.cache.region.factory_class=\n    org.hibernate.cache.jcache.JCacheRegionFactory\n\n# Statistics for monitoring\nspring.jpa.properties.hibernate.generate_statistics=true\nspring.jpa.properties.hibernate.cache.use_structured_entries=true\n\n# Cache data format\nspring.jpa.properties.hibernate.cache.use_reference_entries=true\n*/\n\n// 4. EhCache configuration (ehcache.xml)\n/*\n<ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:noNamespaceSchemaLocation=\"ehcache.xsd\">\n    \n    <!-- Default cache configuration -->\n    <defaultCache\n        maxElementsInMemory=\"1000\"\n        eternal=\"false\"\n        timeToIdleSeconds=\"300\"\n        timeToLiveSeconds=\"600\"\n        overflowToDisk=\"false\"\n        memoryStoreEvictionPolicy=\"LRU\"/>\n    \n    <!-- Entity cache -->\n    <cache name=\"com.example.model.Product\"\n           maxElementsInMemory=\"10000\"\n           eternal=\"false\"\n           timeToIdleSeconds=\"300\"\n           timeToLiveSeconds=\"600\"/>\n    \n    <!-- Query cache -->\n    <cache name=\"org.hibernate.cache.internal.StandardQueryCache\"\n           maxElementsInMemory=\"100\"\n           eternal=\"false\"\n           timeToLiveSeconds=\"120\"/>\n    \n    <!-- Query results timestamps -->\n    <cache name=\"org.hibernate.cache.spi.UpdateTimestampsCache\"\n           maxElementsInMemory=\"5000\"\n           eternal=\"true\"/>\n    \n    <!-- Collection cache -->\n    <cache name=\"com.example.model.Product.reviews\"\n           maxElementsInMemory=\"10000\"\n           timeToLiveSeconds=\"600\"/>\n</ehcache>\n*/\n\n// 5. Cache concurrency strategies\n/*\n * READ_ONLY:\n * • Best for immutable entities\n * • Fastest\n * • No locking needed\n * • Cannot update cached entities\n */\n@Entity\n@Cacheable\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.READ_ONLY\n)\npublic class Country {\n    @Id\n    private Long id;\n    private String name;\n    private String code;\n}\n\n/*\n * READ_WRITE:\n * • Most common\n * • For entities that are read and written\n * • Uses soft locks\n * • Handles concurrent updates\n */\n@Entity\n@Cacheable\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.READ_WRITE\n)\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n}\n\n/*\n * NONSTRICT_READ_WRITE:\n * • Higher performance than READ_WRITE\n * • No locking\n * • Risk of stale data\n * • Good for rarely updated entities\n */\n@Entity\n@Cacheable\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE\n)\npublic class Category {\n    @Id\n    private Long id;\n    private String name;\n}\n\n/*\n * TRANSACTIONAL:\n * • Full transactional cache\n * • Requires JTA\n * • Slowest but safest\n */\n@Entity\n@Cacheable\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.TRANSACTIONAL\n)\npublic class CriticalData {\n    @Id\n    private Long id;\n}\n\n// 6. Query cache\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    // Enable query cache for specific query\n    @QueryHints({\n        @QueryHint(name = \"org.hibernate.cacheable\", value = \"true\"),\n        @QueryHint(name = \"org.hibernate.cacheRegion\", value = \"productsByCategory\")\n    })\n    @Query(\"SELECT p FROM Product p WHERE p.category = :category\")\n    List<Product> findByCategoryCached(@Param(\"category\") String category);\n    \n    // Query cache with custom region\n    @QueryHints(@QueryHint(name = \"org.hibernate.cacheable\", value = \"true\"))\n    List<Product> findByPriceLessThan(BigDecimal price);\n}\n\n// 7. Programmatic cache management\n@Service\npublic class CacheManagementService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Autowired\n    private CacheManager cacheManager;\n    \n    // Evict entity from cache\n    public void evictEntity(Class<?> entityClass, Object id) {\n        Cache cache = entityManager.getEntityManagerFactory()\n            .getCache();\n        cache.evict(entityClass, id);\n    }\n    \n    // Evict all instances of entity\n    public void evictAllEntities(Class<?> entityClass) {\n        Cache cache = entityManager.getEntityManagerFactory()\n            .getCache();\n        cache.evict(entityClass);\n    }\n    \n    // Clear entire cache\n    public void clearAllCaches() {\n        Cache cache = entityManager.getEntityManagerFactory()\n            .getCache();\n        cache.evictAll();\n    }\n    \n    // Check if entity is cached\n    public boolean isEntityCached(Class<?> entityClass, Object id) {\n        Cache cache = entityManager.getEntityManagerFactory()\n            .getCache();\n        return cache.contains(entityClass, id);\n    }\n    \n    // Spring Cache abstraction\n    public void evictSpringCache(String cacheName) {\n        Cache cache = cacheManager.getCache(cacheName);\n        if (cache != null) {\n            cache.clear();\n        }\n    }\n}\n\n// 8. Cache statistics\n@Service\npublic class CacheStatisticsService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public CacheStatistics getCacheStats() {\n        SessionFactory sessionFactory = entityManager\n            .getEntityManagerFactory()\n            .unwrap(SessionFactory.class);\n        \n        Statistics stats = sessionFactory.getStatistics();\n        \n        return CacheStatistics.builder()\n            .queryCacheHitCount(stats.getQueryCacheHitCount())\n            .queryCacheMissCount(stats.getQueryCacheMissCount())\n            .queryCachePutCount(stats.getQueryCachePutCount())\n            .secondLevelCacheHitCount(stats.getSecondLevelCacheHitCount())\n            .secondLevelCacheMissCount(stats.getSecondLevelCacheMissCount())\n            .secondLevelCachePutCount(stats.getSecondLevelCachePutCount())\n            .entityLoadCount(stats.getEntityLoadCount())\n            .build();\n    }\n    \n    public void logCacheStatistics() {\n        SessionFactory sessionFactory = entityManager\n            .getEntityManagerFactory()\n            .unwrap(SessionFactory.class);\n        \n        Statistics stats = sessionFactory.getStatistics();\n        \n        log.info(\"Cache Statistics:\");\n        log.info(\"Second-level cache hit ratio: {}%\", \n            stats.getSecondLevelCacheHitCount() * 100.0 / \n            (stats.getSecondLevelCacheHitCount() + \n             stats.getSecondLevelCacheMissCount()));\n        \n        log.info(\"Query cache hit ratio: {}%\",\n            stats.getQueryCacheHitCount() * 100.0 /\n            (stats.getQueryCacheHitCount() + \n             stats.getQueryCacheMissCount()));\n    }\n}\n\n// 9. Cache invalidation strategies\n@Service\npublic class CacheInvalidationService {\n    \n    @Autowired\n    private EntityManager entityManager;\n    \n    @CacheEvict(value = \"products\", key = \"#productId\")\n    public void updateProduct(Long productId, Product product) {\n        productRepository.save(product);\n        // Cache automatically evicted by @CacheEvict\n    }\n    \n    @CacheEvict(value = \"products\", allEntries = true)\n    public void refreshAllProducts() {\n        // Evict all products from cache\n    }\n    \n    @CachePut(value = \"products\", key = \"#result.id\")\n    public Product saveAndCache(Product product) {\n        return productRepository.save(product);\n        // Save and update cache\n    }\n}\n\n// 10. Best practices\n/*\n * First-Level Cache:\n * âœ… Always enabled, no configuration needed\n * âœ… Use entityManager.clear() for batch operations\n * âœ… Use entityManager.detach() to prevent unwanted updates\n * \n * Second-Level Cache:\n * âœ… Enable only for frequently read, rarely updated entities\n * âœ… Use READ_ONLY for immutable entities\n * âœ… Use READ_WRITE for most cases\n * âœ… Configure appropriate TTL and eviction policies\n * âœ… Monitor cache hit ratios\n * âœ… Be careful with associations (can cause stale data)\n * âŒ Don't cache large collections\n * âŒ Don't cache frequently updated entities\n * âŒ Don't forget to evict on updates\n * \n * Query Cache:\n * âœ… Enable for repeated queries with same parameters\n * âœ… Use custom cache regions for different query types\n * âŒ Don't use for queries with dynamic parameters\n * âŒ Don't use if underlying data changes frequently\n * \n * Performance:\n * • Monitor hit/miss ratios\n * • Profile before and after caching\n * • Be aware of cache invalidation complexity\n * • Consider distributed cache for clustered environments\n */"
    },
    {
      "id": 47,
      "question": "How do you implement auditing in Spring Data JPA?",
      "answer": "Auditing automatically tracks entity changes:\n\nFeatures:\n• @CreatedDate: Creation timestamp\n• @LastModifiedDate: Update timestamp\n• @CreatedBy: Creator user\n• @LastModifiedBy: Last modifier user\n• @EnableJpaAuditing: Enable auditing\n• AuditorAware<T>: Current user provider\n\nBenefits:\n• Automatic tracking\n• No boilerplate code\n• Consistent across entities",
      "explanation": "Spring Data JPA auditing automatically populates audit fields (@CreatedDate, @CreatedBy, etc.) when entities are created or modified.",
      "difficulty": "Medium",
      "code": "// 1. Enable JPA Auditing\n@Configuration\n@EnableJpaAuditing(auditorAwareRef = \"auditorProvider\")\npublic class JpaConfig {\n    \n    @Bean\n    public AuditorAware<String> auditorProvider() {\n        return new AuditorAwareImpl();\n    }\n}\n\n// 2. Implement AuditorAware\npublic class AuditorAwareImpl implements AuditorAware<String> {\n    \n    @Override\n    public Optional<String> getCurrentAuditor() {\n        // Get current user from SecurityContext\n        Authentication authentication = SecurityContextHolder\n            .getContext()\n            .getAuthentication();\n        \n        if (authentication == null || \n            !authentication.isAuthenticated() ||\n            authentication instanceof AnonymousAuthenticationToken) {\n            return Optional.empty();\n        }\n        \n        // Return username\n        return Optional.of(authentication.getName());\n    }\n}\n\n// 3. Base auditable entity\n@MappedSuperclass\n@EntityListeners(AuditingEntityListener.class)\npublic abstract class Auditable {\n    \n    @CreatedBy\n    @Column(name = \"created_by\", nullable = false, updatable = false)\n    private String createdBy;\n    \n    @CreatedDate\n    @Column(name = \"created_date\", nullable = false, updatable = false)\n    @Temporal(TemporalType.TIMESTAMP)\n    private Date createdDate;\n    \n    @LastModifiedBy\n    @Column(name = \"last_modified_by\")\n    private String lastModifiedBy;\n    \n    @LastModifiedDate\n    @Column(name = \"last_modified_date\")\n    @Temporal(TemporalType.TIMESTAMP)\n    private Date lastModifiedDate;\n    \n    // Getters and setters\n}\n\n// 4. Using auditable base class\n@Entity\npublic class Product extends Auditable {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    \n    private BigDecimal price;\n    \n    // createdBy, createdDate, lastModifiedBy, lastModifiedDate\n    // automatically populated by Spring Data JPA\n}\n\n// 5. Inline auditing (without base class)\n@Entity\n@EntityListeners(AuditingEntityListener.class)\npublic class Order {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private BigDecimal total;\n    \n    @CreatedDate\n    private LocalDateTime createdAt;\n    \n    @LastModifiedDate\n    private LocalDateTime updatedAt;\n    \n    @CreatedBy\n    private String createdBy;\n    \n    @LastModifiedBy\n    private String modifiedBy;\n}\n\n// 6. Using Java 8 date types\n@MappedSuperclass\n@EntityListeners(AuditingEntityListener.class)\npublic abstract class AuditableEntity {\n    \n    @CreatedDate\n    @Column(nullable = false, updatable = false)\n    private LocalDateTime createdDate;\n    \n    @LastModifiedDate\n    private LocalDateTime lastModifiedDate;\n    \n    @CreatedBy\n    @Column(nullable = false, updatable = false)\n    private String createdBy;\n    \n    @LastModifiedBy\n    private String lastModifiedBy;\n}\n\n// 7. Advanced AuditorAware with User entity\npublic class User {AuthenticationAuditorAware implements AuditorAware<User> {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Override\n    public Optional<User> getCurrentAuditor() {\n        Authentication authentication = SecurityContextHolder\n            .getContext()\n            .getAuthentication();\n        \n        if (authentication == null || !authentication.isAuthenticated()) {\n            return Optional.empty();\n        }\n        \n        String username = authentication.getName();\n        return userRepository.findByUsername(username);\n    }\n}\n\n// 8. Auditable with User entity reference\n@MappedSuperclass\n@EntityListeners(AuditingEntityListener.class)\npublic abstract class UserAuditable {\n    \n    @CreatedDate\n    @Column(nullable = false, updatable = false)\n    private LocalDateTime createdDate;\n    \n    @LastModifiedDate\n    private LocalDateTime lastModifiedDate;\n    \n    @CreatedBy\n    @ManyToOne(fetch = FetchType.LAZY)\n    @JoinColumn(name = \"created_by\", nullable = false, updatable = false)\n    private User createdBy;\n    \n    @LastModifiedBy\n    @ManyToOne(fetch = FetchType.LAZY)\n    @JoinColumn(name = \"last_modified_by\")\n    private User lastModifiedBy;\n}\n\n// 9. Custom auditing fields\n@Entity\n@EntityListeners(AuditingEntityListener.class)\npublic class Document {\n    \n    @Id\n    private Long id;\n    \n    private String content;\n    \n    // Standard audit fields\n    @CreatedDate\n    private LocalDateTime createdAt;\n    \n    @CreatedBy\n    private String createdBy;\n    \n    // Custom audit fields\n    private String createdByIp;\n    \n    private String createdUserAgent;\n    \n    @PrePersist\n    public void prePersist() {\n        HttpServletRequest request = getCurrentRequest();\n        if (request != null) {\n            this.createdByIp = request.getRemoteAddr();\n            this.createdUserAgent = request.getHeader(\"User-Agent\");\n        }\n    }\n    \n    private HttpServletRequest getCurrentRequest() {\n        RequestAttributes attrs = RequestContextHolder\n            .getRequestAttributes();\n        if (attrs instanceof ServletRequestAttributes) {\n            return ((ServletRequestAttributes) attrs).getRequest();\n        }\n        return null;\n    }\n}\n\n// 10. Testing auditing\n@SpringBootTest\n@AutoConfigureTestDatabase(replace = Replace.NONE)\npublic class AuditingTest {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Test\n    @WithMockUser(username = \"admin\")\n    public void testAuditingOnCreate() {\n        // Create product\n        Product product = new Product();\n        product.setName(\"Laptop\");\n        product.setPrice(new BigDecimal(\"999.99\"));\n        \n        Product saved = productRepository.save(product);\n        \n        // Verify audit fields populated\n        assertNotNull(saved.getCreatedBy());\n        assertEquals(\"admin\", saved.getCreatedBy());\n        assertNotNull(saved.getCreatedDate());\n        assertNull(saved.getLastModifiedBy());\n        assertNull(saved.getLastModifiedDate());\n    }\n    \n    @Test\n    @WithMockUser(username = \"admin\")\n    public void testAuditingOnUpdate() {\n        // Create product\n        Product product = new Product();\n        product.setName(\"Phone\");\n        product.setPrice(new BigDecimal(\"699.99\"));\n        Product saved = productRepository.save(product);\n        \n        // Wait a bit\n        Thread.sleep(100);\n        \n        // Update product\n        saved.setPrice(new BigDecimal(\"649.99\"));\n        Product updated = productRepository.save(saved);\n        \n        // Verify audit fields\n        assertEquals(\"admin\", updated.getCreatedBy());\n        assertNotNull(updated.getCreatedDate());\n        assertEquals(\"admin\", updated.getLastModifiedBy());\n        assertNotNull(updated.getLastModifiedDate());\n        assertTrue(updated.getLastModifiedDate()\n            .after(updated.getCreatedDate()));\n    }\n    \n    @Test\n    @WithMockUser(username = \"user1\")\n    public void testDifferentUsers() {\n        // User1 creates\n        Product product = new Product();\n        product.setName(\"Tablet\");\n        Product saved = productRepository.save(product);\n        assertEquals(\"user1\", saved.getCreatedBy());\n        \n        // User2 updates\n        SecurityContextHolder.getContext()\n            .setAuthentication(new UsernamePasswordAuthenticationToken(\n                \"user2\", null, Collections.emptyList()\n            ));\n        \n        saved.setName(\"Tablet Pro\");\n        Product updated = productRepository.save(saved);\n        \n        assertEquals(\"user1\", updated.getCreatedBy());\n        assertEquals(\"user2\", updated.getLastModifiedBy());\n    }\n}\n\n// Best practices:\n/*\n * âœ… DO:\n * • Use @EnableJpaAuditing in configuration\n * • Implement AuditorAware for current user\n * • Create base auditable class for reuse\n * • Use LocalDateTime for Java 8+\n * • Make audit fields non-updatable (createdBy, createdDate)\n * • Use @Column constraints (nullable, updatable)\n * • Test auditing with @WithMockUser\n * \n * âŒ DON'T:\n * • Don't manually set audit fields\n * • Don't forget @EntityListeners(AuditingEntityListener.class)\n * • Don't expose audit fields in API updates\n * • Don't use mutable date types (use LocalDateTime)\n * \n * Security considerations:\n * • Validate user in AuditorAware\n * • Handle anonymous users gracefully\n * • Log audit information for compliance\n * • Don't trust client-provided audit data\n */"
    },
    {
      "id": 48,
      "question": "How do you use entity lifecycle callbacks in JPA?",
      "answer": "Entity lifecycle callbacks execute at specific entity state transitions:\n\nCallbacks:\n• @PrePersist: Before insert\n• @PostPersist: After insert\n• @PreUpdate: Before update\n• @PostUpdate: After update\n• @PreRemove: Before delete\n• @PostRemove: After delete\n• @PostLoad: After entity loaded\n\nUse cases:\n• Validation\n• Default values\n• Audit logging\n• Derived fields\n• Event publishing",
      "explanation": "Lifecycle callbacks provide hooks into JPA entity state changes, enabling automatic execution of code at key points.",
      "difficulty": "Medium",
      "code": "// 1. Entity with lifecycle callbacks\n@Entity\npublic class User {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String username;\n    \n    private String email;\n    \n    private String password;\n    \n    private LocalDateTime createdAt;\n    \n    private LocalDateTime updatedAt;\n    \n    private boolean active;\n    \n    @Transient\n    private boolean isNew = true;\n    \n    // Called before entity is persisted (INSERT)\n    @PrePersist\n    public void prePersist() {\n        System.out.println(\"PrePersist: Creating user \" + username);\n        this.createdAt = LocalDateTime.now();\n        this.active = true; // Default value\n        \n        // Validation\n        if (email == null || !email.contains(\"@\")) {\n            throw new IllegalStateException(\"Invalid email\");\n        }\n    }\n    \n    // Called after entity is persisted\n    @PostPersist\n    public void postPersist() {\n        System.out.println(\"PostPersist: User created with ID \" + id);\n        this.isNew = false;\n        // Send welcome email, log to audit, etc.\n    }\n    \n    // Called before entity is updated\n    @PreUpdate\n    public void preUpdate() {\n        System.out.println(\"PreUpdate: Updating user \" + id);\n        this.updatedAt = LocalDateTime.now();\n        \n        // Validation\n        if (username != null && username.length() < 3) {\n            throw new IllegalStateException(\"Username too short\");\n        }\n    }\n    \n    // Called after entity is updated\n    @PostUpdate\n    public void postUpdate() {\n        System.out.println(\"PostUpdate: User \" + id + \" updated\");\n        // Clear cache, notify listeners, etc.\n    }\n    \n    // Called before entity is removed (DELETE)\n    @PreRemove\n    public void preRemove() {\n        System.out.println(\"PreRemove: Deleting user \" + id);\n        // Cascade delete children, check constraints\n        if (username.equals(\"admin\")) {\n            throw new IllegalStateException(\"Cannot delete admin user\");\n        }\n    }\n    \n    // Called after entity is removed\n    @PostRemove\n    public void postRemove() {\n        System.out.println(\"PostRemove: User \" + id + \" deleted\");\n        // Cleanup files, remove from cache, log audit\n    }\n    \n    // Called after entity is loaded from database\n    @PostLoad\n    public void postLoad() {\n        System.out.println(\"PostLoad: User \" + id + \" loaded\");\n        this.isNew = false;\n        // Decrypt fields, calculate derived values\n    }\n}\n\n// 2. External entity listener\n@Component\npublic class UserEntityListener {\n    \n    @Autowired\n    private ApplicationEventPublisher eventPublisher;\n    \n    @Autowired\n    private AuditService auditService;\n    \n    @PrePersist\n    public void beforeCreate(User user) {\n        // Hash password before saving\n        if (user.getPassword() != null && !user.getPassword().startsWith(\"$\")) {\n            user.setPassword(hashPassword(user.getPassword()));\n        }\n    }\n    \n    @PostPersist\n    public void afterCreate(User user) {\n        // Publish event\n        eventPublisher.publishEvent(new UserCreatedEvent(user));\n        \n        // Log audit\n        auditService.logUserCreated(user.getId());\n    }\n    \n    @PostUpdate\n    public void afterUpdate(User user) {\n        eventPublisher.publishEvent(new UserUpdatedEvent(user));\n    }\n    \n    @PostRemove\n    public void afterDelete(User user) {\n        eventPublisher.publishEvent(new UserDeletedEvent(user));\n        auditService.logUserDeleted(user.getId());\n    }\n    \n    private String hashPassword(String password) {\n        // Use BCrypt or similar\n        return \"$\" + password.hashCode();\n    }\n}\n\n// Register external listener\n@Entity\n@EntityListeners(UserEntityListener.class)\npublic class User {\n    // Entity fields\n}\n\n// 3. Multiple callbacks for different purposes\n@Entity\n@EntityListeners({\n    AuditingEntityListener.class,\n    UserEntityListener.class,\n    ValidationEntityListener.class\n})\npublic class Product {\n    @Id\n    private Long id;\n    \n    private String name;\n    \n    private BigDecimal price;\n    \n    // Listeners executed in order\n}\n\n// 4. Callback execution order\n@Entity\npublic class Order {\n    \n    @PrePersist\n    public void validate() {\n        System.out.println(\"1. Validate\");\n    }\n    \n    @PrePersist\n    public void setDefaults() {\n        System.out.println(\"2. Set defaults\");\n    }\n    \n    @PrePersist\n    public void calculateTotal() {\n        System.out.println(\"3. Calculate total\");\n    }\n    \n    // Execution order not guaranteed within same callback type!\n    // Use external listener for ordered execution\n}\n\n// 5. Callback with dependency injection\n@Component\npublic class EntityCallbackListener {\n    \n    private static ApplicationEventPublisher eventPublisher;\n    \n    @Autowired\n    public void setEventPublisher(ApplicationEventPublisher publisher) {\n        EntityCallbackListener.eventPublisher = publisher;\n    }\n    \n    @PostPersist\n    public void publishEvent(Object entity) {\n        if (eventPublisher != null) {\n            eventPublisher.publishEvent(new EntityCreatedEvent(entity));\n        }\n    }\n}\n\n// 6. Conditional callbacks\n@Entity\npublic class Document {\n    \n    @Id\n    private Long id;\n    \n    private String content;\n    \n    private boolean indexed;\n    \n    @Transient\n    private boolean contentChanged;\n    \n    @PostLoad\n    public void postLoad() {\n        contentChanged = false;\n    }\n    \n    public void setContent(String content) {\n        if (!Objects.equals(this.content, content)) {\n            this.content = content;\n            this.contentChanged = true;\n        }\n    }\n    \n    @PreUpdate\n    public void preUpdate() {\n        if (contentChanged) {\n            // Re-index only if content changed\n            this.indexed = false;\n        }\n    }\n}\n\n// 7. Inheritance and callbacks\n@MappedSuperclass\npublic abstract class BaseEntity {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private LocalDateTime createdAt;\n    \n    @PrePersist\n    protected void onCreate() {\n        createdAt = LocalDateTime.now();\n    }\n}\n\n@Entity\npublic class Customer extends BaseEntity {\n    private String name;\n    \n    @PrePersist\n    public void validateCustomer() {\n        // Called AFTER BaseEntity.onCreate()\n        if (name == null) {\n            throw new IllegalStateException(\"Name required\");\n        }\n    }\n}\n\n// 8. Callbacks vs entity listeners comparison\n/*\n * Callbacks in entity:\n * âœ… Simple, inline\n * âœ… Direct access to entity\n * âŒ No dependency injection\n * âŒ Tight coupling\n * \n * External EntityListener:\n * âœ… Dependency injection supported\n * âœ… Reusable across entities\n * âœ… Better separation of concerns\n * âŒ More complex setup\n */\n\n// 9. Common use cases\n@Entity\npublic class Invoice {\n    \n    @Id\n    private Long id;\n    \n    private BigDecimal subtotal;\n    \n    private BigDecimal tax;\n    \n    private BigDecimal total;\n    \n    private String invoiceNumber;\n    \n    // Use case 1: Calculate derived fields\n    @PrePersist\n    @PreUpdate\n    public void calculateTotal() {\n        this.total = subtotal.add(tax);\n    }\n    \n    // Use case 2: Generate unique identifiers\n    @PrePersist\n    public void generateInvoiceNumber() {\n        if (invoiceNumber == null) {\n            invoiceNumber = \"INV-\" + \n                System.currentTimeMillis() + \"-\" + \n                ThreadLocalRandom.current().nextInt(1000, 9999);\n        }\n    }\n    \n    // Use case 3: Validation\n    @PrePersist\n    @PreUpdate\n    public void validate() {\n        if (subtotal.compareTo(BigDecimal.ZERO) < 0) {\n            throw new IllegalStateException(\"Subtotal cannot be negative\");\n        }\n    }\n}\n\n// 10. Callback exceptions and transactions\n@Service\npublic class CallbackBehaviorDemo {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional\n    public void demonstrateCallbackException() {\n        User user = new User();\n        user.setUsername(\"test\");\n        user.setEmail(\"invalid-email\"); // Will throw in @PrePersist\n        \n        try {\n            userRepository.save(user);\n        } catch (IllegalStateException e) {\n            // Transaction rolled back\n            // Entity not saved\n            System.out.println(\"Callback exception: \" + e.getMessage());\n        }\n    }\n}\n\n// Best practices:\n/*\n * âœ… DO:\n * • Use @PrePersist for default values\n * • Use @PostLoad for derived/calculated fields\n * • Use @PreUpdate for validation\n * • Use external listeners for complex logic\n * • Keep callbacks fast (no heavy I/O)\n * • Use callbacks for audit logging\n * \n * âŒ DON'T:\n * • Don't access database in callbacks (can cause flush)\n * • Don't throw checked exceptions\n * • Don't rely on callback execution order\n * • Don't use for complex business logic\n * • Don't access lazy-loaded collections in @PostLoad\n * • Don't modify primary key in callbacks\n * \n * Callback lifecycle:\n * new -> @PrePersist -> INSERT -> @PostPersist -> managed\n * managed -> @PreUpdate -> UPDATE -> @PostUpdate -> managed\n * managed -> @PreRemove -> DELETE -> @PostRemove -> removed\n * SELECT -> @PostLoad -> managed\n */"
    },
    {
      "id": 49,
      "question": "How do you create custom repository implementations in Spring Data JPA?",
      "answer": "Custom implementations extend repository functionality:\n\nApproach:\n1. Create custom interface\n2. Implement with `Impl` suffix\n3. Extend in main repository\n4. Use EntityManager for custom queries\n\nUse cases:\n• Complex queries beyond method names\n• Criteria API usage\n• Bulk operations\n• Custom logic\n• Performance optimization",
      "explanation": "Custom repository implementations allow adding methods with complex logic beyond Spring Data JPA's query derivation capabilities.",
      "difficulty": "Hard",
      "code": "// 1. Define custom repository interface\npublic interface UserRepositoryCustom {\n    List<User> findUsersByComplexCriteria(UserSearchCriteria criteria);\n    void bulkUpdateStatus(List<Long> userIds, String status);\n    Page<User> findWithDynamicQuery(Map<String, Object> filters, Pageable pageable);\n}\n\n// 2. Implement custom repository\n@Repository\npublic class UserRepositoryCustomImpl implements UserRepositoryCustom {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public List<User> findUsersByComplexCriteria(UserSearchCriteria criteria) {\n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<User> query = cb.createQuery(User.class);\n        Root<User> user = query.from(User.class);\n        \n        List<Predicate> predicates = new ArrayList<>();\n        \n        // Dynamic predicates based on criteria\n        if (criteria.getName() != null) {\n            predicates.add(cb.like(\n                cb.lower(user.get(\"name\")),\n                \"%\" + criteria.getName().toLowerCase() + \"%\"\n            ));\n        }\n        \n        if (criteria.getMinAge() != null) {\n            predicates.add(cb.greaterThanOrEqualTo(\n                user.get(\"age\"),\n                criteria.getMinAge()\n            ));\n        }\n        \n        if (criteria.getStatus() != null) {\n            predicates.add(cb.equal(\n                user.get(\"status\"),\n                criteria.getStatus()\n            ));\n        }\n        \n        if (criteria.getCreatedAfter() != null) {\n            predicates.add(cb.greaterThan(\n                user.get(\"createdDate\"),\n                criteria.getCreatedAfter()\n            ));\n        }\n        \n        query.where(predicates.toArray(new Predicate[0]));\n        \n        return entityManager.createQuery(query).getResultList();\n    }\n    \n    @Override\n    @Transactional\n    public void bulkUpdateStatus(List<Long> userIds, String status) {\n        // Efficient bulk update without loading entities\n        String jpql = \"UPDATE User u SET u.status = :status \" +\n                     \"WHERE u.id IN :ids\";\n        \n        entityManager.createQuery(jpql)\n            .setParameter(\"status\", status)\n            .setParameter(\"ids\", userIds)\n            .executeUpdate();\n    }\n    \n    @Override\n    public Page<User> findWithDynamicQuery(\n            Map<String, Object> filters,\n            Pageable pageable) {\n        \n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        \n        // Query for data\n        CriteriaQuery<User> query = cb.createQuery(User.class);\n        Root<User> user = query.from(User.class);\n        \n        List<Predicate> predicates = buildPredicates(filters, cb, user);\n        query.where(predicates.toArray(new Predicate[0]));\n        \n        // Apply sorting\n        if (pageable.getSort().isSorted()) {\n            List<Order> orders = new ArrayList<>();\n            pageable.getSort().forEach(order -> {\n                if (order.isAscending()) {\n                    orders.add(cb.asc(user.get(order.getProperty())));\n                } else {\n                    orders.add(cb.desc(user.get(order.getProperty())));\n                }\n            });\n            query.orderBy(orders);\n        }\n        \n        TypedQuery<User> typedQuery = entityManager.createQuery(query);\n        typedQuery.setFirstResult((int) pageable.getOffset());\n        typedQuery.setMaxResults(pageable.getPageSize());\n        \n        List<User> content = typedQuery.getResultList();\n        \n        // Count query\n        CriteriaQuery<Long> countQuery = cb.createQuery(Long.class);\n        Root<User> countRoot = countQuery.from(User.class);\n        countQuery.select(cb.count(countRoot));\n        countQuery.where(buildPredicates(filters, cb, countRoot)\n            .toArray(new Predicate[0]));\n        \n        Long total = entityManager.createQuery(countQuery).getSingleResult();\n        \n        return new PageImpl<>(content, pageable, total);\n    }\n    \n    private List<Predicate> buildPredicates(\n            Map<String, Object> filters,\n            CriteriaBuilder cb,\n            Root<User> root) {\n        \n        List<Predicate> predicates = new ArrayList<>();\n        \n        filters.forEach((key, value) -> {\n            if (value != null) {\n                if (value instanceof String) {\n                    predicates.add(cb.like(\n                        cb.lower(root.get(key)),\n                        \"%\" + ((String) value).toLowerCase() + \"%\"\n                    ));\n                } else {\n                    predicates.add(cb.equal(root.get(key), value));\n                }\n            }\n        });\n        \n        return predicates;\n    }\n}\n\n// 3. Main repository extending custom interface\npublic interface UserRepository extends \n        JpaRepository<User, Long>,\n        UserRepositoryCustom { // Extend custom interface\n    \n    // Standard Spring Data JPA methods\n    List<User> findByStatus(String status);\n    \n    Optional<User> findByEmail(String email);\n    \n    // Custom methods from UserRepositoryCustom available here\n}\n\n// 4. Using custom repository\n@Service\npublic class UserService {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    public List<User> searchUsers(UserSearchCriteria criteria) {\n        // Calls custom implementation\n        return userRepository.findUsersByComplexCriteria(criteria);\n    }\n    \n    public void deactivateUsers(List<Long> userIds) {\n        // Efficient bulk update\n        userRepository.bulkUpdateStatus(userIds, \"INACTIVE\");\n    }\n    \n    public Page<User> dynamicSearch(\n            Map<String, Object> filters,\n            Pageable pageable) {\n        return userRepository.findWithDynamicQuery(filters, pageable);\n    }\n}\n\n// 5. Custom repository with native queries\npublic interface ProductRepositoryCustom {\n    List<ProductStats> getProductStatistics();\n    void optimizeProductSearch();\n}\n\n@Repository\npublic class ProductRepositoryCustomImpl implements ProductRepositoryCustom {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public List<ProductStats> getProductStatistics() {\n        String sql = \n            \"SELECT p.category, \" +\n            \"       COUNT(p.id) as productCount, \" +\n            \"       AVG(p.price) as avgPrice, \" +\n            \"       SUM(o.quantity) as totalSold \" +\n            \"FROM products p \" +\n            \"LEFT JOIN order_items o ON p.id = o.product_id \" +\n            \"GROUP BY p.category\";\n        \n        Query query = entityManager.createNativeQuery(sql);\n        List<Object[]> results = query.getResultList();\n        \n        return results.stream()\n            .map(row -> new ProductStats(\n                (String) row[0],\n                ((Number) row[1]).longValue(),\n                ((Number) row[2]).doubleValue(),\n                ((Number) row[3]).longValue()\n            ))\n            .collect(Collectors.toList());\n    }\n    \n    @Override\n    @Transactional\n    public void optimizeProductSearch() {\n        // Database-specific optimization\n        entityManager.createNativeQuery(\n            \"ANALYZE TABLE products\"\n        ).executeUpdate();\n    }\n}\n\n// 6. Custom repository base class for all entities\npublic interface CustomRepository<T, ID> {\n    void refresh(T entity);\n    T findByIdOrThrow(ID id);\n    List<T> findAllById(Iterable<ID> ids, boolean preserveOrder);\n}\n\npublic class CustomRepositoryImpl<T, ID extends Serializable>\n        extends SimpleJpaRepository<T, ID>\n        implements CustomRepository<T, ID> {\n    \n    private final EntityManager entityManager;\n    \n    public CustomRepositoryImpl(\n            JpaEntityInformation<T, ?> entityInformation,\n            EntityManager entityManager) {\n        super(entityInformation, entityManager);\n        this.entityManager = entityManager;\n    }\n    \n    @Override\n    public void refresh(T entity) {\n        entityManager.refresh(entity);\n    }\n    \n    @Override\n    public T findByIdOrThrow(ID id) {\n        return findById(id)\n            .orElseThrow(() -> new EntityNotFoundException(\n                \"Entity not found with id: \" + id\n            ));\n    }\n    \n    @Override\n    public List<T> findAllById(Iterable<ID> ids, boolean preserveOrder) {\n        List<T> results = findAllById(ids);\n        \n        if (!preserveOrder) {\n            return results;\n        }\n        \n        // Preserve order of input IDs\n        Map<ID, T> resultMap = results.stream()\n            .collect(Collectors.toMap(\n                entity -> (ID) entityManager\n                    .getEntityManagerFactory()\n                    .getPersistenceUnitUtil()\n                    .getIdentifier(entity),\n                entity -> entity\n            ));\n        \n        List<T> orderedResults = new ArrayList<>();\n        ids.forEach(id -> {\n            T entity = resultMap.get(id);\n            if (entity != null) {\n                orderedResults.add(entity);\n            }\n        });\n        \n        return orderedResults;\n    }\n}\n\n// 7. Enable custom repository base class\n@Configuration\n@EnableJpaRepositories(\n    basePackages = \"com.example.repository\",\n    repositoryBaseClass = CustomRepositoryImpl.class\n)\npublic class JpaConfig {\n}\n\n// 8. Repository using custom base\npublic interface ProductRepository extends \n        JpaRepository<Product, Long>,\n        CustomRepository<Product, Long> { // Custom base methods available\n    \n    // refresh(), findByIdOrThrow(), findAllById() available\n}\n\n// 9. Complex custom implementation with specifications\npublic interface OrderRepositoryCustom {\n    Page<Order> findBySpecification(\n        Specification<Order> spec,\n        Pageable pageable\n    );\n}\n\n@Repository\npublic class OrderRepositoryCustomImpl implements OrderRepositoryCustom {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public Page<Order> findBySpecification(\n            Specification<Order> spec,\n            Pageable pageable) {\n        \n        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n        CriteriaQuery<Order> query = cb.createQuery(Order.class);\n        Root<Order> root = query.from(Order.class);\n        \n        // Apply specification\n        Predicate predicate = spec.toPredicate(root, query, cb);\n        if (predicate != null) {\n            query.where(predicate);\n        }\n        \n        // Fetch associations efficiently\n        root.fetch(\"items\", JoinType.LEFT);\n        root.fetch(\"customer\", JoinType.LEFT);\n        \n        // Remove duplicates from join fetches\n        query.distinct(true);\n        \n        TypedQuery<Order> typedQuery = entityManager.createQuery(query);\n        typedQuery.setFirstResult((int) pageable.getOffset());\n        typedQuery.setMaxResults(pageable.getPageSize());\n        \n        List<Order> content = typedQuery.getResultList();\n        \n        // Count query (without fetch joins)\n        CriteriaQuery<Long> countQuery = cb.createQuery(Long.class);\n        Root<Order> countRoot = countQuery.from(Order.class);\n        countQuery.select(cb.count(countRoot));\n        \n        if (predicate != null) {\n            countQuery.where(spec.toPredicate(countRoot, countQuery, cb));\n        }\n        \n        Long total = entityManager.createQuery(countQuery).getSingleResult();\n        \n        return new PageImpl<>(content, pageable, total);\n    }\n}\n\n// 10. Testing custom repository\n@SpringBootTest\npublic class CustomRepositoryTest {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Test\n    public void testCustomMethod() {\n        // Test complex criteria search\n        UserSearchCriteria criteria = new UserSearchCriteria();\n        criteria.setName(\"John\");\n        criteria.setMinAge(18);\n        criteria.setStatus(\"ACTIVE\");\n        \n        List<User> users = userRepository\n            .findUsersByComplexCriteria(criteria);\n        \n        assertFalse(users.isEmpty());\n        users.forEach(user -> {\n            assertTrue(user.getName().contains(\"John\"));\n            assertTrue(user.getAge() >= 18);\n            assertEquals(\"ACTIVE\", user.getStatus());\n        });\n    }\n    \n    @Test\n    public void testBulkUpdate() {\n        List<Long> userIds = Arrays.asList(1L, 2L, 3L);\n        \n        userRepository.bulkUpdateStatus(userIds, \"INACTIVE\");\n        \n        List<User> users = userRepository.findAllById(userIds);\n        users.forEach(user -> \n            assertEquals(\"INACTIVE\", user.getStatus())\n        );\n    }\n}\n\n// Best practices:\n/*\n * âœ… DO:\n * • Use Impl suffix for implementation class\n * • Inject EntityManager in custom impl\n * • Use Criteria API for type-safe queries\n * • Implement pagination in custom methods\n * • Use bulk operations for mass updates\n * • Keep custom methods focused and cohesive\n * \n * âŒ DON'T:\n * • Don't put business logic in repository\n * • Don't ignore pagination for large datasets\n * • Don't use string-based field names (use metamodel)\n * • Don't forget @Transactional for modifying operations\n * • Don't duplicate Spring Data JPA capabilities\n * \n * When to use custom implementations:\n * • Complex dynamic queries\n * • Criteria API usage\n * • Bulk operations\n * • Native queries with custom mapping\n * • Performance-critical operations\n * • Database-specific features\n */"
    },
    {
      "id": 50,
      "question": "How do you implement batch operations in Spring Data JPA?",
      "answer": "Batch operations improve performance for bulk INSERT/UPDATE/DELETE:\n\nTechniques:\n• saveAll() for batch inserts\n• Hibernate batch_size configuration\n• order_inserts/order_updates\n• Manual flush and clear\n• StatelessSession for large batches\n\nBenefits:\n• Reduced database round-trips\n• Better performance\n• Lower memory usage\n• Faster bulk operations",
      "explanation": "Batch operations group multiple database operations into single round-trip, significantly improving performance for bulk data operations.",
      "difficulty": "Hard",
      "code": "// 1. Configure batch size in application.properties\n/*\n# Hibernate batch settings\nspring.jpa.properties.hibernate.jdbc.batch_size=50\nspring.jpa.properties.hibernate.order_inserts=true\nspring.jpa.properties.hibernate.order_updates=true\nspring.jpa.properties.hibernate.batch_versioned_data=true\n\n# Identity generator disables batching - use SEQUENCE instead\n# spring.jpa.properties.hibernate.jdbc.batch_size won't work with GenerationType.IDENTITY\n*/\n\n// 2. Entity with SEQUENCE generator (required for batching)\n@Entity\npublic class Product {\n    \n    @Id\n    @GeneratedValue(\n        strategy = GenerationType.SEQUENCE,\n        generator = \"product_seq\"\n    )\n    @SequenceGenerator(\n        name = \"product_seq\",\n        sequenceName = \"product_sequence\",\n        allocationSize = 50 // Match batch_size\n    )\n    private Long id;\n    \n    private String name;\n    \n    private BigDecimal price;\n}\n\n// 3. Basic batch insert using saveAll()\n@Service\npublic class ProductService {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void batchInsertSimple(List<Product> products) {\n        // Uses configured batch_size automatically\n        productRepository.saveAll(products);\n    }\n    \n    // Optimized batch insert with manual flush/clear\n    @Transactional\n    public void batchInsertOptimized(List<Product> products) {\n        int batchSize = 50;\n        \n        for (int i = 0; i < products.size(); i++) {\n            entityManager.persist(products.get(i));\n            \n            if (i > 0 && i % batchSize == 0) {\n                // Flush batch to database\n                entityManager.flush();\n                // Clear persistence context to free memory\n                entityManager.clear();\n            }\n        }\n        \n        // Flush remaining\n        entityManager.flush();\n        entityManager.clear();\n    }\n}\n\n// 4. Batch update\n@Service\npublic class BatchUpdateService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void batchUpdate(List<Product> products) {\n        int batchSize = 50;\n        \n        for (int i = 0; i < products.size(); i++) {\n            // Merge detached entities\n            entityManager.merge(products.get(i));\n            \n            if (i > 0 && i % batchSize == 0) {\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n        \n        entityManager.flush();\n        entityManager.clear();\n    }\n    \n    // Bulk JPQL update (more efficient)\n    @Transactional\n    public int bulkUpdatePrice(BigDecimal increase) {\n        String jpql = \"UPDATE Product p SET p.price = p.price + :increase\";\n        \n        return entityManager.createQuery(jpql)\n            .setParameter(\"increase\", increase)\n            .executeUpdate();\n    }\n    \n    // Bulk update by IDs\n    @Transactional\n    public int bulkUpdateStatus(List<Long> ids, String status) {\n        String jpql = \"UPDATE Product p SET p.status = :status \" +\n                     \"WHERE p.id IN :ids\";\n        \n        return entityManager.createQuery(jpql)\n            .setParameter(\"status\", status)\n            .setParameter(\"ids\", ids)\n            .executeUpdate();\n    }\n}\n\n// 5. Batch delete\n@Service\npublic class BatchDeleteService {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    // Spring Data JPA method (less efficient)\n    @Transactional\n    public void deleteInBatch(List<Long> ids) {\n        List<Product> products = productRepository.findAllById(ids);\n        productRepository.deleteInBatch(products);\n        // Single DELETE statement\n    }\n    \n    // Bulk JPQL delete (most efficient)\n    @Transactional\n    public int bulkDelete(List<Long> ids) {\n        String jpql = \"DELETE FROM Product p WHERE p.id IN :ids\";\n        \n        return entityManager.createQuery(jpql)\n            .setParameter(\"ids\", ids)\n            .executeUpdate();\n    }\n    \n    // Native batch delete\n    @Transactional\n    public int nativeBulkDelete(List<Long> ids) {\n        String sql = \"DELETE FROM products WHERE id IN (:ids)\";\n        \n        return entityManager.createNativeQuery(sql)\n            .setParameter(\"ids\", ids)\n            .executeUpdate();\n    }\n}\n\n// 6. StatelessSession for very large batches\n@Service\npublic class LargeBatchService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void processLargeBatch(List<Product> products) {\n        Session session = entityManager.unwrap(Session.class);\n        \n        // StatelessSession doesn't have first-level cache\n        StatelessSession statelessSession = session\n            .getSessionFactory()\n            .openStatelessSession();\n        \n        Transaction tx = statelessSession.beginTransaction();\n        \n        try {\n            int batchSize = 50;\n            \n            for (int i = 0; i < products.size(); i++) {\n                statelessSession.insert(products.get(i));\n                \n                if (i > 0 && i % batchSize == 0) {\n                    // No need to clear (no cache)\n                }\n            }\n            \n            tx.commit();\n            \n        } catch (Exception e) {\n            tx.rollback();\n            throw e;\n        } finally {\n            statelessSession.close();\n        }\n    }\n}\n\n// 7. Custom batch repository\npublic interface BatchRepository {\n    <S extends T> void batchInsert(Iterable<S> entities, int batchSize);\n    <S extends T> void batchUpdate(Iterable<S> entities, int batchSize);\n}\n\n@Repository\npublic class BatchRepositoryImpl implements BatchRepository {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    @Transactional\n    public <S> void batchInsert(Iterable<S> entities, int batchSize) {\n        int i = 0;\n        for (S entity : entities) {\n            entityManager.persist(entity);\n            i++;\n            \n            if (i % batchSize == 0) {\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n        \n        // Flush remaining\n        if (i % batchSize != 0) {\n            entityManager.flush();\n            entityManager.clear();\n        }\n    }\n    \n    @Override\n    @Transactional\n    public <S> void batchUpdate(Iterable<S> entities, int batchSize) {\n        int i = 0;\n        for (S entity : entities) {\n            entityManager.merge(entity);\n            i++;\n            \n            if (i % batchSize == 0) {\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n        \n        if (i % batchSize != 0) {\n            entityManager.flush();\n            entityManager.clear();\n        }\n    }\n}\n\n// 8. JDBC batch insert (fastest)\n@Service\npublic class JdbcBatchService {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    @Transactional\n    public void jdbcBatchInsert(List<Product> products) {\n        String sql = \"INSERT INTO products (id, name, price) \" +\n                    \"VALUES (?, ?, ?)\";\n        \n        jdbcTemplate.batchUpdate(sql, products, products.size(),\n            (PreparedStatement ps, Product product) -> {\n                ps.setLong(1, product.getId());\n                ps.setString(2, product.getName());\n                ps.setBigDecimal(3, product.getPrice());\n            }\n        );\n    }\n    \n    // Chunked batch update\n    @Transactional\n    public void jdbcBatchUpdateChunked(\n            List<Product> products,\n            int chunkSize) {\n        \n        String sql = \"UPDATE products SET name = ?, price = ? \" +\n                    \"WHERE id = ?\";\n        \n        List<List<Product>> chunks = Lists.partition(products, chunkSize);\n        \n        for (List<Product> chunk : chunks) {\n            jdbcTemplate.batchUpdate(sql, chunk, chunk.size(),\n                (ps, product) -> {\n                    ps.setString(1, product.getName());\n                    ps.setBigDecimal(2, product.getPrice());\n                    ps.setLong(3, product.getId());\n                }\n            );\n        }\n    }\n}\n\n// 9. Performance monitoring\n@Service\npublic class BatchPerformanceService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public void compareBatchPerformance(List<Product> products) {\n        // Method 1: saveAll() - Slowest\n        long start1 = System.currentTimeMillis();\n        productRepository.saveAll(products);\n        long time1 = System.currentTimeMillis() - start1;\n        System.out.println(\"saveAll: \" + time1 + \"ms\");\n        \n        // Method 2: Manual batching - Fast\n        long start2 = System.currentTimeMillis();\n        batchInsertOptimized(products);\n        long time2 = System.currentTimeMillis() - start2;\n        System.out.println(\"Manual batch: \" + time2 + \"ms\");\n        \n        // Method 3: JDBC batch - Fastest\n        long start3 = System.currentTimeMillis();\n        jdbcBatchService.jdbcBatchInsert(products);\n        long time3 = System.currentTimeMillis() - start3;\n        System.out.println(\"JDBC batch: \" + time3 + \"ms\");\n    }\n}\n\n// 10. Best practices\n/*\n * Configuration:\n * âœ… Set hibernate.jdbc.batch_size (50-100)\n * âœ… Use SEQUENCE generator (not IDENTITY)\n * âœ… Set allocationSize = batch_size\n * âœ… Enable order_inserts and order_updates\n * âœ… Set batch_versioned_data=true for @Version\n * \n * Implementation:\n * âœ… Flush and clear after each batch\n * âœ… Use StatelessSession for very large batches\n * âœ… Use JPQL bulk operations when possible\n * âœ… Use JDBC batch for maximum performance\n * âœ… Partition large lists into chunks\n * âŒ Avoid IDENTITY generator (disables batching)\n * âŒ Avoid cascade operations in batch\n * âŒ Avoid loading entities for delete (use bulk delete)\n * \n * Performance comparison (10,000 records):\n * • Individual saves: ~20 seconds\n * • saveAll() without batching: ~15 seconds\n * • JPA with batching: ~3 seconds\n * • JDBC batch: ~1 second\n * \n * Memory considerations:\n * • Flush/clear to prevent OutOfMemoryError\n * • Use StatelessSession for millions of records\n * • Process in chunks for very large datasets\n * • Monitor heap usage during batch operations\n */"
    },
    {
      "id": 51,
      "question": "How do you implement soft deletes in Spring Data JPA?",
      "answer": "Soft delete marks records as deleted without physical removal:\n\nImplementation:\n• Add 'deleted' flag or 'deletedAt' timestamp\n• Override delete methods\n• Filter deleted records in queries\n• Use @Where or @FilterDef\n\nBenefits:\n• Data recovery possible\n• Audit trail maintained\n• Referential integrity preserved",
      "explanation": "Soft delete preserves data by marking it as deleted instead of removing it, enabling recovery and maintaining audit trails.",
      "difficulty": "Medium",
      "code": "// 1. Entity with soft delete flag\n@Entity\n@Where(clause = \"deleted = false\") // Filter deleted records globally\npublic class Product {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    \n    private BigDecimal price;\n    \n    @Column(nullable = false)\n    private Boolean deleted = false;\n    \n    private LocalDateTime deletedAt;\n    \n    private String deletedBy;\n}\n\n// 2. Alternative: Using timestamp for soft delete\n@Entity\n@SQLDelete(sql = \"UPDATE products SET deleted_at = NOW() WHERE id = ?\")\n@Where(clause = \"deleted_at IS NULL\")\npublic class Product {\n    \n    @Id\n    private Long id;\n    \n    private String name;\n    \n    @Column(name = \"deleted_at\")\n    private LocalDateTime deletedAt;\n}\n\n// 3. Custom repository with soft delete\npublic interface SoftDeleteRepository<T, ID> extends JpaRepository<T, ID> {\n    void softDelete(ID id);\n    void softDeleteAll(Iterable<ID> ids);\n    List<T> findDeleted();\n    void hardDelete(ID id);\n}\n\n@Repository\npublic class ProductRepositoryImpl implements SoftDeleteRepository<Product, Long> {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    @Transactional\n    public void softDelete(Long id) {\n        Product product = entityManager.find(Product.class, id);\n        if (product != null) {\n            product.setDeleted(true);\n            product.setDeletedAt(LocalDateTime.now());\n            product.setDeletedBy(getCurrentUser());\n        }\n    }\n    \n    @Override\n    @Transactional\n    public void softDeleteAll(Iterable<Long> ids) {\n        String jpql = \"UPDATE Product p SET p.deleted = true, \" +\n                     \"p.deletedAt = :now, p.deletedBy = :user \" +\n                     \"WHERE p.id IN :ids\";\n        \n        entityManager.createQuery(jpql)\n            .setParameter(\"now\", LocalDateTime.now())\n            .setParameter(\"user\", getCurrentUser())\n            .setParameter(\"ids\", ids)\n            .executeUpdate();\n    }\n    \n    @Override\n    public List<Product> findDeleted() {\n        return entityManager\n            .createQuery(\"SELECT p FROM Product p WHERE p.deleted = true\", Product.class)\n            .getResultList();\n    }\n    \n    @Override\n    @Transactional\n    public void hardDelete(Long id) {\n        Product product = entityManager.find(Product.class, id);\n        if (product != null) {\n            entityManager.remove(product);\n        }\n    }\n}\n\n// 4. Service layer\n@Service\npublic class ProductService {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Transactional\n    public void deleteProduct(Long id) {\n        productRepository.softDelete(id);\n    }\n    \n    @Transactional\n    public void restoreProduct(Long id) {\n        Product product = productRepository.findById(id)\n            .orElseThrow();\n        product.setDeleted(false);\n        product.setDeletedAt(null);\n        product.setDeletedBy(null);\n        productRepository.save(product);\n    }\n    \n    public List<Product> getActiveProducts() {\n        // @Where clause automatically filters deleted\n        return productRepository.findAll();\n    }\n    \n    public List<Product> getDeletedProducts() {\n        return productRepository.findDeleted();\n    }\n}\n\n// 5. Using Hibernate filters for dynamic filtering\n@Entity\n@FilterDef(name = \"deletedFilter\", parameters = @ParamDef(name = \"isDeleted\", type = \"boolean\"))\n@Filter(name = \"deletedFilter\", condition = \"deleted = :isDeleted\")\npublic class Order {\n    @Id\n    private Long id;\n    \n    private Boolean deleted = false;\n}\n\n@Service\npublic class OrderService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<Order> findOrders(boolean includeDeleted) {\n        Session session = entityManager.unwrap(Session.class);\n        \n        Filter filter = session.enableFilter(\"deletedFilter\");\n        filter.setParameter(\"isDeleted\", false);\n        \n        List<Order> orders = entityManager\n            .createQuery(\"SELECT o FROM Order o\", Order.class)\n            .getResultList();\n        \n        session.disableFilter(\"deletedFilter\");\n        \n        return orders;\n    }\n}"
    },
    {
      "id": 52,
      "question": "How do you handle multi-tenancy in Spring Data JPA?",
      "answer": "Multi-tenancy isolates data for different tenants/clients:\n\nStrategies:\n1. Separate Database: Each tenant has own database\n2. Separate Schema: Shared database, different schemas\n3. Shared Schema: Discriminator column (tenant_id)\n\nImplementation:\n• Tenant identifier from security context\n• Custom connection provider\n• Discriminator in queries\n• Row-level security",
      "explanation": "Multi-tenancy allows single application to serve multiple tenants with isolated data, using database, schema, or discriminator-based separation.",
      "difficulty": "Hard",
      "code": "// 1. Discriminator-based (Shared Schema) - Most common\n@Entity\n@FilterDef(name = \"tenantFilter\", parameters = @ParamDef(name = \"tenantId\", type = \"string\"))\n@Filter(name = \"tenantFilter\", condition = \"tenant_id = :tenantId\")\npublic class Product {\n    \n    @Id\n    private Long id;\n    \n    private String name;\n    \n    @Column(name = \"tenant_id\", nullable = false)\n    private String tenantId;\n}\n\n// 2. Tenant context holder\npublic class TenantContext {\n    private static final ThreadLocal<String> CURRENT_TENANT = new ThreadLocal<>();\n    \n    public static void setTenantId(String tenantId) {\n        CURRENT_TENANT.set(tenantId);\n    }\n    \n    public static String getTenantId() {\n        return CURRENT_TENANT.get();\n    }\n    \n    public static void clear() {\n        CURRENT_TENANT.remove();\n    }\n}\n\n// 3. Tenant interceptor\n@Component\npublic class TenantInterceptor implements HandlerInterceptor {\n    \n    @Override\n    public boolean preHandle(\n            HttpServletRequest request,\n            HttpServletResponse response,\n            Object handler) {\n        \n        // Extract tenant from header, subdomain, or JWT\n        String tenantId = request.getHeader(\"X-Tenant-Id\");\n        \n        if (tenantId == null) {\n            // Or from JWT token\n            Authentication auth = SecurityContextHolder.getContext().getAuthentication();\n            if (auth instanceof JwtAuthenticationToken) {\n                tenantId = ((JwtAuthenticationToken) auth).getToken().getClaim(\"tenant\");\n            }\n        }\n        \n        if (tenantId != null) {\n            TenantContext.setTenantId(tenantId);\n        }\n        \n        return true;\n    }\n    \n    @Override\n    public void afterCompletion(\n            HttpServletRequest request,\n            HttpServletResponse response,\n            Object handler,\n            Exception ex) {\n        TenantContext.clear();\n    }\n}\n\n// 4. Hibernate filter for automatic tenant filtering\n@Component\npublic class TenantFilterAspect {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Before(\"execution(* com.example.repository.*.*(..))\")\n    public void enableTenantFilter() {\n        Session session = entityManager.unwrap(Session.class);\n        Filter filter = session.enableFilter(\"tenantFilter\");\n        filter.setParameter(\"tenantId\", TenantContext.getTenantId());\n    }\n}\n\n// 5. Separate database strategy\n@Configuration\npublic class MultiTenantJpaConfiguration {\n    \n    @Bean\n    public DataSource dataSource() {\n        return new TenantRoutingDataSource();\n    }\n}\n\npublic class TenantRoutingDataSource extends AbstractRoutingDataSource {\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return TenantContext.getTenantId();\n    }\n}\n\n@Configuration\npublic class TenantDataSourceConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        Map<Object, Object> dataSourceMap = new HashMap<>();\n        \n        // Tenant 1\n        DataSourceBuilder builder1 = DataSourceBuilder.create();\n        builder1.url(\"jdbc:mysql://localhost/tenant1_db\");\n        dataSourceMap.put(\"tenant1\", builder1.build());\n        \n        // Tenant 2\n        DataSourceBuilder builder2 = DataSourceBuilder.create();\n        builder2.url(\"jdbc:mysql://localhost/tenant2_db\");\n        dataSourceMap.put(\"tenant2\", builder2.build());\n        \n        TenantRoutingDataSource routingDataSource = new TenantRoutingDataSource();\n        routingDataSource.setTargetDataSources(dataSourceMap);\n        routingDataSource.setDefaultTargetDataSource(builder1.build());\n        \n        return routingDataSource;\n    }\n}"
    },
    {
      "id": 53,
      "question": "How do you test Spring Data JPA repositories?",
      "answer": "Testing ensures repository correctness:\n\nApproaches:\n• @DataJpaTest: JPA slice testing\n• @SpringBootTest: Full integration testing\n• TestEntityManager: Test-specific entity manager\n• @AutoConfigureTestDatabase: Database configuration\n• TestContainers: Real database in Docker\n\nBest practices:\n• Test custom queries\n• Verify relationships\n• Test edge cases\n• Use in-memory or containers",
      "explanation": "@DataJpaTest provides lightweight JPA testing with automatic transaction rollback and in-memory database support.",
      "difficulty": "Medium",
      "code": "// 1. Basic repository test with @DataJpaTest\n@DataJpaTest\npublic class UserRepositoryTest {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Autowired\n    private TestEntityManager entityManager;\n    \n    @Test\n    public void testFindByEmail() {\n        // Given\n        User user = new User();\n        user.setName(\"John Doe\");\n        user.setEmail(\"john@example.com\");\n        entityManager.persist(user);\n        entityManager.flush();\n        \n        // When\n        Optional<User> found = userRepository.findByEmail(\"john@example.com\");\n        \n        // Then\n        assertTrue(found.isPresent());\n        assertEquals(\"John Doe\", found.get().getName());\n    }\n    \n    @Test\n    public void testSaveUser() {\n        User user = new User();\n        user.setName(\"Jane\");\n        user.setEmail(\"jane@example.com\");\n        \n        User saved = userRepository.save(user);\n        \n        assertNotNull(saved.getId());\n        assertEquals(\"Jane\", saved.getName());\n    }\n}\n\n// 2. Testing with real database (PostgreSQL)\n@DataJpaTest\n@AutoConfigureTestDatabase(replace = Replace.NONE) // Don't replace with H2\n@TestPropertySource(properties = {\n    \"spring.datasource.url=jdbc:postgresql://localhost:5432/testdb\",\n    \"spring.jpa.hibernate.ddl-auto=create-drop\"\n})\npublic class ProductRepositoryIntegrationTest {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Test\n    public void testComplexQuery() {\n        // Test with real database\n    }\n}\n\n// 3. TestContainers for isolated testing\n@DataJpaTest\n@Testcontainers\n@AutoConfigureTestDatabase(replace = Replace.NONE)\npublic class OrderRepositoryTestContainersTest {\n    \n    @Container\n    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15\")\n        .withDatabaseName(\"testdb\")\n        .withUsername(\"test\")\n        .withPassword(\"test\");\n    \n    @DynamicPropertySource\n    static void configureProperties(DynamicPropertyRegistry registry) {\n        registry.add(\"spring.datasource.url\", postgres::getJdbcUrl);\n        registry.add(\"spring.datasource.username\", postgres::getUsername);\n        registry.add(\"spring.datasource.password\", postgres::getPassword);\n    }\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @Test\n    public void testOrderCreation() {\n        Order order = new Order();\n        order.setTotal(new BigDecimal(\"100.00\"));\n        \n        Order saved = orderRepository.save(order);\n        \n        assertNotNull(saved.getId());\n    }\n}\n\n// 4. Testing custom queries\n@DataJpaTest\npublic class CustomQueryTest {\n    \n    @Autowired\n    private ProductRepository productRepository;\n    \n    @Autowired\n    private TestEntityManager entityManager;\n    \n    @Test\n    public void testFindByCategoryAndPriceRange() {\n        // Setup test data\n        Product p1 = new Product(\"Laptop\", new BigDecimal(\"999\"), \"Electronics\");\n        Product p2 = new Product(\"Phone\", new BigDecimal(\"699\"), \"Electronics\");\n        Product p3 = new Product(\"Book\", new BigDecimal(\"29\"), \"Books\");\n        \n        entityManager.persist(p1);\n        entityManager.persist(p2);\n        entityManager.persist(p3);\n        entityManager.flush();\n        \n        // Test\n        List<Product> results = productRepository.findByCategoryAndPriceRange(\n            \"Electronics\",\n            new BigDecimal(\"500\"),\n            new BigDecimal(\"1000\")\n        );\n        \n        assertEquals(2, results.size());\n    }\n}\n\n// 5. Testing relationships\n@DataJpaTest\npublic class RelationshipTest {\n    \n    @Autowired\n    private TestEntityManager entityManager;\n    \n    @Test\n    public void testOneToManyRelationship() {\n        // Create user\n        User user = new User(\"John\");\n        entityManager.persist(user);\n        \n        // Create orders\n        Order order1 = new Order(new BigDecimal(\"100\"));\n        order1.setUser(user);\n        Order order2 = new Order(new BigDecimal(\"200\"));\n        order2.setUser(user);\n        \n        entityManager.persist(order1);\n        entityManager.persist(order2);\n        entityManager.flush();\n        entityManager.clear();\n        \n        // Verify\n        User foundUser = entityManager.find(User.class, user.getId());\n        assertEquals(2, foundUser.getOrders().size());\n    }\n}"
    },
    {
      "id": 54,
      "question": "How do you implement query performance optimization in JPA?",
      "answer": "Optimization techniques:\n\n1. Fetch Strategy: Use LAZY loading\n2. Projections: Select only needed columns\n3. Batch Fetching: Load collections efficiently\n4. Query Hints: Database-specific optimizations\n5. Caching: Second-level cache\n6. Indexing: Database indexes\n7. N+1 Prevention: Use JOIN FETCH\n\nMonitoring:\n• Enable SQL logging\n• Track query count\n• Measure execution time",
      "explanation": "Query optimization minimizes database round-trips and data transfer through strategic fetching, projections, and caching.",
      "difficulty": "Hard",
      "code": "// 1. Projection-based optimization\npublic interface UserNameProjection {\n    String getName();\n    String getEmail();\n}\n\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // Only selects name and email columns\n    List<UserNameProjection> findAllProjectedBy();\n    \n    // DTO projection\n    @Query(\"SELECT new com.example.dto.UserDTO(u.id, u.name, u.email) FROM User u\")\n    List<UserDTO> findAllAsDTO();\n}\n\n// 2. JOIN FETCH to solve N+1\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    // âŒ BAD: Causes N+1 problem\n    @Query(\"SELECT o FROM Order o\")\n    List<Order> findAllWithN1Problem();\n    // For 100 orders: 1 query for orders + 100 queries for items\n    \n    // âœ… GOOD: Single query with JOIN FETCH\n    @Query(\"SELECT DISTINCT o FROM Order o LEFT JOIN FETCH o.items\")\n    List<Order> findAllWithItems();\n    // Only 1 query!\n    \n    // Multiple JOIN FETCH\n    @Query(\"SELECT DISTINCT o FROM Order o \" +\n           \"LEFT JOIN FETCH o.items \" +\n           \"LEFT JOIN FETCH o.customer\")\n    List<Order> findAllWithItemsAndCustomer();\n}\n\n// 3. Batch fetching\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    @OneToMany(mappedBy = \"user\")\n    @BatchSize(size = 10) // Fetch 10 collections at once\n    private List<Order> orders;\n}\n\n// application.properties\n/*\nspring.jpa.properties.hibernate.default_batch_fetch_size=10\n*/\n\n// 4. Query hints\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    @QueryHints({\n        @QueryHint(name = \"org.hibernate.fetchSize\", value = \"50\"),\n        @QueryHint(name = \"org.hibernate.readOnly\", value = \"true\"),\n        @QueryHint(name = \"org.hibernate.cacheable\", value = \"true\")\n    })\n    @Query(\"SELECT p FROM Product p WHERE p.category = :category\")\n    List<Product> findByCategoryOptimized(@Param(\"category\") String category);\n}\n\n// 5. Performance monitoring\n@Component\npublic class QueryPerformanceInterceptor extends EmptyInterceptor {\n    \n    private ThreadLocal<Long> queryCount = ThreadLocal.withInitial(() -> 0L);\n    \n    @Override\n    public String onPrepareStatement(String sql) {\n        queryCount.set(queryCount.get() + 1);\n        log.debug(\"Query #{}: {}\", queryCount.get(), sql);\n        return sql;\n    }\n    \n    public long getQueryCount() {\n        return queryCount.get();\n    }\n    \n    public void reset() {\n        queryCount.set(0L);\n    }\n}"
    },
    {
      "id": 55,
      "question": "What are common JPA performance pitfalls and how to avoid them?",
      "answer": "Common pitfalls:\n\n1. N+1 Problem: Multiple queries for associations\n2. Eager Loading: Loading unnecessary data\n3. Missing Indexes: Slow queries\n4. Large Collections: Memory issues\n5. Cartesian Products: JOIN FETCH on multiple collections\n6. No Pagination: Loading all records\n7. Unnecessary Updates: Dirty checking overhead\n\nSolutions:\n• Use JOIN FETCH wisely\n• LAZY loading default\n• Add database indexes\n• Paginate results\n• Use projections\n• Read-only queries",
      "explanation": "Understanding and avoiding common JPA pitfalls prevents performance degradation and ensures efficient database access.",
      "difficulty": "Hard",
      "code": "// 1. N+1 Problem\n// âŒ WRONG: N+1 queries\n@Service\npublic class OrderService {\n    \n    public void processOrders() {\n        List<Order> orders = orderRepository.findAll(); // 1 query\n        \n        for (Order order : orders) {\n            // N queries (one per order)\n            List<OrderItem> items = order.getItems();\n            processItems(items);\n        }\n    }\n}\n\n// âœ… CORRECT: Single query with JOIN FETCH\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    @Query(\"SELECT DISTINCT o FROM Order o LEFT JOIN FETCH o.items\")\n    List<Order> findAllWithItems();\n}\n\n// 2. Cartesian Product Problem\n// âŒ WRONG: Multiple JOIN FETCH creates cartesian product\n@Query(\"SELECT o FROM Order o \" +\n       \"LEFT JOIN FETCH o.items \" +        // Collection 1\n       \"LEFT JOIN FETCH o.payments\")        // Collection 2\nList<Order> findAllWithItemsAndPayments(); // Multiplies row count!\n\n// âœ… CORRECT: Fetch in separate queries or use @EntityGraph\n@EntityGraph(attributePaths = {\"items\", \"payments\"})\n@Query(\"SELECT DISTINCT o FROM Order o\")\nList<Order> findAllWithRelations();\n\n// 3. Lazy Loading Exception\n// âŒ WRONG: Accessing lazy collection outside transaction\n@Service\npublic class UserService {\n    \n    public UserDTO getUserOrders(Long userId) {\n        User user = userRepository.findById(userId).orElseThrow();\n        // Transaction ends here\n        \n        user.getOrders().size(); // LazyInitializationException!\n        return new UserDTO(user);\n    }\n}\n\n// âœ… CORRECT: Access within transaction or use JOIN FETCH\n@Service\npublic class UserService {\n    \n    @Transactional(readOnly = true)\n    public UserDTO getUserOrders(Long userId) {\n        User user = userRepository.findById(userId).orElseThrow();\n        user.getOrders().size(); // OK - still in transaction\n        return new UserDTO(user);\n    }\n}\n\n// 4. Missing Pagination\n// âŒ WRONG: Loading millions of records\npublic List<Product> getAllProducts() {\n    return productRepository.findAll(); // OutOfMemoryError!\n}\n\n// âœ… CORRECT: Use pagination\npublic Page<Product> getProducts(int page, int size) {\n    return productRepository.findAll(PageRequest.of(page, size));\n}\n\n// 5. Inefficient Bulk Operations\n// âŒ WRONG: Individual saves\n@Transactional\npublic void saveProducts(List<Product> products) {\n    for (Product product : products) {\n        productRepository.save(product); // N database calls\n    }\n}\n\n// âœ… CORRECT: Batch save\n@Transactional\npublic void saveProducts(List<Product> products) {\n    int batchSize = 50;\n    for (int i = 0; i < products.size(); i++) {\n        entityManager.persist(products.get(i));\n        if (i % batchSize == 0) {\n            entityManager.flush();\n            entityManager.clear();\n        }\n    }\n}\n\n// 6. Unnecessary Read-Only Optimization\n@Service\npublic class ReportService {\n    \n    @Transactional(readOnly = true) // Skips dirty checking\n    public List<ProductReport> generateReport() {\n        return productRepository.findAllForReport();\n    }\n}\n\n// 7. Best practices summary\n/*\nâœ… DO:\n• Use LAZY loading by default\n• Add @Transactional(readOnly=true) for queries\n• Use projections for reports\n• Paginate large result sets\n• Use JOIN FETCH for known associations\n• Enable SQL logging in development\n• Monitor query count and execution time\n• Add database indexes on foreign keys\n• Use batch operations for bulk inserts\n• Clear persistence context in long transactions\n\nâŒ DON'T:\n• Don't use EAGER loading by default\n• Don't fetch entire entity for single field\n• Don't load collections without pagination\n• Don't JOIN FETCH multiple collections\n• Don't access lazy collections outside transaction\n• Don't ignore N+1 warnings\n• Don't perform queries in loops\n• Don't forget to add indexes\n*/"
    },
    {
      "id": 56,
      "question": "How do you implement database migration with JPA using Flyway?",
      "answer": "Flyway manages database schema versioning:\n\nFeatures:\n• Version-controlled migrations\n• SQL or Java-based migrations\n• Automatic execution on startup\n• Rollback support\n• Cross-database compatibility\n\nBest practices:\n• Never modify existing migrations\n• Use meaningful version numbers\n• Test migrations thoroughly\n• Keep migrations small and focused",
      "explanation": "Flyway automates database schema evolution through versioned migration scripts, ensuring consistency across environments.",
      "difficulty": "Medium",
      "code": "// 1. Add Flyway dependency (pom.xml or build.gradle)\n/*\n<dependency>\n    <groupId>org.flywaydb</groupId>\n    <artifactId>flyway-core</artifactId>\n</dependency>\n*/\n\n// 2. application.properties configuration\n/*\n# Disable Hibernate auto DDL\nspring.jpa.hibernate.ddl-auto=validate\n\n# Flyway configuration\nspring.flyway.enabled=true\nspring.flyway.baseline-on-migrate=true\nspring.flyway.locations=classpath:db/migration\nspring.flyway.sql-migration-prefix=V\nspring.flyway.sql-migration-separator=__\nspring.flyway.sql-migration-suffixes=.sql\n*/\n\n// 3. Migration file structure\n/*\nresources/\n  db/\n    migration/\n      V1__create_user_table.sql\n      V2__add_email_to_user.sql\n      V3__create_order_table.sql\n      V4__add_indexes.sql\n*/\n\n// 4. Example migration: V1__create_user_table.sql\n/*\nCREATE TABLE users (\n    id BIGSERIAL PRIMARY KEY,\n    username VARCHAR(50) NOT NULL UNIQUE,\n    email VARCHAR(100) NOT NULL,\n    password VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP,\n    CONSTRAINT uk_email UNIQUE (email)\n);\n\nCREATE INDEX idx_users_email ON users(email);\n*/\n\n// 5. Adding column: V2__add_status_to_user.sql\n/*\nALTER TABLE users ADD COLUMN status VARCHAR(20) DEFAULT 'ACTIVE';\nALTER TABLE users ADD COLUMN last_login TIMESTAMP;\n\nCREATE INDEX idx_users_status ON users(status);\n*/\n\n// 6. Java-based migration\n@Component\npublic class V3__MigrateUserData implements JavaMigration {\n    \n    @Override\n    public void migrate(Context context) throws Exception {\n        try (Statement stmt = context.getConnection().createStatement()) {\n            // Complex data migration\n            stmt.execute(\n                \"UPDATE users SET status = 'INACTIVE' \" +\n                \"WHERE last_login < NOW() - INTERVAL '90 days'\"\n            );\n        }\n    }\n}\n\n// 7. Programmatic Flyway configuration\n@Configuration\npublic class FlywayConfig {\n    \n    @Bean(initMethod = \"migrate\")\n    public Flyway flyway(DataSource dataSource) {\n        return Flyway.configure()\n            .dataSource(dataSource)\n            .locations(\"classpath:db/migration\")\n            .baselineOnMigrate(true)\n            .validateOnMigrate(true)\n            .load();\n    }\n}\n\n// 8. Testing with Flyway\n@SpringBootTest\n@Sql(scripts = \"/db/migration/V1__create_user_table.sql\")\npublic class MigrationTest {\n    \n    @Autowired\n    private Flyway flyway;\n    \n    @Test\n    public void testMigration() {\n        assertEquals(3, flyway.info().applied().length);\n    }\n}"
    },
    {
      "id": 57,
      "question": "How do you implement database migration with JPA using Liquibase?",
      "answer": "Liquibase provides database-independent schema migration:\n\nFeatures:\n• XML, YAML, JSON, or SQL changesets\n• Database-independent changes\n• Rollback support\n• Preconditions and contexts\n• Change verification\n\nAdvantages over Flyway:\n• Rollback support\n• Database abstraction\n• Conditional execution\n• Change documentation",
      "explanation": "Liquibase offers advanced database migration with rollback capabilities and database-independent change definitions.",
      "difficulty": "Medium",
      "code": "// 1. Add Liquibase dependency\n/*\n<dependency>\n    <groupId>org.liquibase</groupId>\n    <artifactId>liquibase-core</artifactId>\n</dependency>\n*/\n\n// 2. application.properties\n/*\nspring.jpa.hibernate.ddl-auto=validate\nspring.liquibase.change-log=classpath:db/changelog/db.changelog-master.yaml\nspring.liquibase.enabled=true\n*/\n\n// 3. Master changelog (db.changelog-master.yaml)\n/*\ndatabaseChangeLog:\n  - include:\n      file: db/changelog/changes/v1.0.0-create-tables.yaml\n  - include:\n      file: db/changelog/changes/v1.1.0-add-columns.yaml\n  - include:\n      file: db/changelog/changes/v1.2.0-add-indexes.yaml\n*/\n\n// 4. Create table changeset (v1.0.0-create-tables.yaml)\n/*\ndatabaseChangeLog:\n  - changeSet:\n      id: 1\n      author: john.doe\n      changes:\n        - createTable:\n            tableName: users\n            columns:\n              - column:\n                  name: id\n                  type: bigint\n                  autoIncrement: true\n                  constraints:\n                    primaryKey: true\n                    nullable: false\n              - column:\n                  name: username\n                  type: varchar(50)\n                  constraints:\n                    nullable: false\n                    unique: true\n              - column:\n                  name: email\n                  type: varchar(100)\n                  constraints:\n                    nullable: false\n              - column:\n                  name: created_at\n                  type: timestamp\n                  defaultValueComputed: CURRENT_TIMESTAMP\n      rollback:\n        - dropTable:\n            tableName: users\n*/\n\n// 5. Add column changeset (v1.1.0-add-columns.yaml)\n/*\ndatabaseChangeLog:\n  - changeSet:\n      id: 2\n      author: jane.smith\n      changes:\n        - addColumn:\n            tableName: users\n            columns:\n              - column:\n                  name: status\n                  type: varchar(20)\n                  defaultValue: ACTIVE\n              - column:\n                  name: last_login\n                  type: timestamp\n      rollback:\n        - dropColumn:\n            tableName: users\n            columnName: status\n        - dropColumn:\n            tableName: users\n            columnName: last_login\n*/\n\n// 6. Programmatic Liquibase\n@Configuration\npublic class LiquibaseConfig {\n    \n    @Bean\n    public SpringLiquibase liquibase(DataSource dataSource) {\n        SpringLiquibase liquibase = new SpringLiquibase();\n        liquibase.setDataSource(dataSource);\n        liquibase.setChangeLog(\"classpath:db/changelog/db.changelog-master.yaml\");\n        liquibase.setContexts(\"development,test\");\n        return liquibase;\n    }\n}\n\n// 7. Custom Java change\npublic class CustomDataMigration extends CustomTaskChange {\n    \n    @Override\n    public void execute(Database database) throws CustomChangeException {\n        try {\n            JdbcConnection connection = (JdbcConnection) database.getConnection();\n            Statement stmt = connection.createStatement();\n            \n            // Complex migration logic\n            stmt.execute(\"UPDATE users SET status = 'MIGRATED'\");\n            \n        } catch (Exception e) {\n            throw new CustomChangeException(e);\n        }\n    }\n}"
    },
    {
      "id": 58,
      "question": "How do you implement full-text search in JPA?",
      "answer": "Full-text search enables searching text content:\n\nApproaches:\n1. Database Native: PostgreSQL, MySQL full-text\n2. Hibernate Search: Lucene/Elasticsearch integration\n3. External: Elasticsearch, Solr\n\nFeatures:\n• Relevance ranking\n• Fuzzy matching\n• Phrase search\n• Stemming and stop words\n• Multi-field search\n\nBest for: Content-heavy applications, search functionality",
      "explanation": "Full-text search provides advanced text searching capabilities beyond basic LIKE queries, with relevance ranking and linguistic features.",
      "difficulty": "Hard",
      "code": "// 1. PostgreSQL full-text search\n@Repository\npublic interface ArticleRepository extends JpaRepository<Article, Long> {\n    \n    @Query(value = \n        \"SELECT * FROM articles \" +\n        \"WHERE to_tsvector('english', title || ' ' || content) @@ \" +\n        \"      to_tsquery('english', :searchTerm) \" +\n        \"ORDER BY ts_rank(to_tsvector('english', title || ' ' || content), \" +\n        \"                to_tsquery('english', :searchTerm)) DESC\",\n        nativeQuery = true)\n    List<Article> fullTextSearch(@Param(\"searchTerm\") String searchTerm);\n}\n\n// 2. MySQL full-text search\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    @Query(value = \n        \"SELECT *, MATCH(name, description) AGAINST(:searchTerm IN BOOLEAN MODE) as score \" +\n        \"FROM products \" +\n        \"WHERE MATCH(name, description) AGAINST(:searchTerm IN BOOLEAN MODE) \" +\n        \"ORDER BY score DESC\",\n        nativeQuery = true)\n    List<Product> fullTextSearch(@Param(\"searchTerm\") String searchTerm);\n}\n\n// 3. Hibernate Search with Lucene\n@Entity\n@Indexed // Mark for full-text indexing\npublic class Article {\n    \n    @Id\n    private Long id;\n    \n    @Field(analyze = Analyze.YES) // Analyzed for searching\n    private String title;\n    \n    @Field(analyze = Analyze.YES)\n    private String content;\n    \n    @Field(analyze = Analyze.NO) // Not analyzed (exact match)\n    private String author;\n}\n\n// 4. Hibernate Search query\n@Service\npublic class SearchService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<Article> searchArticles(String query) {\n        FullTextEntityManager fullTextEM = \n            Search.getFullTextEntityManager(entityManager);\n        \n        QueryBuilder qb = fullTextEM.getSearchFactory()\n            .buildQueryBuilder()\n            .forEntity(Article.class)\n            .get();\n        \n        org.apache.lucene.search.Query luceneQuery = qb\n            .keyword()\n            .onFields(\"title\", \"content\")\n            .matching(query)\n            .createQuery();\n        \n        FullTextQuery jpaQuery = fullTextEM\n            .createFullTextQuery(luceneQuery, Article.class);\n        \n        return jpaQuery.getResultList();\n    }\n}\n\n// 5. Elasticsearch integration\n@Document(indexName = \"products\")\npublic class Product {\n    \n    @Id\n    private String id;\n    \n    @Field(type = FieldType.Text, analyzer = \"standard\")\n    private String name;\n    \n    @Field(type = FieldType.Text)\n    private String description;\n}\n\npublic interface ProductSearchRepository \n        extends ElasticsearchRepository<Product, String> {\n    \n    List<Product> findByNameOrDescription(String name, String description);\n}"
    },
    {
      "id": 59,
      "question": "How do you handle database connection pooling in JPA?",
      "answer": "Connection pooling reuses database connections:\n\nPopular pools:\n1. HikariCP: Default in Spring Boot (fastest)\n2. Tomcat JDBC: Alternative\n3. Apache DBCP2: Legacy\n\nConfiguration:\n• Pool size (min/max)\n• Connection timeout\n• Idle timeout\n• Validation queries\n• Leak detection\n\nBenefits:\n• Reduced connection overhead\n• Better performance\n• Resource management",
      "explanation": "Connection pooling maintains a pool of reusable database connections, avoiding expensive connection creation/destruction overhead.",
      "difficulty": "Medium",
      "code": "// 1. HikariCP configuration (application.properties)\n/*\n# HikariCP settings (default in Spring Boot)\nspring.datasource.hikari.minimum-idle=5\nspring.datasource.hikari.maximum-pool-size=20\nspring.datasource.hikari.idle-timeout=300000\nspring.datasource.hikari.max-lifetime=1800000\nspring.datasource.hikari.connection-timeout=30000\nspring.datasource.hikari.pool-name=HikariPoolUsers\n\n# Leak detection\nspring.datasource.hikari.leak-detection-threshold=60000\n\n# Connection test query\nspring.datasource.hikari.connection-test-query=SELECT 1\n*/\n\n// 2. Programmatic HikariCP configuration\n@Configuration\npublic class DataSourceConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        HikariConfig config = new HikariConfig();\n        \n        config.setJdbcUrl(\"jdbc:postgresql://localhost:5432/mydb\");\n        config.setUsername(\"user\");\n        config.setPassword(\"password\");\n        \n        // Pool sizing\n        config.setMinimumIdle(5);\n        config.setMaximumPoolSize(20);\n        \n        // Timeouts\n        config.setConnectionTimeout(30000); // 30 seconds\n        config.setIdleTimeout(600000);      // 10 minutes\n        config.setMaxLifetime(1800000);     // 30 minutes\n        \n        // Performance\n        config.setAutoCommit(false);\n        config.setConnectionTestQuery(\"SELECT 1\");\n        \n        // Leak detection\n        config.setLeakDetectionThreshold(60000); // 60 seconds\n        \n        return new HikariDataSource(config);\n    }\n}\n\n// 3. Multiple data sources\n@Configuration\npublic class MultiDataSourceConfig {\n    \n    @Bean\n    @Primary\n    @ConfigurationProperties(\"spring.datasource.primary.hikari\")\n    public DataSource primaryDataSource() {\n        return DataSourceBuilder.create()\n            .type(HikariDataSource.class)\n            .build();\n    }\n    \n    @Bean\n    @ConfigurationProperties(\"spring.datasource.secondary.hikari\")\n    public DataSource secondaryDataSource() {\n        return DataSourceBuilder.create()\n            .type(HikariDataSource.class)\n            .build();\n    }\n}\n\n// 4. Monitoring connection pool\n@Component\npublic class DataSourceHealthIndicator implements HealthIndicator {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Override\n    public Health health() {\n        if (dataSource instanceof HikariDataSource) {\n            HikariDataSource hikari = (HikariDataSource) dataSource;\n            HikariPoolMXBean poolMXBean = hikari.getHikariPoolMXBean();\n            \n            return Health.up()\n                .withDetail(\"active\", poolMXBean.getActiveConnections())\n                .withDetail(\"idle\", poolMXBean.getIdleConnections())\n                .withDetail(\"total\", poolMXBean.getTotalConnections())\n                .withDetail(\"waiting\", poolMXBean.getThreadsAwaitingConnection())\n                .build();\n        }\n        \n        return Health.unknown().build();\n    }\n}\n\n// 5. Connection pool sizing formula\n/*\nOptimal pool size = ((core_count * 2) + effective_spindle_count)\n\nExample:\n- 4 CPU cores\n- 1 disk (SSD treated as 1 spindle)\n- Pool size = (4 * 2) + 1 = 9 connections\n\nStart with this formula, then tune based on:\n- Application load\n- Query complexity\n- Database capacity\n- Response time requirements\n*/"
    },
    {
      "id": 60,
      "question": "How do you implement database sharding with JPA?",
      "answer": "Sharding distributes data across multiple databases:\n\nStrategies:\n1. Range-based: By ID ranges\n2. Hash-based: Hash of shard key\n3. Geographic: By location\n4. List-based: Explicit mapping\n\nImplementation:\n• Custom routing logic\n• AbstractRoutingDataSource\n• Shard key selection\n• Cross-shard queries handling\n\nChallenges:\n• Complex joins\n• Transactions\n• Rebalancing",
      "explanation": "Sharding horizontally partitions data across multiple databases to scale beyond single database capacity limits.",
      "difficulty": "Expert",
      "code": "// 1. Shard key determination\npublic class ShardContext {\n    private static final ThreadLocal<String> CURRENT_SHARD = new ThreadLocal<>();\n    \n    public static void setShardKey(String shardKey) {\n        CURRENT_SHARD.set(determineShardId(shardKey));\n    }\n    \n    public static String getShardId() {\n        return CURRENT_SHARD.get();\n    }\n    \n    private static String determineShardId(String key) {\n        // Hash-based sharding\n        int hash = Math.abs(key.hashCode());\n        int shardId = hash % 4; // 4 shards\n        return \"shard\" + shardId;\n    }\n    \n    public static void clear() {\n        CURRENT_SHARD.remove();\n    }\n}\n\n// 2. Routing data source\npublic class ShardRoutingDataSource extends AbstractRoutingDataSource {\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return ShardContext.getShardId();\n    }\n}\n\n// 3. Data source configuration\n@Configuration\npublic class ShardConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        Map<Object, Object> shards = new HashMap<>();\n        \n        // Shard 0\n        HikariDataSource shard0 = new HikariDataSource();\n        shard0.setJdbcUrl(\"jdbc:postgresql://shard0-host/db\");\n        shards.put(\"shard0\", shard0);\n        \n        // Shard 1\n        HikariDataSource shard1 = new HikariDataSource();\n        shard1.setJdbcUrl(\"jdbc:postgresql://shard1-host/db\");\n        shards.put(\"shard1\", shard1);\n        \n        // Shard 2\n        HikariDataSource shard2 = new HikariDataSource();\n        shard2.setJdbcUrl(\"jdbc:postgresql://shard2-host/db\");\n        shards.put(\"shard2\", shard2);\n        \n        // Shard 3\n        HikariDataSource shard3 = new HikariDataSource();\n        shard3.setJdbcUrl(\"jdbc:postgresql://shard3-host/db\");\n        shards.put(\"shard3\", shard3);\n        \n        ShardRoutingDataSource routingDataSource = new ShardRoutingDataSource();\n        routingDataSource.setTargetDataSources(shards);\n        routingDataSource.setDefaultTargetDataSource(shard0);\n        \n        return routingDataSource;\n    }\n}\n\n// 4. Sharding-aware service\n@Service\npublic class UserShardingService {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional\n    public User createUser(User user) {\n        // Set shard based on user ID or region\n        ShardContext.setShardKey(user.getEmail());\n        \n        try {\n            return userRepository.save(user);\n        } finally {\n            ShardContext.clear();\n        }\n    }\n    \n    @Transactional(readOnly = true)\n    public User findUser(String email) {\n        ShardContext.setShardKey(email);\n        \n        try {\n            return userRepository.findByEmail(email).orElse(null);\n        } finally {\n            ShardContext.clear();\n        }\n    }\n    \n    // Cross-shard query (expensive!)\n    public List<User> findAllActiveUsers() {\n        List<User> allUsers = new ArrayList<>();\n        \n        // Query each shard\n        for (int i = 0; i < 4; i++) {\n            ShardContext.setShardKey(\"shard\" + i);\n            try {\n                allUsers.addAll(userRepository.findByActive(true));\n            } finally {\n                ShardContext.clear();\n            }\n        }\n        \n        return allUsers;\n    }\n}"
    },
    {
      "id": 61,
      "question": "How do you implement custom ID generators in JPA?",
      "answer": "Custom ID generators provide specialized ID generation logic:\n\nApproaches:\n1. IdentifierGenerator: Hibernate-specific\n2. @GenericGenerator: Annotation-based\n3. Sequence/Table: Standard JPA\n4. UUID: Universal unique IDs\n\nUse cases:\n• Business-specific formats\n• Composite IDs\n• External ID systems\n• Multi-tenant IDs",
      "explanation": "Custom ID generators allow implementing business-specific ID formats like 'USR-2024-0001' or integrating with external ID services.",
      "difficulty": "Medium",
      "code": "// 1. Custom string ID generator\npublic class CustomIdGenerator implements IdentifierGenerator {\n    \n    @Override\n    public Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        String prefix = \"USR\";\n        String year = String.valueOf(LocalDate.now().getYear());\n        \n        // Query max ID from database\n        String query = \"SELECT MAX(CAST(SUBSTRING(id, 9) AS INTEGER)) FROM users\";\n        \n        Integer maxId = (Integer) session.createNativeQuery(query)\n            .uniqueResult();\n        \n        int nextId = (maxId != null) ? maxId + 1 : 1;\n        \n        return String.format(\"%s-%s-%04d\", prefix, year, nextId);\n        // Returns: USR-2024-0001, USR-2024-0002, etc.\n    }\n}\n\n@Entity\npublic class User {\n    @Id\n    @GeneratedValue(generator = \"custom-id\")\n    @GenericGenerator(\n        name = \"custom-id\",\n        strategy = \"com.example.CustomIdGenerator\"\n    )\n    private String id;\n}\n\n// 2. UUID generator\n@Entity\npublic class Document {\n    @Id\n    @GeneratedValue(generator = \"uuid2\")\n    @GenericGenerator(name = \"uuid2\", strategy = \"uuid2\")\n    @Column(columnDefinition = \"VARCHAR(36)\")\n    private String id;\n}\n\n// 3. Sequence with custom allocation\n@Entity\npublic class Order {\n    @Id\n    @GeneratedValue(\n        strategy = GenerationType.SEQUENCE,\n        generator = \"order_seq\"\n    )\n    @SequenceGenerator(\n        name = \"order_seq\",\n        sequenceName = \"order_id_seq\",\n        initialValue = 1000,\n        allocationSize = 10\n    )\n    private Long id;\n}\n\n// 4. Composite key with custom generation\n@Embeddable\npublic class OrderItemId implements Serializable {\n    private Long orderId;\n    private Integer itemSequence;\n}\n\n@Entity\npublic class OrderItem {\n    @EmbeddedId\n    private OrderItemId id;\n    \n    @PrePersist\n    public void generateId() {\n        if (id == null) {\n            id = new OrderItemId();\n        }\n        if (id.getItemSequence() == null) {\n            id.setItemSequence(generateSequence());\n        }\n    }\n}"
    },
    {
      "id": 62,
      "question": "How do you implement read replicas with JPA?",
      "answer": "Read replicas distribute read load across multiple databases:\n\nStrategy:\n• Primary: Write operations\n• Replicas: Read operations\n• Automatic routing\n• Replication lag handling\n\nBenefits:\n• Improved read performance\n• Load distribution\n• High availability\n• Reduced primary load\n\nImplementation:\n• AbstractRoutingDataSource\n• @Transactional(readOnly=true)\n• Connection pool per source",
      "explanation": "Read replicas use separate routing for read vs write operations, directing reads to replica databases to improve scalability.",
      "difficulty": "Hard",
      "code": "// 1. Routing data source\npublic class ReplicationRoutingDataSource extends AbstractRoutingDataSource {\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return TransactionSynchronizationManager.isCurrentTransactionReadOnly() \n            ? \"read\" : \"write\";\n    }\n}\n\n// 2. Data source configuration\n@Configuration\npublic class ReplicationDataSourceConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        // Primary (write) data source\n        HikariDataSource primary = new HikariDataSource();\n        primary.setJdbcUrl(\"jdbc:postgresql://primary-host/db\");\n        primary.setUsername(\"user\");\n        primary.setPassword(\"password\");\n        \n        // Read replica\n        HikariDataSource replica = new HikariDataSource();\n        replica.setJdbcUrl(\"jdbc:postgresql://replica-host/db\");\n        replica.setUsername(\"user\");\n        replica.setPassword(\"password\");\n        replica.setReadOnly(true);\n        \n        Map<Object, Object> dataSources = new HashMap<>();\n        dataSources.put(\"write\", primary);\n        dataSources.put(\"read\", replica);\n        \n        ReplicationRoutingDataSource routingDataSource = \n            new ReplicationRoutingDataSource();\n        routingDataSource.setTargetDataSources(dataSources);\n        routingDataSource.setDefaultTargetDataSource(primary);\n        \n        return routingDataSource;\n    }\n}\n\n// 3. Service with read/write separation\n@Service\npublic class UserService {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @Transactional(readOnly = true) // Routes to replica\n    public List<User> getAllUsers() {\n        return userRepository.findAll();\n    }\n    \n    @Transactional // Routes to primary\n    public User createUser(User user) {\n        return userRepository.save(user);\n    }\n}\n\n// 4. Multiple read replicas with load balancing\npublic class LoadBalancedRoutingDataSource extends AbstractRoutingDataSource {\n    \n    private final List<String> readKeys = Arrays.asList(\"read1\", \"read2\", \"read3\");\n    private final AtomicInteger counter = new AtomicInteger(0);\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {\n            // Round-robin load balancing\n            int index = counter.getAndIncrement() % readKeys.size();\n            return readKeys.get(index);\n        }\n        return \"write\";\n    }\n}"
    },
    {
      "id": 63,
      "question": "How do you implement database encryption in JPA?",
      "answer": "Database encryption protects sensitive data:\n\nLevels:\n1. Application-level: Encrypt before save\n2. Column-level: Specific fields encrypted\n3. Database-level: TDE (Transparent Data Encryption)\n\nImplementation:\n• AttributeConverter for fields\n• Entity listeners\n• JPA callbacks\n• Database features (TDE)\n\nConsiderations:\n• Key management\n• Performance impact\n• Searchability",
      "explanation": "Encryption secures sensitive data at rest, using application-level converters or database TDE.",
      "difficulty": "Hard",
      "code": "// 1. AttributeConverter for field encryption\n@Converter\npublic class StringEncryptionConverter implements AttributeConverter<String, String> {\n    \n    private static final String ALGORITHM = \"AES/GCM/NoPadding\";\n    private static final String SECRET_KEY = \"MySecretKey12345\"; // Use key management service!\n    \n    @Override\n    public String convertToDatabaseColumn(String attribute) {\n        if (attribute == null) return null;\n        \n        try {\n            Cipher cipher = Cipher.getInstance(ALGORITHM);\n            SecretKeySpec keySpec = new SecretKeySpec(\n                SECRET_KEY.getBytes(), \"AES\"\n            );\n            cipher.init(Cipher.ENCRYPT_MODE, keySpec);\n            \n            byte[] encrypted = cipher.doFinal(attribute.getBytes());\n            return Base64.getEncoder().encodeToString(encrypted);\n            \n        } catch (Exception e) {\n            throw new RuntimeException(\"Encryption failed\", e);\n        }\n    }\n    \n    @Override\n    public String convertToEntityAttribute(String dbData) {\n        if (dbData == null) return null;\n        \n        try {\n            Cipher cipher = Cipher.getInstance(ALGORITHM);\n            SecretKeySpec keySpec = new SecretKeySpec(\n                SECRET_KEY.getBytes(), \"AES\"\n            );\n            cipher.init(Cipher.DECRYPT_MODE, keySpec);\n            \n            byte[] decrypted = cipher.doFinal(\n                Base64.getDecoder().decode(dbData)\n            );\n            return new String(decrypted);\n            \n        } catch (Exception e) {\n            throw new RuntimeException(\"Decryption failed\", e);\n        }\n    }\n}\n\n// 2. Entity with encrypted field\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String username;\n    \n    @Convert(converter = StringEncryptionConverter.class)\n    @Column(length = 500) // Encrypted data is longer\n    private String ssn;\n    \n    @Convert(converter = StringEncryptionConverter.class)\n    private String creditCard;\n}\n\n// 3. Key management service integration\n@Component\npublic class EncryptionService {\n    \n    @Autowired\n    private KeyManagementService kms;\n    \n    public String encrypt(String plaintext) {\n        String key = kms.getEncryptionKey();\n        // Encrypt with key\n        return encrypted;\n    }\n    \n    public String decrypt(String ciphertext) {\n        String key = kms.getEncryptionKey();\n        // Decrypt with key\n        return plaintext;\n    }\n}\n\n// 4. Searchable encryption (hashing)\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    @Convert(converter = StringEncryptionConverter.class)\n    private String email;\n    \n    @Column(name = \"email_hash\", unique = true)\n    private String emailHash; // SHA-256 hash for searching\n    \n    public void setEmail(String email) {\n        this.email = email;\n        this.emailHash = hashEmail(email);\n    }\n    \n    private String hashEmail(String email) {\n        MessageDigest digest = MessageDigest.getInstance(\"SHA-256\");\n        byte[] hash = digest.digest(email.getBytes());\n        return Base64.getEncoder().encodeToString(hash);\n    }\n}\n\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    // Search using hash\n    Optional<User> findByEmailHash(String emailHash);\n}"
    },
    {
      "id": 64,
      "question": "How do you implement event-driven architecture with JPA?",
      "answer": "Event-driven architecture decouples components through events:\n\nApproaches:\n1. Spring Events: In-process events\n2. Transaction Events: @TransactionalEventListener\n3. Domain Events: DDD pattern\n4. External: Kafka, RabbitMQ\n\nBenefits:\n• Loose coupling\n• Scalability\n• Async processing\n• Audit trail\n\nUse cases:\n• Notifications\n• Cache invalidation\n• External system sync",
      "explanation": "Event-driven JPA publishes domain events on entity changes, enabling reactive processing and loose coupling between components.",
      "difficulty": "Hard",
      "code": "// 1. Domain event\npublic class UserCreatedEvent {\n    private final Long userId;\n    private final LocalDateTime timestamp;\n    \n    public UserCreatedEvent(Long userId) {\n        this.userId = userId;\n        this.timestamp = LocalDateTime.now();\n    }\n}\n\n// 2. Entity publishing events\n@Entity\n@EntityListeners(AuditingEntityListener.class)\npublic class User {\n    @Id\n    private Long id;\n    private String email;\n    \n    @Transient\n    @DomainEvents\n    private Collection<Object> domainEvents = new ArrayList<>();\n    \n    public User createUser(String email) {\n        User user = new User();\n        user.setEmail(email);\n        user.registerEvent(new UserCreatedEvent(user.getId()));\n        return user;\n    }\n    \n    protected void registerEvent(Object event) {\n        domainEvents.add(event);\n    }\n    \n    @AfterDomainEventPublication\n    protected void clearEvents() {\n        domainEvents.clear();\n    }\n}\n\n// 3. Event listener\n@Component\npublic class UserEventListener {\n    \n    @Autowired\n    private EmailService emailService;\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)\n    public void handleUserCreated(UserCreatedEvent event) {\n        // Executed after transaction commits\n        emailService.sendWelcomeEmail(event.getUserId());\n    }\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_ROLLBACK)\n    public void handleUserCreationFailure(UserCreatedEvent event) {\n        log.error(\"User creation failed: \" + event.getUserId());\n    }\n}\n\n// 4. Publishing to external message broker\n@Service\npublic class EventPublishingService {\n    \n    @Autowired\n    private KafkaTemplate<String, Object> kafkaTemplate;\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)\n    public void publishToKafka(UserCreatedEvent event) {\n        kafkaTemplate.send(\"user-events\", event);\n    }\n}\n\n// 5. Outbox pattern for reliable event publishing\n@Entity\npublic class OutboxEvent {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String aggregateType;\n    private String aggregateId;\n    private String eventType;\n    \n    @Column(columnDefinition = \"TEXT\")\n    private String payload;\n    \n    private LocalDateTime createdAt;\n    private boolean published;\n}\n\n@Service\npublic class OutboxService {\n    \n    @Transactional\n    public void saveWithOutbox(User user, Object event) {\n        userRepository.save(user);\n        \n        OutboxEvent outboxEvent = new OutboxEvent();\n        outboxEvent.setAggregateType(\"User\");\n        outboxEvent.setAggregateId(user.getId().toString());\n        outboxEvent.setEventType(event.getClass().getSimpleName());\n        outboxEvent.setPayload(serializeEvent(event));\n        outboxEvent.setCreatedAt(LocalDateTime.now());\n        \n        outboxRepository.save(outboxEvent);\n    }\n}"
    },
    {
      "id": 65,
      "question": "How do you implement Change Data Capture (CDC) with JPA?",
      "answer": "CDC captures and streams database changes:\n\nApproaches:\n1. Debezium: Kafka Connect based\n2. Polling: Query change tables\n3. Triggers: Database triggers\n4. Event Sourcing: Store all changes\n\nBenefits:\n• Real-time data sync\n• Microservices integration\n• Data warehouse ETL\n• Audit logging\n\nUse cases:\n• Cache invalidation\n• Search index updates\n• Analytics pipelines",
      "explanation": "CDC tracks database changes in real-time, enabling reactive data pipelines and keeping external systems synchronized.",
      "difficulty": "Expert",
      "code": "// 1. Change tracking entity\n@Entity\n@Table(name = \"entity_changes\")\npublic class EntityChange {\n    @Id\n    @GeneratedValue\n    private Long id;\n    \n    private String entityType;\n    private String entityId;\n    private String operation; // INSERT, UPDATE, DELETE\n    \n    @Column(columnDefinition = \"TEXT\")\n    private String oldValue;\n    \n    @Column(columnDefinition = \"TEXT\")\n    private String newValue;\n    \n    private LocalDateTime changedAt;\n    private String changedBy;\n}\n\n// 2. Entity listener for CDC\n@Component\npublic class ChangeDataCaptureListener {\n    \n    @Autowired\n    private EntityChangeRepository changeRepository;\n    \n    @PostPersist\n    public void onInsert(Object entity) {\n        captureChange(entity, \"INSERT\", null, serialize(entity));\n    }\n    \n    @PostUpdate\n    public void onUpdate(Object entity) {\n        // Capture before and after state\n        captureChange(entity, \"UPDATE\", getOldValue(entity), serialize(entity));\n    }\n    \n    @PostRemove\n    public void onDelete(Object entity) {\n        captureChange(entity, \"DELETE\", serialize(entity), null);\n    }\n    \n    private void captureChange(\n            Object entity,\n            String operation,\n            String oldValue,\n            String newValue) {\n        \n        EntityChange change = new EntityChange();\n        change.setEntityType(entity.getClass().getSimpleName());\n        change.setEntityId(getEntityId(entity));\n        change.setOperation(operation);\n        change.setOldValue(oldValue);\n        change.setNewValue(newValue);\n        change.setChangedAt(LocalDateTime.now());\n        change.setChangedBy(getCurrentUser());\n        \n        changeRepository.save(change);\n    }\n}\n\n// 3. Debezium integration (application.properties)\n/*\n# Kafka connector for Debezium\ndebezium.source.connector.class=io.debezium.connector.postgresql.PostgresConnector\ndebezium.source.database.hostname=localhost\ndebezium.source.database.port=5432\ndebezium.source.database.user=postgres\ndebezium.source.database.password=password\ndebezium.source.database.dbname=mydb\ndebezium.source.table.include.list=public.users,public.orders\n*/\n\n// 4. CDC event consumer\n@Component\npublic class CDCEventConsumer {\n    \n    @KafkaListener(topics = \"dbserver.public.users\")\n    public void consumeUserChanges(String message) {\n        // Parse Debezium CDC event\n        CDCEvent event = parseEvent(message);\n        \n        switch (event.getOperation()) {\n            case \"c\": // Create\n                handleUserCreated(event);\n                break;\n            case \"u\": // Update\n                handleUserUpdated(event);\n                break;\n            case \"d\": // Delete\n                handleUserDeleted(event);\n                break;\n        }\n    }\n    \n    private void handleUserCreated(CDCEvent event) {\n        // Update cache, search index, etc.\n        cacheService.invalidate(\"user:\" + event.getKey());\n        searchService.indexUser(event.getAfter());\n    }\n}\n\n// 5. Polling-based CDC\n@Service\npublic class PollingCDCService {\n    \n    @Scheduled(fixedRate = 5000) // Every 5 seconds\n    public void pollChanges() {\n        LocalDateTime lastPoll = getLastPollTime();\n        \n        List<EntityChange> changes = changeRepository\n            .findByChangedAtAfter(lastPoll);\n        \n        changes.forEach(this::processChange);\n        \n        updateLastPollTime(LocalDateTime.now());\n    }\n    \n    private void processChange(EntityChange change) {\n        // Publish to message broker\n        kafkaTemplate.send(\"entity-changes\", change);\n    }\n}"
    },
    {
      "id": 66,
      "question": "How do you implement pessimistic locking timeout handling in JPA?",
      "answer": "Timeout handling prevents indefinite lock waiting:\n\nConfiguration:\n• javax.persistence.lock.timeout\n• Query hints\n• Global timeout settings\n• NOWAIT option\n\nStrategies:\n• Fail immediately (NOWAIT)\n• Wait with timeout\n• Retry logic\n• User notification\n\nBest practices:\n• Set reasonable timeouts\n• Handle LockTimeoutException\n• Implement retry with backoff\n• Log lock contentions",
      "explanation": "Lock timeout handling prevents deadlocks and improves user experience by failing fast or implementing intelligent retry strategies.",
      "difficulty": "Medium",
      "code": "// 1. Repository with lock timeout\n@Repository\npublic interface AccountRepository extends JpaRepository<Account, Long> {\n    \n    @Lock(LockModeType.PESSIMISTIC_WRITE)\n    @QueryHints({\n        @QueryHint(name = \"javax.persistence.lock.timeout\", value = \"5000\")\n    })\n    Optional<Account> findByIdWithTimeout(Long id);\n    \n    @Lock(LockModeType.PESSIMISTIC_WRITE)\n    @QueryHints({\n        @QueryHint(name = \"javax.persistence.lock.timeout\", value = \"0\")\n    })\n    Optional<Account> findByIdNoWait(Long id);\n}\n\n// 2. Service with timeout handling\n@Service\npublic class AccountService {\n    \n    @Transactional\n    public void transferWithTimeout(Long fromId, Long toId, BigDecimal amount) {\n        try {\n            Account from = accountRepository\n                .findByIdWithTimeout(fromId)\n                .orElseThrow();\n            \n            Account to = accountRepository\n                .findByIdWithTimeout(toId)\n                .orElseThrow();\n            \n            from.withdraw(amount);\n            to.deposit(amount);\n            \n        } catch (LockTimeoutException e) {\n            throw new ServiceBusyException(\n                \"Account is currently locked. Please try again.\",\n                e\n            );\n        }\n    }\n}\n\n// 3. Retry logic with exponential backoff\n@Service\npublic class RetryableAccountService {\n    \n    @Retryable(\n        value = LockTimeoutException.class,\n        maxAttempts = 3,\n        backoff = @Backoff(delay = 1000, multiplier = 2)\n    )\n    @Transactional\n    public void transferWithRetry(\n            Long fromId,\n            Long toId,\n            BigDecimal amount) {\n        \n        Account from = accountRepository\n            .findByIdWithTimeout(fromId)\n            .orElseThrow();\n        \n        Account to = accountRepository\n            .findByIdWithTimeout(toId)\n            .orElseThrow();\n        \n        from.withdraw(amount);\n        to.deposit(amount);\n    }\n    \n    @Recover\n    public void recover(LockTimeoutException e, Long fromId, Long toId) {\n        log.error(\"Transfer failed after retries: {} -> {}\", fromId, toId);\n        throw new TransferFailedException(\"Unable to complete transfer\", e);\n    }\n}"
    },
    {
      "id": 67,
      "question": "How do you implement database partitioning strategies with JPA?",
      "answer": "Partitioning divides tables into smaller pieces:\n\nTypes:\n1. Range: By value ranges (dates, IDs)\n2. List: By discrete values\n3. Hash: By hash function\n4. Composite: Combination\n\nBenefits:\n• Improved query performance\n• Easier maintenance\n• Efficient archiving\n• Parallel processing\n\nJPA integration:\n• Transparent (database handles)\n• Partition pruning\n• Query optimization",
      "explanation": "Database partitioning improves performance by dividing large tables, with JPA queries automatically benefiting from partition pruning.",
      "difficulty": "Hard",
      "code": "// 1. Entity for partitioned table\n@Entity\n@Table(name = \"orders\")\npublic class Order {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private BigDecimal total;\n    \n    @Column(name = \"order_date\")\n    private LocalDate orderDate; // Partition key\n    \n    private String status;\n}\n\n// 2. PostgreSQL range partitioning (SQL)\n/*\nCREATE TABLE orders (\n    id BIGSERIAL,\n    total DECIMAL(10,2),\n    order_date DATE NOT NULL,\n    status VARCHAR(20),\n    PRIMARY KEY (id, order_date)\n) PARTITION BY RANGE (order_date);\n\nCREATE TABLE orders_2023 PARTITION OF orders\n    FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');\n\nCREATE TABLE orders_2024 PARTITION OF orders\n    FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\n\nCREATE TABLE orders_2025 PARTITION OF orders\n    FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');\n*/\n\n// 3. Repository queries (partition pruning automatic)\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    // Partition pruning: Only queries orders_2024\n    @Query(\"SELECT o FROM Order o WHERE o.orderDate BETWEEN :start AND :end\")\n    List<Order> findByDateRange(\n        @Param(\"start\") LocalDate start,\n        @Param(\"end\") LocalDate end\n    );\n    \n    // Queries single partition\n    List<Order> findByOrderDate(LocalDate date);\n}\n\n// 4. MySQL hash partitioning\n/*\nCREATE TABLE users (\n    id BIGINT PRIMARY KEY,\n    username VARCHAR(50),\n    email VARCHAR(100),\n    created_at TIMESTAMP\n) PARTITION BY HASH(id) PARTITIONS 8;\n*/\n\n// 5. Partition management service\n@Service\npublic class PartitionManagementService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Scheduled(cron = \"0 0 0 1 * *\") // First day of month\n    public void createNextMonthPartition() {\n        LocalDate nextMonth = LocalDate.now().plusMonths(1);\n        LocalDate monthAfter = nextMonth.plusMonths(1);\n        \n        String partitionName = \"orders_\" + \n            nextMonth.format(DateTimeFormatter.ofPattern(\"yyyy_MM\"));\n        \n        String sql = String.format(\n            \"CREATE TABLE IF NOT EXISTS %s PARTITION OF orders \" +\n            \"FOR VALUES FROM ('%s') TO ('%s')\",\n            partitionName,\n            nextMonth,\n            monthAfter\n        );\n        \n        entityManager.createNativeQuery(sql).executeUpdate();\n    }\n}"
    },
    {
      "id": 68,
      "question": "How do you implement data archiving strategies with JPA?",
      "answer": "Data archiving moves old data to archive storage:\n\nStrategies:\n1. Partition Dropping: Drop old partitions\n2. Archive Table: Move to separate table\n3. Cold Storage: Move to cheaper storage\n4. Soft Archive: Flag as archived\n\nSteps:\n• Identify archival criteria\n• Copy to archive\n• Verify copy\n• Delete from main\n• Schedule automation\n\nBenefits:\n• Improved performance\n• Reduced costs\n• Compliance",
      "explanation": "Archiving moves historical data from active tables to archive storage, improving query performance while retaining data for compliance.",
      "difficulty": "Medium",
      "code": "// 1. Archive entity\n@Entity\n@Table(name = \"orders_archive\")\npublic class OrderArchive {\n    @Id\n    private Long id;\n    \n    private BigDecimal total;\n    private LocalDate orderDate;\n    private String status;\n    private LocalDateTime archivedAt;\n}\n\n// 2. Archiving service\n@Service\npublic class DataArchivingService {\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @Autowired\n    private OrderArchiveRepository archiveRepository;\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    @Scheduled(cron = \"0 0 2 * * *\") // 2 AM daily\n    public void archiveOldOrders() {\n        LocalDate cutoffDate = LocalDate.now().minusYears(2);\n        \n        int batchSize = 1000;\n        int archivedCount = 0;\n        \n        while (true) {\n            List<Order> orders = orderRepository\n                .findTop1000ByOrderDateBeforeOrderById(cutoffDate);\n            \n            if (orders.isEmpty()) {\n                break;\n            }\n            \n            // Copy to archive\n            List<OrderArchive> archived = orders.stream()\n                .map(this::toArchive)\n                .collect(Collectors.toList());\n            \n            archiveRepository.saveAll(archived);\n            entityManager.flush();\n            \n            // Delete from main table\n            orderRepository.deleteAll(orders);\n            entityManager.flush();\n            entityManager.clear();\n            \n            archivedCount += orders.size();\n        }\n        \n        log.info(\"Archived {} orders\", archivedCount);\n    }\n    \n    private OrderArchive toArchive(Order order) {\n        OrderArchive archive = new OrderArchive();\n        archive.setId(order.getId());\n        archive.setTotal(order.getTotal());\n        archive.setOrderDate(order.getOrderDate());\n        archive.setStatus(order.getStatus());\n        archive.setArchivedAt(LocalDateTime.now());\n        return archive;\n    }\n}\n\n// 3. Partition-based archiving (PostgreSQL)\n@Service\npublic class PartitionArchivingService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Scheduled(cron = \"0 0 3 1 * *\") // 3 AM, first of month\n    public void archiveOldPartitions() {\n        // Detach old partition\n        String detachSql = \n            \"ALTER TABLE orders DETACH PARTITION orders_2022\";\n        entityManager.createNativeQuery(detachSql).executeUpdate();\n        \n        // Rename to archive\n        String renameSql = \n            \"ALTER TABLE orders_2022 RENAME TO orders_2022_archive\";\n        entityManager.createNativeQuery(renameSql).executeUpdate();\n        \n        // Optionally export to file or S3\n        exportPartition(\"orders_2022_archive\");\n    }\n}"
    },
    {
      "id": 69,
      "question": "How do you implement query result caching in JPA?",
      "answer": "Query result caching stores query results:\n\nTypes:\n1. Query Cache: Hibernate query cache\n2. Spring Cache: @Cacheable annotation\n3. Second-Level Cache: Entity cache\n\nConfiguration:\n• Enable query cache\n• Mark queries cacheable\n• Set cache regions\n• Define eviction policies\n\nBenefits:\n• Reduced database queries\n• Improved response time\n• Lower database load\n\nConsiderations:\n• Cache invalidation\n• Memory usage\n• Stale data",
      "explanation": "Query caching stores query results in memory, eliminating repeated database queries for identical queries with same parameters.",
      "difficulty": "Medium",
      "code": "// 1. Enable query cache (application.properties)\n/*\nspring.jpa.properties.hibernate.cache.use_query_cache=true\nspring.jpa.properties.hibernate.cache.use_second_level_cache=true\nspring.jpa.properties.hibernate.cache.region.factory_class=\n    org.hibernate.cache.jcache.JCacheRegionFactory\n*/\n\n// 2. Repository with query cache\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    @QueryHints({\n        @QueryHint(name = \"org.hibernate.cacheable\", value = \"true\"),\n        @QueryHint(name = \"org.hibernate.cacheRegion\", value = \"productsByCategory\")\n    })\n    @Query(\"SELECT p FROM Product p WHERE p.category = :category\")\n    List<Product> findByCategoryCached(@Param(\"category\") String category);\n    \n    @QueryHints(@QueryHint(name = \"org.hibernate.cacheable\", value = \"true\"))\n    List<Product> findByStatus(String status);\n}\n\n// 3. Spring Cache with @Cacheable\n@Service\npublic class ProductService {\n    \n    @Cacheable(value = \"products\", key = \"#category\")\n    public List<Product> getProductsByCategory(String category) {\n        return productRepository.findByCategory(category);\n    }\n    \n    @CacheEvict(value = \"products\", allEntries = true)\n    public void clearProductCache() {\n        // Evict all cached products\n    }\n    \n    @CachePut(value = \"products\", key = \"#product.id\")\n    public Product updateProduct(Product product) {\n        return productRepository.save(product);\n    }\n}\n\n// 4. Cache configuration\n@Configuration\n@EnableCaching\npublic class CacheConfig {\n    \n    @Bean\n    public CacheManager cacheManager() {\n        CaffeineCacheManager cacheManager = new CaffeineCacheManager(\n            \"products\", \"users\", \"orders\"\n        );\n        \n        cacheManager.setCaffeine(Caffeine.newBuilder()\n            .maximumSize(1000)\n            .expireAfterWrite(10, TimeUnit.MINUTES)\n            .recordStats()\n        );\n        \n        return cacheManager;\n    }\n}\n\n// 5. Selective cache invalidation\n@Service\npublic class CacheInvalidationService {\n    \n    @Autowired\n    private CacheManager cacheManager;\n    \n    @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT)\n    public void handleProductUpdated(ProductUpdatedEvent event) {\n        Cache cache = cacheManager.getCache(\"products\");\n        if (cache != null) {\n            cache.evict(event.getProductId());\n            cache.evict(event.getCategory()); // Evict category cache too\n        }\n    }\n}"
    },
    {
      "id": 70,
      "question": "How do you implement database connection health checks in JPA?",
      "answer": "Health checks monitor database connectivity:\n\nImplementation:\n• Spring Actuator /health\n• Custom HealthIndicator\n• Connection validation\n• Query timeouts\n• Connection pool monitoring\n\nMetrics:\n• Connection availability\n• Response time\n• Pool statistics\n• Failed queries\n\nBenefits:\n• Early problem detection\n• Proactive monitoring\n• Load balancer integration\n• Alerting",
      "explanation": "Health checks verify database availability and performance, enabling monitoring systems to detect issues before users are affected.",
      "difficulty": "Easy",
      "code": "// 1. Spring Boot Actuator (automatic)\n/*\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n\napplication.properties:\nmanagement.endpoints.web.exposure.include=health,info\nmanagement.endpoint.health.show-details=always\n*/\n\n// 2. Custom database health indicator\n@Component\npublic class DatabaseHealthIndicator implements HealthIndicator {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public Health health() {\n        try {\n            long startTime = System.currentTimeMillis();\n            \n            // Execute simple query\n            entityManager.createNativeQuery(\"SELECT 1\")\n                .getSingleResult();\n            \n            long responseTime = System.currentTimeMillis() - startTime;\n            \n            return Health.up()\n                .withDetail(\"database\", \"available\")\n                .withDetail(\"responseTime\", responseTime + \"ms\")\n                .build();\n                \n        } catch (Exception e) {\n            return Health.down()\n                .withDetail(\"error\", e.getMessage())\n                .withException(e)\n                .build();\n        }\n    }\n}\n\n// 3. Connection pool health\n@Component\npublic class ConnectionPoolHealthIndicator implements HealthIndicator {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Override\n    public Health health() {\n        if (dataSource instanceof HikariDataSource) {\n            HikariDataSource hikari = (HikariDataSource) dataSource;\n            HikariPoolMXBean pool = hikari.getHikariPoolMXBean();\n            \n            int active = pool.getActiveConnections();\n            int idle = pool.getIdleConnections();\n            int total = pool.getTotalConnections();\n            int waiting = pool.getThreadsAwaitingConnection();\n            \n            Health.Builder builder = Health.up();\n            \n            builder.withDetail(\"pool\", Map.of(\n                \"active\", active,\n                \"idle\", idle,\n                \"total\", total,\n                \"waiting\", waiting,\n                \"max\", hikari.getMaximumPoolSize()\n            ));\n            \n            // Warning if pool nearly exhausted\n            if (active >= hikari.getMaximumPoolSize() * 0.9) {\n                builder.status(\"WARNING\")\n                    .withDetail(\"warning\", \"Connection pool nearly exhausted\");\n            }\n            \n            return builder.build();\n        }\n        \n        return Health.unknown().build();\n    }\n}\n\n// 4. Scheduled health monitoring\n@Component\npublic class DatabaseHealthMonitor {\n    \n    @Autowired\n    private HealthIndicator databaseHealthIndicator;\n    \n    @Scheduled(fixedRate = 60000) // Every minute\n    public void monitorHealth() {\n        Health health = databaseHealthIndicator.health();\n        \n        if (health.getStatus() != Status.UP) {\n            log.error(\"Database health check failed: {}\", health);\n            alertService.sendAlert(\"Database Unhealthy\", health.toString());\n        }\n    }\n}"
    },
    {
      "id": 71,
      "question": "How do you implement JSON/JSONB columns in JPA?",
      "answer": "JSON columns store structured data in databases:\n\nDatabase Support:\n• PostgreSQL: JSONB type\n• MySQL: JSON type\n• Oracle: JSON columns\n\nImplementation:\n• AttributeConverter\n• Hibernate custom types\n• Native queries for JSON ops\n\nBenefits:\n• Flexible schema\n• Nested data storage\n• Efficient querying\n• No joins needed",
      "explanation": "JSON columns allow storing complex objects directly in database, with native support for querying nested fields.",
      "difficulty": "Medium",
      "code": "// 1. Entity with JSON column\n@Entity\npublic class Product {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    \n    @Column(columnDefinition = \"jsonb\")\n    @Convert(converter = JsonAttributeConverter.class)\n    private Map<String, Object> attributes;\n    \n    @Column(columnDefinition = \"jsonb\")\n    @Convert(converter = MetadataConverter.class)\n    private Metadata metadata;\n}\n\n// 2. JSON AttributeConverter\n@Converter\npublic class JsonAttributeConverter \n        implements AttributeConverter<Map<String, Object>, String> {\n    \n    private final ObjectMapper objectMapper = new ObjectMapper();\n    \n    @Override\n    public String convertToDatabaseColumn(Map<String, Object> attribute) {\n        if (attribute == null) return null;\n        \n        try {\n            return objectMapper.writeValueAsString(attribute);\n        } catch (JsonProcessingException e) {\n            throw new RuntimeException(\"Failed to convert to JSON\", e);\n        }\n    }\n    \n    @Override\n    public Map<String, Object> convertToEntityAttribute(String dbData) {\n        if (dbData == null) return null;\n        \n        try {\n            return objectMapper.readValue(\n                dbData,\n                new TypeReference<Map<String, Object>>() {}\n            );\n        } catch (JsonProcessingException e) {\n            throw new RuntimeException(\"Failed to parse JSON\", e);\n        }\n    }\n}\n\n// 3. PostgreSQL JSONB queries\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    // Query JSON field\n    @Query(value = \n        \"SELECT * FROM products WHERE attributes->>'color' = :color\",\n        nativeQuery = true)\n    List<Product> findByColor(@Param(\"color\") String color);\n    \n    // JSON contains\n    @Query(value = \n        \"SELECT * FROM products WHERE attributes @> :json::jsonb\",\n        nativeQuery = true)\n    List<Product> findByAttributes(@Param(\"json\") String json);\n    \n    // Nested JSON query\n    @Query(value = \n        \"SELECT * FROM products WHERE \" +\n        \"attributes->'dimensions'->>'width' > :width\",\n        nativeQuery = true)\n    List<Product> findByWidth(@Param(\"width\") String width);\n}\n\n// 4. Custom POJO in JSON\npublic class Metadata {\n    private String author;\n    private LocalDateTime createdAt;\n    private List<String> tags;\n    // getters/setters\n}\n\n@Converter\npublic class MetadataConverter \n        implements AttributeConverter<Metadata, String> {\n    \n    private final ObjectMapper mapper = new ObjectMapper()\n        .registerModule(new JavaTimeModule());\n    \n    @Override\n    public String convertToDatabaseColumn(Metadata metadata) {\n        try {\n            return mapper.writeValueAsString(metadata);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n    \n    @Override\n    public Metadata convertToEntityAttribute(String dbData) {\n        try {\n            return mapper.readValue(dbData, Metadata.class);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n}"
    },
    {
      "id": 72,
      "question": "How do you implement array columns in JPA?",
      "answer": "Array columns store multiple values in single field:\n\nDatabase Support:\n• PostgreSQL: Native arrays\n• Other DBs: Workarounds needed\n\nTypes:\n• Primitive arrays (Integer[], String[])\n• Custom type arrays\n\nImplementation:\n• Hibernate custom type\n• Native queries\n• @Type annotation\n\nUse cases:\n• Tags/labels\n• Categories\n• Permissions\n• Simple lists",
      "explanation": "Array columns efficiently store collections without separate join tables, ideal for simple lists in PostgreSQL.",
      "difficulty": "Medium",
      "code": "// 1. Entity with array column (PostgreSQL)\n@Entity\n@Table(name = \"articles\")\npublic class Article {\n    @Id\n    private Long id;\n    \n    private String title;\n    \n    @Type(type = \"string-array\")\n    @Column(\n        name = \"tags\",\n        columnDefinition = \"text[]\"\n    )\n    private String[] tags;\n    \n    @Type(type = \"int-array\")\n    @Column(\n        name = \"category_ids\",\n        columnDefinition = \"integer[]\"\n    )\n    private Integer[] categoryIds;\n}\n\n// 2. Hibernate custom type for string arrays\npublic class StringArrayType extends AbstractSingleColumnStandardBasicType<String[]> {\n    \n    public static final StringArrayType INSTANCE = new StringArrayType();\n    \n    public StringArrayType() {\n        super(\n            ArraySqlTypeDescriptor.INSTANCE,\n            StringArrayTypeDescriptor.INSTANCE\n        );\n    }\n    \n    @Override\n    public String getName() {\n        return \"string-array\";\n    }\n}\n\n// 3. Repository with array queries\n@Repository\npublic interface ArticleRepository extends JpaRepository<Article, Long> {\n    \n    // Array contains\n    @Query(value = \n        \"SELECT * FROM articles WHERE :tag = ANY(tags)\",\n        nativeQuery = true)\n    List<Article> findByTag(@Param(\"tag\") String tag);\n    \n    // Array overlap\n    @Query(value = \n        \"SELECT * FROM articles WHERE tags && :tags\",\n        nativeQuery = true)\n    List<Article> findByAnyTags(@Param(\"tags\") String[] tags);\n    \n    // Array contains all\n    @Query(value = \n        \"SELECT * FROM articles WHERE tags @> :tags\",\n        nativeQuery = true)\n    List<Article> findByAllTags(@Param(\"tags\") String[] tags);\n}\n\n// 4. Service with array operations\n@Service\npublic class ArticleService {\n    \n    @Transactional\n    public Article createArticle(String title, List<String> tags) {\n        Article article = new Article();\n        article.setTitle(title);\n        article.setTags(tags.toArray(new String[0]));\n        return articleRepository.save(article);\n    }\n    \n    public List<Article> searchByTags(List<String> tags) {\n        return articleRepository.findByAnyTags(\n            tags.toArray(new String[0])\n        );\n    }\n}"
    },
    {
      "id": 73,
      "question": "How do you implement spatial/geographic data in JPA?",
      "answer": "Spatial data handles geographic coordinates and geometries:\n\nTypes:\n• Point: Single location\n• LineString: Path/route\n• Polygon: Area/boundary\n• MultiPoint/MultiPolygon\n\nLibraries:\n• Hibernate Spatial\n• JTS (Java Topology Suite)\n• PostGIS (PostgreSQL)\n\nOperations:\n• Distance calculations\n• Within radius queries\n• Intersection checks\n• Spatial indexing",
      "explanation": "Spatial data types enable location-based queries like \"find all stores within 5km\" using database-native geographic functions.",
      "difficulty": "Hard",
      "code": "// 1. Add dependencies\n/*\n<dependency>\n    <groupId>org.hibernate</groupId>\n    <artifactId>hibernate-spatial</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.locationtech.jts</groupId>\n    <artifactId>jts-core</artifactId>\n</dependency>\n*/\n\n// 2. Entity with spatial column\n@Entity\npublic class Store {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    \n    @Column(columnDefinition = \"geometry(Point,4326)\")\n    private Point location;\n    \n    @Column(columnDefinition = \"geometry(Polygon,4326)\")\n    private Polygon deliveryArea;\n}\n\n// 3. Creating spatial objects\n@Service\npublic class StoreService {\n    \n    private final GeometryFactory geometryFactory = \n        new GeometryFactory(new PrecisionModel(), 4326);\n    \n    @Transactional\n    public Store createStore(\n            String name,\n            double latitude,\n            double longitude) {\n        \n        Store store = new Store();\n        store.setName(name);\n        \n        Point location = geometryFactory.createPoint(\n            new Coordinate(longitude, latitude)\n        );\n        store.setLocation(location);\n        \n        return storeRepository.save(store);\n    }\n}\n\n// 4. Spatial queries\n@Repository\npublic interface StoreRepository extends JpaRepository<Store, Long> {\n    \n    // Find stores within distance\n    @Query(value = \n        \"SELECT * FROM stores \" +\n        \"WHERE ST_DWithin(location, ST_Point(:lng, :lat, 4326), :distance)\",\n        nativeQuery = true)\n    List<Store> findWithinDistanceMeters(\n        @Param(\"lat\") double latitude,\n        @Param(\"lng\") double longitude,\n        @Param(\"distance\") double meters\n    );\n    \n    // Find stores within polygon\n    @Query(value = \n        \"SELECT * FROM stores \" +\n        \"WHERE ST_Within(location, ST_GeomFromText(:polygon, 4326))\",\n        nativeQuery = true)\n    List<Store> findWithinArea(@Param(\"polygon\") String wkt);\n    \n    // Order by distance\n    @Query(value = \n        \"SELECT *, ST_Distance(location, ST_Point(:lng, :lat, 4326)) as distance \" +\n        \"FROM stores \" +\n        \"ORDER BY distance LIMIT :limit\",\n        nativeQuery = true)\n    List<Store> findNearestStores(\n        @Param(\"lat\") double latitude,\n        @Param(\"lng\") double longitude,\n        @Param(\"limit\") int limit\n    );\n}\n\n// 5. Distance calculation\n@Service\npublic class LocationService {\n    \n    public double calculateDistance(Store store1, Store store2) {\n        Point p1 = store1.getLocation();\n        Point p2 = store2.getLocation();\n        \n        // Distance in meters using JTS\n        return p1.distance(p2) * 111320; // ~111km per degree\n    }\n    \n    public boolean isWithinDeliveryArea(Store store, Point customerLocation) {\n        return store.getDeliveryArea().contains(customerLocation);\n    }\n}"
    },
    {
      "id": 74,
      "question": "How do you implement database views in JPA?",
      "answer": "Database views provide virtual tables based on queries:\n\nImplementation:\n1. Create view in database\n2. Map as @Immutable entity\n3. Use @Subselect for dynamic views\n4. Read-only operations\n\nBenefits:\n• Simplified complex queries\n• Denormalization\n• Security (hide columns)\n• Performance (materialized views)\n\nUse cases:\n• Reporting\n• Aggregations\n• Joining multiple tables\n• Legacy database integration",
      "explanation": "Views provide simplified read-only access to complex query results, mapped as JPA entities with @Immutable annotation.",
      "difficulty": "Medium",
      "code": "// 1. Create database view\n/*\nCREATE VIEW order_summary AS\nSELECT \n    o.id,\n    o.order_date,\n    o.status,\n    u.username as customer_name,\n    COUNT(oi.id) as item_count,\n    SUM(oi.quantity * oi.price) as total_amount\nFROM orders o\nJOIN users u ON o.user_id = u.id\nJOIN order_items oi ON o.id = oi.order_id\nGROUP BY o.id, o.order_date, o.status, u.username;\n*/\n\n// 2. Map view as entity\n@Entity\n@Immutable // Read-only\n@Table(name = \"order_summary\")\npublic class OrderSummaryView {\n    @Id\n    private Long id;\n    \n    @Column(name = \"order_date\")\n    private LocalDate orderDate;\n    \n    private String status;\n    \n    @Column(name = \"customer_name\")\n    private String customerName;\n    \n    @Column(name = \"item_count\")\n    private Long itemCount;\n    \n    @Column(name = \"total_amount\")\n    private BigDecimal totalAmount;\n    \n    // Only getters, no setters (immutable)\n}\n\n// 3. Repository for view\n@Repository\npublic interface OrderSummaryRepository \n        extends JpaRepository<OrderSummaryView, Long> {\n    \n    List<OrderSummaryView> findByStatus(String status);\n    \n    List<OrderSummaryView> findByOrderDateBetween(\n        LocalDate start,\n        LocalDate end\n    );\n}\n\n// 4. @Subselect for dynamic view\n@Entity\n@Immutable\n@Subselect(\n    \"SELECT p.id, p.name, p.price, \" +\n    \"       AVG(r.rating) as avg_rating, \" +\n    \"       COUNT(r.id) as review_count \" +\n    \"FROM products p \" +\n    \"LEFT JOIN reviews r ON p.id = r.product_id \" +\n    \"GROUP BY p.id, p.name, p.price\"\n)\npublic class ProductRatingView {\n    @Id\n    private Long id;\n    \n    private String name;\n    private BigDecimal price;\n    \n    @Column(name = \"avg_rating\")\n    private Double avgRating;\n    \n    @Column(name = \"review_count\")\n    private Long reviewCount;\n}\n\n// 5. Materialized view (PostgreSQL)\n/*\nCREATE MATERIALIZED VIEW daily_sales AS\nSELECT \n    DATE(order_date) as sale_date,\n    COUNT(*) as order_count,\n    SUM(total) as total_sales\nFROM orders\nWHERE status = 'COMPLETED'\nGROUP BY DATE(order_date);\n\nCREATE INDEX idx_daily_sales_date ON daily_sales(sale_date);\n*/\n\n@Entity\n@Immutable\n@Table(name = \"daily_sales\")\npublic class DailySalesView {\n    @Id\n    @Column(name = \"sale_date\")\n    private LocalDate saleDate;\n    \n    @Column(name = \"order_count\")\n    private Long orderCount;\n    \n    @Column(name = \"total_sales\")\n    private BigDecimal totalSales;\n}\n\n// Refresh materialized view\n@Service\npublic class ViewRefreshService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Scheduled(cron = \"0 0 * * * *\") // Hourly\n    public void refreshMaterializedViews() {\n        entityManager.createNativeQuery(\n            \"REFRESH MATERIALIZED VIEW CONCURRENTLY daily_sales\"\n        ).executeUpdate();\n    }\n}"
    },
    {
      "id": 75,
      "question": "How do you implement composite keys in JPA?",
      "answer": "Composite keys use multiple columns as primary key:\n\nApproaches:\n1. @IdClass: Separate ID class\n2. @EmbeddedId: Embedded ID class\n\nRequirements:\n• Implement Serializable\n• Override equals() and hashCode()\n• Public no-arg constructor\n\nUse cases:\n• Many-to-many join tables\n• Legacy databases\n• Natural keys\n• Multi-tenant data",
      "explanation": "Composite keys combine multiple fields into a single primary key, useful for join tables and legacy database integration.",
      "difficulty": "Medium",
      "code": "// 1. @EmbeddedId approach (preferred)\n@Embeddable\npublic class OrderItemId implements Serializable {\n    \n    @Column(name = \"order_id\")\n    private Long orderId;\n    \n    @Column(name = \"product_id\")\n    private Long productId;\n    \n    // No-arg constructor\n    public OrderItemId() {}\n    \n    public OrderItemId(Long orderId, Long productId) {\n        this.orderId = orderId;\n        this.productId = productId;\n    }\n    \n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (!(o instanceof OrderItemId)) return false;\n        OrderItemId that = (OrderItemId) o;\n        return Objects.equals(orderId, that.orderId) &&\n               Objects.equals(productId, that.productId);\n    }\n    \n    @Override\n    public int hashCode() {\n        return Objects.hash(orderId, productId);\n    }\n}\n\n@Entity\n@Table(name = \"order_items\")\npublic class OrderItem {\n    \n    @EmbeddedId\n    private OrderItemId id;\n    \n    @ManyToOne\n    @MapsId(\"orderId\") // Maps orderId to order.id\n    @JoinColumn(name = \"order_id\")\n    private Order order;\n    \n    @ManyToOne\n    @MapsId(\"productId\") // Maps productId to product.id\n    @JoinColumn(name = \"product_id\")\n    private Product product;\n    \n    private Integer quantity;\n    private BigDecimal price;\n}\n\n// 2. @IdClass approach\n@IdClass(UserRoleId.class)\n@Entity\n@Table(name = \"user_roles\")\npublic class UserRole {\n    \n    @Id\n    @Column(name = \"user_id\")\n    private Long userId;\n    \n    @Id\n    @Column(name = \"role_id\")\n    private Long roleId;\n    \n    @ManyToOne\n    @JoinColumn(name = \"user_id\", insertable = false, updatable = false)\n    private User user;\n    \n    @ManyToOne\n    @JoinColumn(name = \"role_id\", insertable = false, updatable = false)\n    private Role role;\n    \n    private LocalDateTime assignedAt;\n}\n\npublic class UserRoleId implements Serializable {\n    private Long userId;\n    private Long roleId;\n    \n    // equals(), hashCode(), constructors\n}\n\n// 3. Repository with composite key\npublic interface OrderItemRepository \n        extends JpaRepository<OrderItem, OrderItemId> {\n    \n    List<OrderItem> findByIdOrderId(Long orderId);\n    \n    List<OrderItem> findByIdProductId(Long productId);\n    \n    @Query(\"SELECT oi FROM OrderItem oi WHERE oi.id.orderId = :orderId\")\n    List<OrderItem> findByOrderId(@Param(\"orderId\") Long orderId);\n}\n\n// 4. Service using composite key\n@Service\npublic class OrderItemService {\n    \n    @Transactional\n    public OrderItem addItemToOrder(\n            Long orderId,\n            Long productId,\n            Integer quantity) {\n        \n        OrderItemId id = new OrderItemId(orderId, productId);\n        \n        OrderItem item = new OrderItem();\n        item.setId(id);\n        item.setQuantity(quantity);\n        \n        return orderItemRepository.save(item);\n    }\n    \n    public Optional<OrderItem> findItem(Long orderId, Long productId) {\n        OrderItemId id = new OrderItemId(orderId, productId);\n        return orderItemRepository.findById(id);\n    }\n}"
    },
    {
      "id": 76,
      "question": "How do you implement time-series data in JPA?",
      "answer": "Time-series data requires optimization for temporal queries:\n\nStrategies:\n• Time-based partitioning\n• TimescaleDB extension\n• Indexing on timestamps\n• Retention policies\n• Downsampling aggregates\n\nOptimizations:\n• Batch inserts\n• Append-only pattern\n• Compression\n• Columnar storage\n\nUse cases:\n• Sensor data\n• Logs/metrics\n• Financial data\n• Analytics",
      "explanation": "Time-series data benefits from specialized patterns like partitioning and append-only operations to handle high-volume temporal data efficiently.",
      "difficulty": "Hard",
      "code": "// 1. Time-series entity\n@Entity\n@Table(\n    name = \"sensor_readings\",\n    indexes = {\n        @Index(name = \"idx_sensor_time\", columnList = \"sensor_id,timestamp\"),\n        @Index(name = \"idx_timestamp\", columnList = \"timestamp DESC\")\n    }\n)\npublic class SensorReading {\n    \n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    @Column(name = \"sensor_id\", nullable = false)\n    private String sensorId;\n    \n    @Column(nullable = false)\n    private LocalDateTime timestamp;\n    \n    private Double temperature;\n    private Double humidity;\n    private Double pressure;\n    \n    @Column(columnDefinition = \"jsonb\")\n    @Convert(converter = JsonAttributeConverter.class)\n    private Map<String, Object> metadata;\n}\n\n// 2. TimescaleDB hypertable (PostgreSQL extension)\n/*\n-- Enable TimescaleDB\nCREATE EXTENSION IF NOT EXISTS timescaledb;\n\n-- Convert to hypertable\nSELECT create_hypertable('sensor_readings', 'timestamp');\n\n-- Add compression policy\nALTER TABLE sensor_readings SET (\n    timescaledb.compress,\n    timescaledb.compress_segmentby = 'sensor_id'\n);\n\nSELECT add_compression_policy('sensor_readings', INTERVAL '7 days');\n\n-- Add retention policy\nSELECT add_retention_policy('sensor_readings', INTERVAL '90 days');\n*/\n\n// 3. Repository with time-series queries\n@Repository\npublic interface SensorReadingRepository \n        extends JpaRepository<SensorReading, Long> {\n    \n    // Recent readings\n    List<SensorReading> findTop100BySensorIdOrderByTimestampDesc(\n        String sensorId\n    );\n    \n    // Time range query\n    @Query(\"SELECT sr FROM SensorReading sr \" +\n           \"WHERE sr.sensorId = :sensorId \" +\n           \"AND sr.timestamp BETWEEN :start AND :end \" +\n           \"ORDER BY sr.timestamp\")\n    List<SensorReading> findByTimeRange(\n        @Param(\"sensorId\") String sensorId,\n        @Param(\"start\") LocalDateTime start,\n        @Param(\"end\") LocalDateTime end\n    );\n    \n    // Time bucket aggregation (TimescaleDB)\n    @Query(value = \n        \"SELECT \" +\n        \"  time_bucket('5 minutes', timestamp) AS bucket, \" +\n        \"  sensor_id, \" +\n        \"  AVG(temperature) as avg_temp, \" +\n        \"  MAX(temperature) as max_temp, \" +\n        \"  MIN(temperature) as min_temp \" +\n        \"FROM sensor_readings \" +\n        \"WHERE sensor_id = :sensorId \" +\n        \"  AND timestamp >= :start \" +\n        \"GROUP BY bucket, sensor_id \" +\n        \"ORDER BY bucket DESC\",\n        nativeQuery = true)\n    List<Object[]> getAggregatedReadings(\n        @Param(\"sensorId\") String sensorId,\n        @Param(\"start\") LocalDateTime start\n    );\n}\n\n// 4. Batch insert service\n@Service\npublic class SensorDataService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void batchInsert(List<SensorReading> readings) {\n        int batchSize = 100;\n        \n        for (int i = 0; i < readings.size(); i++) {\n            entityManager.persist(readings.get(i));\n            \n            if (i % batchSize == 0 && i > 0) {\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n    }\n    \n    @Transactional(readOnly = true)\n    public List<SensorSummary> getHourlySummary(\n            String sensorId,\n            LocalDateTime start,\n            LocalDateTime end) {\n        \n        String sql = \n            \"SELECT \" +\n            \"  time_bucket('1 hour', timestamp) as hour, \" +\n            \"  AVG(temperature) as avg_temp, \" +\n            \"  COUNT(*) as reading_count \" +\n            \"FROM sensor_readings \" +\n            \"WHERE sensor_id = :sensorId \" +\n            \"  AND timestamp BETWEEN :start AND :end \" +\n            \"GROUP BY hour \" +\n            \"ORDER BY hour\";\n        \n        return entityManager\n            .createNativeQuery(sql)\n            .setParameter(\"sensorId\", sensorId)\n            .setParameter(\"start\", start)\n            .setParameter(\"end\", end)\n            .getResultStream()\n            .map(this::mapToSummary)\n            .collect(Collectors.toList());\n    }\n}\n\n// 5. Continuous aggregate (materialized view)\n/*\nCREATE MATERIALIZED VIEW sensor_hourly_avg\nWITH (timescaledb.continuous) AS\nSELECT \n    time_bucket('1 hour', timestamp) AS hour,\n    sensor_id,\n    AVG(temperature) as avg_temperature,\n    AVG(humidity) as avg_humidity,\n    COUNT(*) as reading_count\nFROM sensor_readings\nGROUP BY hour, sensor_id;\n\nSELECT add_continuous_aggregate_policy('sensor_hourly_avg',\n    start_offset => INTERVAL '3 hours',\n    end_offset => INTERVAL '1 hour',\n    schedule_interval => INTERVAL '1 hour');\n*/"
    },
    {
      "id": 77,
      "question": "How do you implement database triggers from JPA?",
      "answer": "Triggers execute automatically on database events:\n\nTypes:\n• BEFORE INSERT/UPDATE/DELETE\n• AFTER INSERT/UPDATE/DELETE\n• INSTEAD OF (views)\n\nJPA Integration:\n• Can't create triggers via JPA\n• Use migrations (Flyway/Liquibase)\n• @PrePersist/@PostPersist for Java-side\n• Native SQL for trigger creation\n\nUse cases:\n• Audit logging\n• Data validation\n• Denormalization\n• Complex constraints",
      "explanation": "While JPA doesn't create triggers, they can be managed through migrations and work transparently with JPA entities for database-level automation.",
      "difficulty": "Medium",
      "code": "// 1. Create trigger via Flyway migration\n/*\n-- V1__create_audit_trigger.sql\n\nCREATE TABLE order_audit (\n    audit_id BIGSERIAL PRIMARY KEY,\n    order_id BIGINT NOT NULL,\n    action VARCHAR(10) NOT NULL,\n    old_status VARCHAR(50),\n    new_status VARCHAR(50),\n    changed_by VARCHAR(100),\n    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Trigger function\nCREATE OR REPLACE FUNCTION audit_order_changes()\nRETURNS TRIGGER AS $$\nBEGIN\n    IF TG_OP = 'UPDATE' AND OLD.status != NEW.status THEN\n        INSERT INTO order_audit (\n            order_id,\n            action,\n            old_status,\n            new_status,\n            changed_by\n        ) VALUES (\n            NEW.id,\n            'UPDATE',\n            OLD.status,\n            NEW.status,\n            current_user\n        );\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Create trigger\nCREATE TRIGGER order_status_audit\nAFTER UPDATE ON orders\nFOR EACH ROW\nEXECUTE FUNCTION audit_order_changes();\n*/\n\n// 2. Entity (trigger works transparently)\n@Entity\n@Table(name = \"orders\")\npublic class Order {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String status;\n    private LocalDateTime updatedAt;\n    \n    // When status changes, trigger fires automatically\n}\n\n// 3. Audit log entity (populated by trigger)\n@Entity\n@Table(name = \"order_audit\")\n@Immutable\npublic class OrderAudit {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(name = \"audit_id\")\n    private Long auditId;\n    \n    @Column(name = \"order_id\")\n    private Long orderId;\n    \n    private String action;\n    \n    @Column(name = \"old_status\")\n    private String oldStatus;\n    \n    @Column(name = \"new_status\")\n    private String newStatus;\n    \n    @Column(name = \"changed_by\")\n    private String changedBy;\n    \n    @Column(name = \"changed_at\")\n    private LocalDateTime changedAt;\n}\n\n// 4. Advanced trigger: Auto-update timestamp\n/*\n-- Trigger for updated_at column\nCREATE OR REPLACE FUNCTION update_timestamp()\nRETURNS TRIGGER AS $$\nBEGIN\n    NEW.updated_at = CURRENT_TIMESTAMP;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER set_timestamp\nBEFORE UPDATE ON orders\nFOR EACH ROW\nEXECUTE FUNCTION update_timestamp();\n*/\n\n// 5. Trigger for data validation\n/*\nCREATE OR REPLACE FUNCTION validate_order_total()\nRETURNS TRIGGER AS $$\nBEGIN\n    IF NEW.total_amount < 0 THEN\n        RAISE EXCEPTION 'Order total cannot be negative';\n    END IF;\n    \n    IF NEW.total_amount > 100000 THEN\n        -- Log large order for review\n        INSERT INTO large_orders_review (order_id, amount)\n        VALUES (NEW.id, NEW.total_amount);\n    END IF;\n    \n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER check_order_total\nBEFORE INSERT OR UPDATE ON orders\nFOR EACH ROW\nEXECUTE FUNCTION validate_order_total();\n*/\n\n// Java service (trigger executes automatically)\n@Service\npublic class OrderService {\n    \n    @Transactional\n    public Order updateOrderStatus(Long orderId, String newStatus) {\n        Order order = orderRepository.findById(orderId)\n            .orElseThrow();\n        \n        order.setStatus(newStatus);\n        // Trigger fires on save, creates audit entry\n        return orderRepository.save(order);\n    }\n    \n    public List<OrderAudit> getOrderHistory(Long orderId) {\n        return orderAuditRepository.findByOrderId(orderId);\n    }\n}"
    },
    {
      "id": 78,
      "question": "How do you implement database sequences custom strategies in JPA?",
      "answer": "Custom sequence strategies provide flexible ID generation:\n\nBuilt-in Strategies:\n• AUTO: Provider chooses\n• IDENTITY: Auto-increment\n• SEQUENCE: Database sequence\n• TABLE: Sequence table\n\nCustom Strategies:\n• IdentifierGenerator interface\n• Pooled sequences\n• Formatted IDs (e.g., INV-00001)\n• Time-based IDs\n• Composite generators\n\nConfiguration:\n• @GenericGenerator\n• @Parameter annotations\n• Hibernate-specific",
      "explanation": "Custom ID generators enable business-specific ID formats like order numbers, invoice codes, or optimized strategies for high-volume inserts.",
      "difficulty": "Hard",
      "code": "// 1. Custom formatted ID generator\npublic class FormattedIdGenerator implements IdentifierGenerator {\n    \n    @Override\n    public Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        String prefix = \"INV\";\n        \n        String query = String.format(\n            \"SELECT MAX(CAST(SUBSTRING(id, %d) AS INTEGER)) FROM %s\",\n            prefix.length() + 2,\n            object.getClass().getSimpleName()\n        );\n        \n        Integer maxId = (Integer) session\n            .createQuery(query)\n            .uniqueResult();\n        \n        int nextId = (maxId == null) ? 1 : maxId + 1;\n        \n        return String.format(\"%s-%05d\", prefix, nextId);\n    }\n}\n\n@Entity\npublic class Invoice {\n    @Id\n    @GenericGenerator(\n        name = \"invoice_id_generator\",\n        strategy = \"com.example.FormattedIdGenerator\"\n    )\n    @GeneratedValue(generator = \"invoice_id_generator\")\n    private String id; // INV-00001, INV-00002, etc.\n    \n    private BigDecimal amount;\n}\n\n// 2. Time-based ID generator (Twitter Snowflake-like)\npublic class SnowflakeIdGenerator implements IdentifierGenerator {\n    \n    private static final long EPOCH = 1609459200000L; // 2021-01-01\n    private static final long WORKER_ID_BITS = 10L;\n    private static final long SEQUENCE_BITS = 12L;\n    \n    private final long workerId;\n    private long sequence = 0L;\n    private long lastTimestamp = -1L;\n    \n    public SnowflakeIdGenerator() {\n        this.workerId = getWorkerId(); // From config\n    }\n    \n    @Override\n    public synchronized Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        long timestamp = System.currentTimeMillis();\n        \n        if (timestamp == lastTimestamp) {\n            sequence = (sequence + 1) & ((1L << SEQUENCE_BITS) - 1);\n            if (sequence == 0) {\n                timestamp = waitNextMillis(lastTimestamp);\n            }\n        } else {\n            sequence = 0L;\n        }\n        \n        lastTimestamp = timestamp;\n        \n        return ((timestamp - EPOCH) << (WORKER_ID_BITS + SEQUENCE_BITS))\n            | (workerId << SEQUENCE_BITS)\n            | sequence;\n    }\n    \n    private long waitNextMillis(long lastTimestamp) {\n        long timestamp = System.currentTimeMillis();\n        while (timestamp <= lastTimestamp) {\n            timestamp = System.currentTimeMillis();\n        }\n        return timestamp;\n    }\n}\n\n@Entity\npublic class Order {\n    @Id\n    @GenericGenerator(\n        name = \"snowflake_id\",\n        strategy = \"com.example.SnowflakeIdGenerator\"\n    )\n    @GeneratedValue(generator = \"snowflake_id\")\n    private Long id;\n}\n\n// 3. Pooled sequence generator (high performance)\npublic class PooledSequenceGenerator implements IdentifierGenerator {\n    \n    private static final int POOL_SIZE = 50;\n    private long currentValue;\n    private long maxValue;\n    private final Object lock = new Object();\n    \n    @Override\n    public Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        synchronized (lock) {\n            if (currentValue >= maxValue) {\n                allocatePool(session);\n            }\n            return ++currentValue;\n        }\n    }\n    \n    private void allocatePool(SharedSessionContractImplementor session) {\n        String sql = \"SELECT nextval('my_sequence')\";\n        BigInteger next = (BigInteger) session\n            .createNativeQuery(sql)\n            .uniqueResult();\n        \n        currentValue = next.longValue();\n        maxValue = currentValue + POOL_SIZE;\n    }\n}\n\n// 4. Composite ID generator (tenant + sequence)\npublic class TenantSequenceGenerator implements IdentifierGenerator {\n    \n    @Override\n    public Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        // Get current tenant from security context\n        String tenantId = TenantContext.getCurrentTenant();\n        \n        String sql = String.format(\n            \"SELECT COALESCE(MAX(sequence_num), 0) + 1 \" +\n            \"FROM %s WHERE tenant_id = :tenantId\",\n            object.getClass().getSimpleName().toLowerCase()\n        );\n        \n        Integer sequence = (Integer) session\n            .createNativeQuery(sql)\n            .setParameter(\"tenantId\", tenantId)\n            .uniqueResult();\n        \n        return tenantId + \"-\" + sequence;\n    }\n}\n\n@Entity\npublic class Document {\n    @Id\n    @GenericGenerator(\n        name = \"tenant_seq\",\n        strategy = \"com.example.TenantSequenceGenerator\"\n    )\n    @GeneratedValue(generator = \"tenant_seq\")\n    private String id; // TENANT1-1, TENANT1-2, TENANT2-1, etc.\n    \n    private String tenantId;\n}\n\n// 5. UUID v7 generator (time-ordered UUIDs)\npublic class UUIDv7Generator implements IdentifierGenerator {\n    \n    @Override\n    public Serializable generate(\n            SharedSessionContractImplementor session,\n            Object object) {\n        \n        // UUID v7: time-based + random\n        long timestamp = System.currentTimeMillis();\n        byte[] bytes = new byte[16];\n        \n        // First 48 bits: timestamp\n        bytes[0] = (byte) (timestamp >> 40);\n        bytes[1] = (byte) (timestamp >> 32);\n        bytes[2] = (byte) (timestamp >> 24);\n        bytes[3] = (byte) (timestamp >> 16);\n        bytes[4] = (byte) (timestamp >> 8);\n        bytes[5] = (byte) timestamp;\n        \n        // Version and random data\n        bytes[6] = (byte) ((7 << 4) | (bytes[6] & 0x0F));\n        // ... fill rest with random\n        \n        return UUID.nameUUIDFromBytes(bytes);\n    }\n}"
    },
    {
      "id": 79,
      "question": "How do you implement soft deletes with @Where annotation?",
      "answer": "@Where adds automatic WHERE clause to entity queries:\n\nConcepts:\n• Global filter on entity\n• Applies to all queries\n• Hides deleted records\n• Can't be disabled in query\n\nVs @SQLDelete:\n• @Where: Read filtering\n• @SQLDelete: Write operation\n• Usually used together\n\nLimitations:\n• Hibernate-specific\n• Can't be overridden\n• Not in Criteria queries automatically\n\nAlternatives:\n• @FilterDef + @Filter (toggleable)\n• Specification pattern\n• Custom base repository",
      "explanation": "@Where annotation automatically filters soft-deleted records from all queries, ensuring deleted entities remain hidden throughout the application.",
      "difficulty": "Medium",
      "code": "// 1. Basic soft delete with @Where\n@Entity\n@Table(name = \"products\")\n@SQLDelete(sql = \"UPDATE products SET deleted = true WHERE id = ?\")\n@Where(clause = \"deleted = false\")\npublic class Product {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    private String name;\n    private BigDecimal price;\n    \n    @Column(nullable = false)\n    private Boolean deleted = false;\n    \n    @Column(name = \"deleted_at\")\n    private LocalDateTime deletedAt;\n}\n\n// All queries automatically filter deleted = false\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    // This query only returns non-deleted products\n    List<Product> findByName(String name);\n    \n    // Even findAll() respects @Where\n    // SELECT * FROM products WHERE deleted = false\n}\n\n// 2. Soft delete with relations\n@Entity\n@SQLDelete(sql = \"UPDATE categories SET deleted = true WHERE id = ?\")\n@Where(clause = \"deleted = false\")\npublic class Category {\n    @Id\n    private Long id;\n    private String name;\n    private Boolean deleted = false;\n    \n    @OneToMany(mappedBy = \"category\")\n    @Where(clause = \"deleted = false\") // Also filter products\n    private List<Product> products;\n}\n\n// 3. Including deleted records (workaround)\n@Repository\npublic interface ProductRepository \n        extends JpaRepository<Product, Long> {\n    \n    // @Where doesn't apply to native queries\n    @Query(value = \n        \"SELECT * FROM products WHERE id = :id\",\n        nativeQuery = true)\n    Optional<Product> findByIdIncludingDeleted(@Param(\"id\") Long id);\n    \n    // Get all including deleted\n    @Query(value = \"SELECT * FROM products\", nativeQuery = true)\n    List<Product> findAllIncludingDeleted();\n}\n\n// 4. Toggleable filter (more flexible than @Where)\n@Entity\n@FilterDef(\n    name = \"deletedFilter\",\n    parameters = @ParamDef(name = \"isDeleted\", type = \"boolean\")\n)\n@Filter(\n    name = \"deletedFilter\",\n    condition = \"deleted = :isDeleted\"\n)\npublic class Order {\n    @Id\n    private Long id;\n    private Boolean deleted = false;\n}\n\n@Service\npublic class OrderService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<Order> findOrders(boolean includeDeleted) {\n        Session session = entityManager.unwrap(Session.class);\n        \n        Filter filter = session.enableFilter(\"deletedFilter\");\n        filter.setParameter(\"isDeleted\", false);\n        \n        // Query with filter active\n        List<Order> orders = orderRepository.findAll();\n        \n        session.disableFilter(\"deletedFilter\");\n        \n        return orders;\n    }\n}\n\n// 5. Custom repository for deleted records\npublic interface CustomProductRepository {\n    List<Product> findDeleted();\n    Optional<Product> findByIdIgnoreDeleted(Long id);\n    void hardDelete(Long id);\n}\n\n@Repository\npublic class CustomProductRepositoryImpl \n        implements CustomProductRepository {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public List<Product> findDeleted() {\n        return entityManager\n            .createQuery(\n                \"SELECT p FROM Product p WHERE p.deleted = true\",\n                Product.class\n            )\n            .getResultList();\n    }\n    \n    @Override\n    public Optional<Product> findByIdIgnoreDeleted(Long id) {\n        String sql = \"SELECT * FROM products WHERE id = ?\";\n        try {\n            Product product = (Product) entityManager\n                .createNativeQuery(sql, Product.class)\n                .setParameter(1, id)\n                .getSingleResult();\n            return Optional.of(product);\n        } catch (NoResultException e) {\n            return Optional.empty();\n        }\n    }\n    \n    @Override\n    @Transactional\n    public void hardDelete(Long id) {\n        entityManager\n            .createNativeQuery(\"DELETE FROM products WHERE id = ?\")\n            .setParameter(1, id)\n            .executeUpdate();\n    }\n}\n\npublic interface ProductRepository \n        extends JpaRepository<Product, Long>, CustomProductRepository {\n    // Combines standard + custom methods\n}"
    },
    {
      "id": 80,
      "question": "How do you implement database schema validation in JPA?",
      "answer": "Schema validation ensures database matches entity mappings:\n\nhibernate.hbm2ddl.auto Options:\n• validate: Check schema, don't modify\n• update: Update schema (dev only)\n• create: Drop and create\n• create-drop: Create, drop on shutdown\n• none: Do nothing (production)\n\nValidation Checks:\n• Table existence\n• Column types\n• Constraints\n• Indexes\n• Foreign keys\n\nBest Practices:\n• Use 'validate' in production\n• Use migrations (Flyway) for changes\n• Fail fast on mismatch",
      "explanation": "Schema validation prevents runtime errors by verifying database structure matches JPA mappings, catching configuration issues at startup.",
      "difficulty": "Medium",
      "code": "// 1. Configuration for different environments\n// application-dev.properties\nspring.jpa.hibernate.ddl-auto=update\nspring.jpa.show-sql=true\nspring.jpa.properties.hibernate.format_sql=true\n\n// application-test.properties\nspring.jpa.hibernate.ddl-auto=create-drop\nspring.sql.init.mode=always\n\n// application-prod.properties\nspring.jpa.hibernate.ddl-auto=validate\nspring.jpa.properties.javax.persistence.schema-generation.scripts.action=none\nspring.jpa.properties.javax.persistence.schema-generation.create-source=metadata\nspring.jpa.properties.javax.persistence.schema-generation.drop-source=metadata\n\n// 2. Custom validation on startup\n@Component\npublic class SchemaValidator implements ApplicationListener<ApplicationReadyEvent> {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public void onApplicationEvent(ApplicationReadyEvent event) {\n        validateSchema();\n    }\n    \n    private void validateSchema() {\n        try {\n            // Try to access all entity tables\n            entityManager\n                .createQuery(\"SELECT COUNT(*) FROM User\")\n                .getSingleResult();\n            \n            entityManager\n                .createQuery(\"SELECT COUNT(*) FROM Order\")\n                .getSingleResult();\n            \n            logger.info(\"Schema validation successful\");\n        } catch (Exception e) {\n            logger.error(\"Schema validation failed\", e);\n            throw new IllegalStateException(\n                \"Database schema is invalid\", e\n            );\n        }\n    }\n}\n\n// 3. Schema export for review\n@Configuration\npublic class SchemaExportConfig {\n    \n    @Bean\n    public CommandLineRunner exportSchema(\n            EntityManagerFactory emf) {\n        return args -> {\n            if (args.length > 0 && \"export-schema\".equals(args[0])) {\n                exportDDL(emf);\n            }\n        };\n    }\n    \n    private void exportDDL(EntityManagerFactory emf) {\n        MetadataSources metadata = new MetadataSources(\n            new StandardServiceRegistryBuilder().build()\n        );\n        \n        // Add all entities\n        metadata.addAnnotatedClass(User.class);\n        metadata.addAnnotatedClass(Order.class);\n        // ...\n        \n        SchemaExport schemaExport = new SchemaExport();\n        schemaExport.setOutputFile(\"schema.sql\");\n        schemaExport.setDelimiter(\";\");\n        schemaExport.setFormat(true);\n        \n        schemaExport.execute(\n            EnumSet.of(TargetType.SCRIPT),\n            SchemaExport.Action.CREATE,\n            metadata.buildMetadata()\n        );\n        \n        System.out.println(\"Schema exported to schema.sql\");\n    }\n}\n\n// 4. Validation with detailed errors\n@Component\npublic class DetailedSchemaValidator {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @PostConstruct\n    public void validate() throws SQLException {\n        Connection conn = dataSource.getConnection();\n        DatabaseMetaData metaData = conn.getMetaData();\n        \n        // Check if table exists\n        ResultSet tables = metaData.getTables(\n            null, null, \"users\", null\n        );\n        if (!tables.next()) {\n            throw new IllegalStateException(\"Table 'users' not found\");\n        }\n        \n        // Check columns\n        ResultSet columns = metaData.getColumns(\n            null, null, \"users\", null\n        );\n        \n        Set<String> expectedColumns = Set.of(\n            \"id\", \"username\", \"email\", \"created_at\"\n        );\n        Set<String> actualColumns = new HashSet<>();\n        \n        while (columns.next()) {\n            actualColumns.add(columns.getString(\"COLUMN_NAME\"));\n        }\n        \n        if (!actualColumns.containsAll(expectedColumns)) {\n            Set<String> missing = new HashSet<>(expectedColumns);\n            missing.removeAll(actualColumns);\n            throw new IllegalStateException(\n                \"Missing columns in 'users' table: \" + missing\n            );\n        }\n        \n        conn.close();\n    }\n}\n\n// 5. Integration with Flyway\n@Configuration\npublic class FlywayConfig {\n    \n    @Bean(initMethod = \"migrate\")\n    public Flyway flyway(DataSource dataSource) {\n        return Flyway.configure()\n            .dataSource(dataSource)\n            .locations(\"classpath:db/migration\")\n            .baselineOnMigrate(true)\n            .validateOnMigrate(true) // Validate checksums\n            .outOfOrder(false)\n            .load();\n    }\n}\n\n// Ensure Flyway runs before JPA validation\nspring.jpa.hibernate.ddl-auto=validate\nspring.flyway.enabled=true\nspring.flyway.validate-on-migrate=true\nspring.flyway.baseline-on-migrate=true"
    },
    {
      "id": 81,
      "question": "How do you implement database connection failover and high availability in JPA?",
      "answer": "Failover ensures database availability during outages:\n\nStrategies:\n• Primary-replica setup\n• Connection pool retry\n• Multiple data sources\n• Circuit breaker pattern\n• Health checks\n\nTechnologies:\n• HikariCP retry\n• Spring Retry\n• AWS RDS Multi-AZ\n• PostgreSQL streaming replication\n\nConfiguration:\n• Connection timeout\n• Validation query\n• Test on borrow\n• Automatic reconnection",
      "explanation": "Connection failover automatically switches to backup databases when primary fails, ensuring high availability with minimal downtime.",
      "difficulty": "Hard",
      "code": "// 1. HikariCP with connection retry\nspring.datasource.hikari.connection-timeout=20000\nspring.datasource.hikari.maximum-pool-size=10\nspring.datasource.hikari.minimum-idle=5\nspring.datasource.hikari.idle-timeout=300000\nspring.datasource.hikari.max-lifetime=1200000\n\n# Connection validation\nspring.datasource.hikari.connection-test-query=SELECT 1\nspring.datasource.hikari.validation-timeout=3000\n\n# Retry on connection failure\nspring.datasource.hikari.initialization-fail-timeout=30000\n\n// 2. Multiple datasource with failover\n@Configuration\npublic class FailoverDataSourceConfig {\n    \n    @Bean\n    @ConfigurationProperties(\"spring.datasource.primary\")\n    public DataSource primaryDataSource() {\n        return DataSourceBuilder.create().build();\n    }\n    \n    @Bean\n    @ConfigurationProperties(\"spring.datasource.secondary\")\n    public DataSource secondaryDataSource() {\n        return DataSourceBuilder.create().build();\n    }\n    \n    @Bean\n    @Primary\n    public DataSource dataSource() {\n        return new FailoverDataSource(\n            primaryDataSource(),\n            secondaryDataSource()\n        );\n    }\n}\n\npublic class FailoverDataSource extends AbstractRoutingDataSource {\n    \n    private final DataSource primary;\n    private final DataSource secondary;\n    private volatile boolean primaryFailed = false;\n    \n    public FailoverDataSource(\n            DataSource primary,\n            DataSource secondary) {\n        this.primary = primary;\n        this.secondary = secondary;\n        \n        Map<Object, Object> targetDataSources = new HashMap<>();\n        targetDataSources.put(\"primary\", primary);\n        targetDataSources.put(\"secondary\", secondary);\n        \n        setTargetDataSources(targetDataSources);\n        setDefaultTargetDataSource(primary);\n        afterPropertiesSet();\n    }\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        if (primaryFailed) {\n            logger.warn(\"Using secondary datasource\");\n            return \"secondary\";\n        }\n        return \"primary\";\n    }\n    \n    @Override\n    public Connection getConnection() throws SQLException {\n        try {\n            Connection conn = primary.getConnection();\n            \n            // Test connection\n            if (!conn.isValid(3)) {\n                throw new SQLException(\"Primary connection invalid\");\n            }\n            \n            // Primary is healthy\n            if (primaryFailed) {\n                logger.info(\"Primary datasource recovered\");\n                primaryFailed = false;\n            }\n            \n            return conn;\n        } catch (SQLException e) {\n            logger.error(\"Primary datasource failed, switching to secondary\", e);\n            primaryFailed = true;\n            return secondary.getConnection();\n        }\n    }\n}\n\n// 3. Circuit breaker for database calls\n@Service\npublic class UserService {\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    @CircuitBreaker(\n        name = \"databaseCircuitBreaker\",\n        fallbackMethod = \"getUserFromCache\"\n    )\n    @Retry(name = \"databaseRetry\")\n    public User getUser(Long id) {\n        return userRepository.findById(id)\n            .orElseThrow(() -> new UserNotFoundException(id));\n    }\n    \n    private User getUserFromCache(Long id, Exception e) {\n        logger.warn(\"Database unavailable, using cache\", e);\n        return cacheService.getUser(id);\n    }\n}\n\n// resilience4j configuration\nresilience4j.circuitbreaker:\n  instances:\n    databaseCircuitBreaker:\n      sliding-window-size: 10\n      failure-rate-threshold: 50\n      wait-duration-in-open-state: 10000\n      permitted-number-of-calls-in-half-open-state: 3\n\nresilience4j.retry:\n  instances:\n    databaseRetry:\n      max-attempts: 3\n      wait-duration: 1000\n      retry-exceptions:\n        - org.springframework.dao.TransientDataAccessException\n        - java.sql.SQLTransientException\n\n// 4. Database health check\n@Component\npublic class DatabaseHealthIndicator implements HealthIndicator {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Override\n    public Health health() {\n        try (Connection conn = dataSource.getConnection()) {\n            \n            // Test query\n            Statement stmt = conn.createStatement();\n            ResultSet rs = stmt.executeQuery(\"SELECT 1\");\n            \n            if (rs.next()) {\n                return Health.up()\n                    .withDetail(\"database\", \"available\")\n                    .withDetail(\"validationQuery\", \"SELECT 1\")\n                    .build();\n            }\n            \n            return Health.down()\n                .withDetail(\"error\", \"Validation query failed\")\n                .build();\n                \n        } catch (Exception e) {\n            return Health.down()\n                .withDetail(\"error\", e.getMessage())\n                .withException(e)\n                .build();\n        }\n    }\n}\n\n// 5. PostgreSQL with replication URLs\n# Automatic failover with multiple hosts\nspring.datasource.url=jdbc:postgresql://primary:5432,secondary:5432/mydb?targetServerType=primary&loadBalanceHosts=true\nspring.datasource.hikari.connection-timeout=5000\n\n# Or use pgpool for connection pooling + failover\nspring.datasource.url=jdbc:postgresql://pgpool:9999/mydb"
    },
    {
      "id": 82,
      "question": "How do you implement database query timeout and statement timeout in JPA?",
      "answer": "Timeouts prevent long-running queries from blocking resources:\n\nTimeout Types:\n• Query timeout: JDBC statement timeout\n• Transaction timeout: Transaction duration\n• Lock timeout: Waiting for locks\n• Connection timeout: Getting connection\n\nImplementation:\n• @QueryHint\n• EntityManager hints\n• @Transactional timeout\n• Database-level timeouts\n\nBest Practices:\n• Set reasonable defaults\n• Override for specific queries\n• Monitor slow queries\n• Fail fast",
      "explanation": "Query timeouts prevent resource exhaustion by automatically canceling long-running queries, protecting application performance.",
      "difficulty": "Medium",
      "code": "// 1. Query-level timeout\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    // 5 second timeout for this query\n    @QueryHints({\n        @QueryHint(\n            name = \"javax.persistence.query.timeout\",\n            value = \"5000\" // milliseconds\n        )\n    })\n    @Query(\"SELECT o FROM Order o WHERE o.status = :status\")\n    List<Order> findByStatus(@Param(\"status\") String status);\n    \n    // Different timeout for complex query\n    @QueryHints(@QueryHint(\n        name = \"javax.persistence.query.timeout\",\n        value = \"10000\"\n    ))\n    @Query(\"SELECT o FROM Order o \" +\n           \"JOIN FETCH o.items i \" +\n           \"JOIN FETCH o.customer c \" +\n           \"WHERE o.createdAt > :date\")\n    List<Order> findRecentOrdersWithDetails(\n        @Param(\"date\") LocalDateTime date\n    );\n}\n\n// 2. Global query timeout configuration\nspring.jpa.properties.javax.persistence.query.timeout=3000\nspring.jpa.properties.hibernate.query.timeout=3\n\n# PostgreSQL statement timeout\nspring.jpa.properties.hibernate.connection.provider_disables_autocommit=true\nspring.datasource.hikari.connection-init-sql=SET statement_timeout = 5000\n\n// 3. Transaction timeout\n@Service\npublic class OrderService {\n    \n    // Timeout after 10 seconds\n    @Transactional(timeout = 10)\n    public Order processOrder(OrderRequest request) {\n        Order order = createOrder(request);\n        \n        // If this takes > 10 seconds, transaction rolls back\n        paymentService.processPayment(order);\n        inventoryService.reserveItems(order);\n        \n        return orderRepository.save(order);\n    }\n    \n    // Different timeout for batch operation\n    @Transactional(timeout = 60)\n    public void processBatchOrders(List<OrderRequest> requests) {\n        requests.forEach(this::processOrder);\n    }\n}\n\n// 4. EntityManager with timeout\n@Service\npublic class ReportService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<ReportData> generateReport(ReportCriteria criteria) {\n        TypedQuery<ReportData> query = entityManager\n            .createQuery(\n                \"SELECT new com.example.ReportData(\" +\n                \"  o.date, SUM(o.total), COUNT(o)) \" +\n                \"FROM Order o \" +\n                \"WHERE o.date BETWEEN :start AND :end \" +\n                \"GROUP BY o.date\",\n                ReportData.class\n            )\n            .setParameter(\"start\", criteria.getStartDate())\n            .setParameter(\"end\", criteria.getEndDate())\n            .setHint(\"javax.persistence.query.timeout\", 15000);\n        \n        return query.getResultList();\n    }\n}\n\n// 5. Custom timeout interceptor\n@Component\n@Aspect\npublic class QueryTimeoutAspect {\n    \n    @Around(\"execution(* com.example.repository.*.*(..))\")\n    public Object applyTimeout(ProceedingJoinPoint joinPoint) throws Throwable {\n        \n        Method method = ((MethodSignature) joinPoint.getSignature()).getMethod();\n        QueryTimeout annotation = method.getAnnotation(QueryTimeout.class);\n        \n        if (annotation == null) {\n            return joinPoint.proceed();\n        }\n        \n        ExecutorService executor = Executors.newSingleThreadExecutor();\n        Future<?> future = executor.submit(() -> {\n            try {\n                return joinPoint.proceed();\n            } catch (Throwable e) {\n                throw new RuntimeException(e);\n            }\n        });\n        \n        try {\n            return future.get(annotation.value(), TimeUnit.MILLISECONDS);\n        } catch (TimeoutException e) {\n            future.cancel(true);\n            throw new QueryTimeoutException(\n                \"Query exceeded timeout of \" + annotation.value() + \"ms\"\n            );\n        } finally {\n            executor.shutdownNow();\n        }\n    }\n}\n\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.METHOD)\npublic @interface QueryTimeout {\n    long value() default 5000; // milliseconds\n}\n\n// Usage\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    @QueryTimeout(10000)\n    List<Product> findAllWithReviews();\n}\n\n// 6. Database-specific timeouts\n// PostgreSQL\n@Configuration\npublic class PostgresConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(jdbcUrl);\n        config.setConnectionInitSql(\n            \"SET statement_timeout = 10000; \" +  // 10 seconds\n            \"SET lock_timeout = 5000\"             // 5 seconds\n        );\n        return new HikariDataSource(config);\n    }\n}\n\n// MySQL\nspring.datasource.url=jdbc:mysql://localhost:3306/mydb?connectTimeout=5000&socketTimeout=10000"
    },
    {
      "id": 83,
      "question": "How do you implement database indexing strategies in JPA?",
      "answer": "Indexes improve query performance:\n\nIndex Types:\n• Single column: Simple lookup\n• Composite: Multiple columns\n• Unique: Enforce uniqueness\n• Partial: Filtered subset\n• Full-text: Text search\n\nJPA Annotations:\n• @Index on @Table\n• @UniqueConstraint\n• Native SQL for complex indexes\n\nBest Practices:\n• Index foreign keys\n• Index WHERE clause columns\n• Index ORDER BY columns\n• Monitor index usage\n• Avoid over-indexing",
      "explanation": "Strategic indexing dramatically improves query performance by enabling faster data lookups, but requires careful planning to balance read vs write performance.",
      "difficulty": "Medium",
      "code": "// 1. Single and composite indexes\n@Entity\n@Table(\n    name = \"orders\",\n    indexes = {\n        // Single column index\n        @Index(\n            name = \"idx_order_status\",\n            columnList = \"status\"\n        ),\n        \n        // Composite index (order matters!)\n        @Index(\n            name = \"idx_customer_date\",\n            columnList = \"customer_id, order_date DESC\"\n        ),\n        \n        // Unique index\n        @Index(\n            name = \"idx_order_number\",\n            columnList = \"order_number\",\n            unique = true\n        )\n    }\n)\npublic class Order {\n    @Id\n    private Long id;\n    \n    @Column(name = \"order_number\")\n    private String orderNumber;\n    \n    @Column(name = \"customer_id\")\n    private Long customerId;\n    \n    @Column(name = \"order_date\")\n    private LocalDateTime orderDate;\n    \n    private String status;\n}\n\n// 2. Index on foreign keys\n@Entity\n@Table(\n    name = \"order_items\",\n    indexes = {\n        @Index(name = \"idx_order_id\", columnList = \"order_id\"),\n        @Index(name = \"idx_product_id\", columnList = \"product_id\")\n    }\n)\npublic class OrderItem {\n    @Id\n    private Long id;\n    \n    @ManyToOne\n    @JoinColumn(name = \"order_id\")\n    private Order order;\n    \n    @ManyToOne\n    @JoinColumn(name = \"product_id\")\n    private Product product;\n}\n\n// 3. Partial index (PostgreSQL) via migration\n/*\n-- Flyway migration: V1__create_partial_index.sql\n\n-- Index only active orders\nCREATE INDEX idx_active_orders \nON orders (customer_id, order_date)\nWHERE status IN ('PENDING', 'PROCESSING');\n\n-- Index for recent orders\nCREATE INDEX idx_recent_orders\nON orders (order_date DESC)\nWHERE order_date > CURRENT_DATE - INTERVAL '90 days';\n*/\n\n// 4. Expression/functional index\n/*\n-- PostgreSQL: Index on lowercase email\nCREATE INDEX idx_users_email_lower \nON users (LOWER(email));\n\n-- MySQL: Index on year\nCREATE INDEX idx_orders_year \nON orders ((YEAR(order_date)));\n*/\n\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String email;\n}\n\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // Uses idx_users_email_lower\n    @Query(\"SELECT u FROM User u WHERE LOWER(u.email) = LOWER(:email)\")\n    Optional<User> findByEmailIgnoreCase(@Param(\"email\") String email);\n}\n\n// 5. Full-text index\n/*\n-- PostgreSQL: GIN index for full-text search\nCREATE INDEX idx_products_search \nON products USING GIN (to_tsvector('english', name || ' ' || description));\n\n-- MySQL: Full-text index\nCREATE FULLTEXT INDEX idx_products_fulltext \nON products (name, description);\n*/\n\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    // PostgreSQL full-text search\n    @Query(value = \n        \"SELECT * FROM products \" +\n        \"WHERE to_tsvector('english', name || ' ' || description) @@ \" +\n        \"      to_tsquery('english', :query)\",\n        nativeQuery = true)\n    List<Product> fullTextSearch(@Param(\"query\") String query);\n    \n    // MySQL full-text search\n    @Query(value = \n        \"SELECT * FROM products \" +\n        \"WHERE MATCH(name, description) AGAINST (:query IN NATURAL LANGUAGE MODE)\",\n        nativeQuery = true)\n    List<Product> fullTextSearchMySQL(@Param(\"query\") String query);\n}\n\n// 6. Covering index (include columns)\n/*\n-- PostgreSQL: Index with INCLUDE\nCREATE INDEX idx_orders_covering\nON orders (customer_id, order_date)\nINCLUDE (status, total_amount);\n\n-- Now this query uses index-only scan:\nSELECT status, total_amount \nFROM orders \nWHERE customer_id = 123 AND order_date > '2024-01-01';\n*/\n\n// 7. Index monitoring\n@Service\npublic class IndexMonitoringService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    // PostgreSQL: Check unused indexes\n    public List<UnusedIndex> findUnusedIndexes() {\n        String sql = \n            \"SELECT \" +\n            \"  schemaname, tablename, indexname, \" +\n            \"  idx_scan as index_scans, \" +\n            \"  pg_size_pretty(pg_relation_size(indexrelid)) as index_size \" +\n            \"FROM pg_stat_user_indexes \" +\n            \"WHERE idx_scan < 50 \" +\n            \"  AND indexrelname NOT LIKE 'pg_toast%' \" +\n            \"ORDER BY pg_relation_size(indexrelid) DESC\";\n        \n        return entityManager.createNativeQuery(sql)\n            .getResultList();\n    }\n    \n    // Check missing indexes (PostgreSQL)\n    public List<MissingIndex> findMissingIndexes() {\n        String sql = \n            \"SELECT \" +\n            \"  schemaname, tablename, attname, \" +\n            \"  n_distinct, correlation \" +\n            \"FROM pg_stats \" +\n            \"WHERE schemaname NOT IN ('pg_catalog', 'information_schema') \" +\n            \"  AND n_distinct > 100 \" +\n            \"  AND correlation < 0.1 \" +\n            \"ORDER BY n_distinct DESC\";\n        \n        return entityManager.createNativeQuery(sql)\n            .getResultList();\n    }\n}"
    },
    {
      "id": 84,
      "question": "How do you implement database migration strategies in JPA applications?",
      "answer": "Migration strategies manage schema evolution:\n\nTools:\n• Flyway: SQL-based, versioned\n• Liquibase: XML/YAML, database-agnostic\n• JPA DDL: Auto-generation (avoid in prod)\n\nMigration Types:\n• Versioned: Sequential changes\n• Repeatable: Views, procedures\n• Baseline: Existing databases\n• Callbacks: Before/after hooks\n\nBest Practices:\n• Version control migrations\n• Test on staging first\n• Backwards compatible changes\n• Rollback strategy\n• Validate checksums",
      "explanation": "Database migrations provide controlled, versioned schema changes with audit trail, enabling safe evolution of database structure in production.",
      "difficulty": "Medium",
      "code": "// 1. Flyway configuration\n// pom.xml\n/*\n<dependency>\n    <groupId>org.flywaydb</groupId>\n    <artifactId>flyway-core</artifactId>\n</dependency>\n*/\n\n// application.properties\nspring.flyway.enabled=true\nspring.flyway.baseline-on-migrate=true\nspring.flyway.locations=classpath:db/migration\nspring.flyway.validate-on-migrate=true\nspring.flyway.out-of-order=false\n\n# Disable JPA auto-DDL\nspring.jpa.hibernate.ddl-auto=validate\n\n// 2. Flyway migration files\n// src/main/resources/db/migration/V1__create_users_table.sql\nCREATE TABLE users (\n    id BIGSERIAL PRIMARY KEY,\n    username VARCHAR(100) NOT NULL UNIQUE,\n    email VARCHAR(255) NOT NULL UNIQUE,\n    password_hash VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_username ON users(username);\n\n// V2__create_orders_table.sql\nCREATE TABLE orders (\n    id BIGSERIAL PRIMARY KEY,\n    user_id BIGINT NOT NULL REFERENCES users(id),\n    order_number VARCHAR(50) NOT NULL UNIQUE,\n    status VARCHAR(20) NOT NULL,\n    total_amount DECIMAL(10, 2) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE INDEX idx_orders_user_id ON orders(user_id);\nCREATE INDEX idx_orders_status ON orders(status);\n\n// V3__add_user_roles.sql\nALTER TABLE users ADD COLUMN role VARCHAR(20) DEFAULT 'USER';\nUPDATE users SET role = 'USER' WHERE role IS NULL;\nALTER TABLE users ALTER COLUMN role SET NOT NULL;\n\n// 3. Flyway Java-based migrations\n@Component\npublic class V4__migrate_legacy_data implements JavaMigration {\n    \n    @Override\n    public void migrate(Context context) throws Exception {\n        try (Statement statement = context.getConnection().createStatement()) {\n            \n            // Complex data migration\n            statement.execute(\n                \"INSERT INTO users (username, email, password_hash) \" +\n                \"SELECT legacy_name, legacy_email, legacy_pwd \" +\n                \"FROM legacy_users \" +\n                \"WHERE migrated = false\"\n            );\n            \n            // Mark as migrated\n            statement.execute(\n                \"UPDATE legacy_users SET migrated = true\"\n            );\n        }\n    }\n}\n\n// 4. Liquibase configuration\n// pom.xml\n/*\n<dependency>\n    <groupId>org.liquibase</groupId>\n    <artifactId>liquibase-core</artifactId>\n</dependency>\n*/\n\nspring.liquibase.enabled=true\nspring.liquibase.change-log=classpath:db/changelog/db.changelog-master.yaml\nspring.jpa.hibernate.ddl-auto=validate\n\n// db/changelog/db.changelog-master.yaml\ndatabaseChangeLog:\n  - changeSet:\n      id: 1\n      author: developer\n      changes:\n        - createTable:\n            tableName: products\n            columns:\n              - column:\n                  name: id\n                  type: BIGINT\n                  autoIncrement: true\n                  constraints:\n                    primaryKey: true\n              - column:\n                  name: name\n                  type: VARCHAR(255)\n                  constraints:\n                    nullable: false\n              - column:\n                  name: price\n                  type: DECIMAL(10,2)\n                  constraints:\n                    nullable: false\n      rollback:\n        - dropTable:\n            tableName: products\n\n  - changeSet:\n      id: 2\n      author: developer\n      changes:\n        - addColumn:\n            tableName: products\n            columns:\n              - column:\n                  name: description\n                  type: TEXT\n      rollback:\n        - dropColumn:\n            tableName: products\n            columnName: description\n\n// 5. Migration best practices\n@Configuration\npublic class MigrationConfig {\n    \n    // Separate flyway bean for control\n    @Bean(initMethod = \"migrate\")\n    public Flyway flyway(DataSource dataSource) {\n        return Flyway.configure()\n            .dataSource(dataSource)\n            .locations(\"classpath:db/migration\")\n            .baselineOnMigrate(true)\n            .validateOnMigrate(true)\n            .outOfOrder(false)\n            .group(true) // Run all pending as one transaction\n            .callbacks(new MigrationCallback())\n            .load();\n    }\n}\n\npublic class MigrationCallback implements Callback {\n    \n    @Override\n    public void handle(Event event, Context context) {\n        if (event == Event.AFTER_MIGRATE) {\n            System.out.println(\"Migration completed successfully\");\n            // Send notification, update metrics, etc.\n        } else if (event == Event.AFTER_MIGRATE_ERROR) {\n            System.err.println(\"Migration failed!\");\n            // Alert team, rollback, etc.\n        }\n    }\n}\n\n// 6. Testing migrations\n@SpringBootTest\nclass MigrationTest {\n    \n    @Autowired\n    private Flyway flyway;\n    \n    @Test\n    void testMigration() {\n        // Clean database\n        flyway.clean();\n        \n        // Run migrations\n        MigrateResult result = flyway.migrate();\n        \n        assertThat(result.migrationsExecuted).isGreaterThan(0);\n        assertThat(result.success).isTrue();\n    }\n    \n    @Test\n    void testRollback() {\n        // Test rollback SQL\n        flyway.clean();\n        flyway.migrate();\n        \n        // Manually test rollback scripts\n        // (Flyway doesn't support auto-rollback in CE)\n    }\n}"
    },
    {
      "id": 85,
      "question": "How do you implement database backup and restore strategies in JPA applications?",
      "answer": "Backup strategies ensure data recovery:\n\nBackup Types:\n• Full backup: Complete database\n• Incremental: Changes since last\n• Differential: Changes since full\n• Logical: SQL dumps\n• Physical: File-level\n\nStrategies:\n• Scheduled backups\n• Point-in-time recovery\n• WAL archiving\n• Replication for backups\n• Cloud backup services\n\nTesting:\n• Regular restore tests\n• RTO/RPO monitoring\n• Disaster recovery drills",
      "explanation": "Comprehensive backup strategies with regular testing ensure business continuity and data recovery capabilities in disaster scenarios.",
      "difficulty": "Medium",
      "code": "// 1. Scheduled backup service\n@Service\npublic class DatabaseBackupService {\n    \n    @Value(\"${backup.directory}\")\n    private String backupDirectory;\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    // Run daily at 2 AM\n    @Scheduled(cron = \"0 0 2 * * *\")\n    public void performDailyBackup() {\n        String timestamp = LocalDateTime.now()\n            .format(DateTimeFormatter.ofPattern(\"yyyyMMdd_HHmmss\"));\n        \n        String backupFile = backupDirectory + \"/backup_\" + timestamp + \".sql\";\n        \n        try {\n            createBackup(backupFile);\n            logger.info(\"Backup completed: {}\", backupFile);\n            \n            // Verify backup\n            verifyBackup(backupFile);\n            \n            // Upload to cloud storage\n            uploadToCloud(backupFile);\n            \n            // Cleanup old backups\n            cleanupOldBackups();\n            \n        } catch (Exception e) {\n            logger.error(\"Backup failed\", e);\n            alertTeam(\"Backup failed: \" + e.getMessage());\n        }\n    }\n    \n    private void createBackup(String backupFile) throws Exception {\n        // PostgreSQL\n        ProcessBuilder pb = new ProcessBuilder(\n            \"pg_dump\",\n            \"-h\", dbHost,\n            \"-U\", dbUser,\n            \"-F\", \"c\",  // Custom format (compressed)\n            \"-f\", backupFile,\n            dbName\n        );\n        \n        pb.environment().put(\"PGPASSWORD\", dbPassword);\n        Process process = pb.start();\n        \n        int exitCode = process.waitFor();\n        if (exitCode != 0) {\n            throw new RuntimeException(\"Backup failed with exit code: \" + exitCode);\n        }\n    }\n}\n\n// 2. Point-in-time recovery setup (PostgreSQL)\n/*\n-- postgresql.conf\nwal_level = replica\narchive_mode = on\narchive_command = 'cp %p /backup/wal/%f'\narchive_timeout = 300  # 5 minutes\n\n-- Enable continuous archiving\npg_basebackup -D /backup/base -F tar -z -P\n*/\n\n@Configuration\npublic class BackupConfig {\n    \n    @Value(\"${backup.wal.directory}\")\n    private String walDirectory;\n    \n    @PostConstruct\n    public void setupWalArchiving() {\n        File walDir = new File(walDirectory);\n        if (!walDir.exists()) {\n            walDir.mkdirs();\n        }\n    }\n}\n\n// 3. Backup verification\n@Service\npublic class BackupVerificationService {\n    \n    public boolean verifyBackup(String backupFile) {\n        try {\n            // Check file size\n            File file = new File(backupFile);\n            if (file.length() < 1024) { // Less than 1KB\n                logger.error(\"Backup file too small: {}\", file.length());\n                return false;\n            }\n            \n            // Verify file integrity\n            if (backupFile.endsWith(\".sql.gz\")) {\n                verifyGzipIntegrity(backupFile);\n            }\n            \n            // Test restore to temporary database\n            testRestoreToTempDb(backupFile);\n            \n            logger.info(\"Backup verification passed: {}\", backupFile);\n            return true;\n            \n        } catch (Exception e) {\n            logger.error(\"Backup verification failed\", e);\n            return false;\n        }\n    }\n    \n    private void testRestoreToTempDb(String backupFile) throws Exception {\n        String tempDb = \"temp_restore_test_\" + System.currentTimeMillis();\n        \n        // Create temp database\n        ProcessBuilder createDb = new ProcessBuilder(\n            \"createdb\", \"-U\", dbUser, tempDb\n        );\n        createDb.start().waitFor();\n        \n        try {\n            // Restore backup\n            ProcessBuilder restore = new ProcessBuilder(\n                \"pg_restore\",\n                \"-d\", tempDb,\n                \"-U\", dbUser,\n                backupFile\n            );\n            \n            int exitCode = restore.start().waitFor();\n            if (exitCode != 0) {\n                throw new RuntimeException(\"Restore test failed\");\n            }\n            \n            // Verify key tables exist\n            verifyTablesExist(tempDb);\n            \n        } finally {\n            // Drop temp database\n            ProcessBuilder dropDb = new ProcessBuilder(\n                \"dropdb\", \"-U\", dbUser, tempDb\n            );\n            dropDb.start().waitFor();\n        }\n    }\n}\n\n// 4. Cloud backup integration\n@Service\npublic class CloudBackupService {\n    \n    @Autowired\n    private AmazonS3 s3Client;\n    \n    @Value(\"${backup.s3.bucket}\")\n    private String bucketName;\n    \n    public void uploadBackup(String localFile) {\n        File file = new File(localFile);\n        String s3Key = \"backups/\" + file.getName();\n        \n        try {\n            // Upload with metadata\n            ObjectMetadata metadata = new ObjectMetadata();\n            metadata.setContentLength(file.length());\n            metadata.addUserMetadata(\"backup-date\", \n                LocalDateTime.now().toString());\n            metadata.addUserMetadata(\"database\", dbName);\n            \n            PutObjectRequest request = new PutObjectRequest(\n                bucketName,\n                s3Key,\n                file\n            ).withMetadata(metadata);\n            \n            // Use server-side encryption\n            request.setSSEAwsKeyManagementParams(\n                new SSEAwsKeyManagementParams()\n            );\n            \n            s3Client.putObject(request);\n            \n            logger.info(\"Backup uploaded to S3: {}\", s3Key);\n            \n            // Set lifecycle policy (optional)\n            setLifecyclePolicy();\n            \n        } catch (Exception e) {\n            logger.error(\"Failed to upload backup to S3\", e);\n            throw new RuntimeException(\"Cloud backup failed\", e);\n        }\n    }\n    \n    private void setLifecyclePolicy() {\n        // Move to Glacier after 30 days, delete after 90 days\n        BucketLifecycleConfiguration.Rule rule = \n            new BucketLifecycleConfiguration.Rule()\n                .withId(\"BackupRetention\")\n                .withPrefix(\"backups/\")\n                .withStatus(BucketLifecycleConfiguration.ENABLED)\n                .withTransitions(\n                    new BucketLifecycleConfiguration.Transition()\n                        .withDays(30)\n                        .withStorageClass(StorageClass.Glacier)\n                )\n                .withExpirationInDays(90);\n        \n        BucketLifecycleConfiguration config = \n            new BucketLifecycleConfiguration()\n                .withRules(rule);\n        \n        s3Client.setBucketLifecycleConfiguration(bucketName, config);\n    }\n}\n\n// 5. Restore service\n@Service\npublic class DatabaseRestoreService {\n    \n    public void restoreFromBackup(String backupFile, String targetDb) {\n        logger.warn(\"Starting restore to database: {}\", targetDb);\n        \n        try {\n            // Download from S3 if needed\n            if (backupFile.startsWith(\"s3://\")) {\n                backupFile = downloadFromS3(backupFile);\n            }\n            \n            // Stop application (prevent connections)\n            stopApplication();\n            \n            // Drop and recreate database\n            recreateDatabase(targetDb);\n            \n            // Restore\n            ProcessBuilder restore = new ProcessBuilder(\n                \"pg_restore\",\n                \"-d\", targetDb,\n                \"-U\", dbUser,\n                \"-v\",  // Verbose\n                backupFile\n            );\n            \n            int exitCode = restore.start().waitFor();\n            if (exitCode != 0) {\n                throw new RuntimeException(\"Restore failed\");\n            }\n            \n            // Verify restore\n            verifyRestore(targetDb);\n            \n            logger.info(\"Restore completed successfully\");\n            \n        } catch (Exception e) {\n            logger.error(\"Restore failed\", e);\n            throw new RuntimeException(\"Restore failed\", e);\n        }\n    }\n}"
    },
    {
      "id": 86,
      "question": "How do you implement database connection pooling optimization in JPA?",
      "answer": "Connection pool optimization balances performance and resources:\n\nKey Parameters:\n• Maximum pool size: Max connections\n• Minimum idle: Always ready connections\n• Connection timeout: Wait time\n• Idle timeout: Close unused\n• Max lifetime: Connection age\n\nBest Practices:\n• Pool size = (CPU cores * 2) + disk spindles\n• Monitor pool metrics\n• Set appropriate timeouts\n• Validate connections\n• Use HikariCP (fastest)\n\nMonitoring:\n• Active connections\n• Pool wait time\n• Connection creation time",
      "explanation": "Optimized connection pooling prevents resource exhaustion and improves application performance by efficiently managing database connections.",
      "difficulty": "Medium",
      "code": "// 1. HikariCP optimal configuration\nspring.datasource.hikari.maximum-pool-size=10\nspring.datasource.hikari.minimum-idle=5\nspring.datasource.hikari.connection-timeout=30000\nspring.datasource.hikari.idle-timeout=600000\nspring.datasource.hikari.max-lifetime=1800000\n\n# Connection testing\nspring.datasource.hikari.connection-test-query=SELECT 1\nspring.datasource.hikari.validation-timeout=5000\n\n# Performance\nspring.datasource.hikari.leak-detection-threshold=60000\nspring.datasource.hikari.register-mbeans=true\n\n// 2. Calculate optimal pool size\n@Configuration\npublic class DataSourceConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        HikariConfig config = new HikariConfig();\n        \n        // Formula: pool_size = (core_count * 2) + effective_spindle_count\n        int cores = Runtime.getRuntime().availableProcessors();\n        int optimalPoolSize = (cores * 2) + 1; // +1 for single disk\n        \n        config.setMaximumPoolSize(optimalPoolSize);\n        config.setMinimumIdle(cores);\n        \n        // Connection timeout\n        config.setConnectionTimeout(30000); // 30 seconds\n        \n        // How long connection can remain idle\n        config.setIdleTimeout(600000); // 10 minutes\n        \n        // Maximum lifetime of connection\n        config.setMaxLifetime(1800000); // 30 minutes\n        \n        // Connection validation\n        config.setConnectionTestQuery(\"SELECT 1\");\n        config.setValidationTimeout(5000);\n        \n        // Leak detection (connections not returned)\n        config.setLeakDetectionThreshold(60000); // 1 minute\n        \n        // JMX monitoring\n        config.setRegisterMbeans(true);\n        config.setPoolName(\"HikariPool-Main\");\n        \n        config.setJdbcUrl(jdbcUrl);\n        config.setUsername(username);\n        config.setPassword(password);\n        \n        return new HikariDataSource(config);\n    }\n}\n\n// 3. Multiple connection pools\n@Configuration\npublic class MultiPoolConfig {\n    \n    // Fast pool for OLTP operations\n    @Bean(name = \"fastDataSource\")\n    @Primary\n    public DataSource fastDataSource() {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(jdbcUrl);\n        config.setMaximumPoolSize(20);\n        config.setMinimumIdle(5);\n        config.setConnectionTimeout(5000); // 5 seconds\n        config.setPoolName(\"FastPool\");\n        return new HikariDataSource(config);\n    }\n    \n    // Slow pool for OLAP/reporting\n    @Bean(name = \"slowDataSource\")\n    public DataSource slowDataSource() {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(readReplicaUrl);\n        config.setMaximumPoolSize(5);\n        config.setMinimumIdle(1);\n        config.setConnectionTimeout(30000); // 30 seconds\n        config.setPoolName(\"SlowPool\");\n        return new HikariDataSource(config);\n    }\n    \n    @Bean\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory(\n            @Qualifier(\"fastDataSource\") DataSource dataSource) {\n        // Configure with fast pool\n    }\n}\n\n@Service\npublic class ReportService {\n    \n    @Autowired\n    @Qualifier(\"slowDataSource\")\n    private DataSource reportDataSource;\n    \n    public List<ReportData> generateReport() {\n        // Use slow pool for long-running queries\n        try (Connection conn = reportDataSource.getConnection()) {\n            // Execute report query\n        }\n    }\n}\n\n// 4. Pool monitoring\n@Component\npublic class ConnectionPoolMonitor {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Scheduled(fixedRate = 60000) // Every minute\n    public void monitorPool() {\n        if (dataSource instanceof HikariDataSource) {\n            HikariDataSource hikari = (HikariDataSource) dataSource;\n            HikariPoolMXBean pool = hikari.getHikariPoolMXBean();\n            \n            int active = pool.getActiveConnections();\n            int idle = pool.getIdleConnections();\n            int total = pool.getTotalConnections();\n            int waiting = pool.getThreadsAwaitingConnection();\n            \n            logger.info(\n                \"Pool stats - Active: {}, Idle: {}, Total: {}, Waiting: {}\",\n                active, idle, total, waiting\n            );\n            \n            // Alert if pool is exhausted\n            if (waiting > 0) {\n                logger.warn(\"Connection pool exhausted! {} threads waiting\", \n                    waiting);\n                alertTeam(\"Connection pool pressure detected\");\n            }\n            \n            // Alert if too many idle connections\n            if (idle > total * 0.8) {\n                logger.info(\"Consider reducing minimum-idle: {}\", idle);\n            }\n        }\n    }\n}\n\n// 5. Custom health indicator\n@Component\npublic class ConnectionPoolHealthIndicator implements HealthIndicator {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Override\n    public Health health() {\n        if (!(dataSource instanceof HikariDataSource)) {\n            return Health.unknown().build();\n        }\n        \n        HikariDataSource hikari = (HikariDataSource) dataSource;\n        HikariPoolMXBean pool = hikari.getHikariPoolMXBean();\n        \n        int active = pool.getActiveConnections();\n        int idle = pool.getIdleConnections();\n        int total = pool.getTotalConnections();\n        int max = hikari.getMaximumPoolSize();\n        int waiting = pool.getThreadsAwaitingConnection();\n        \n        double utilization = (double) active / max * 100;\n        \n        Health.Builder builder;\n        \n        if (waiting > 5) {\n            builder = Health.down()\n                .withDetail(\"reason\", \"Pool exhausted\");\n        } else if (utilization > 90) {\n            builder = Health.outOfService()\n                .withDetail(\"reason\", \"High utilization\");\n        } else if (utilization > 70) {\n            builder = Health.up()\n                .withDetail(\"warning\", \"High utilization\");\n        } else {\n            builder = Health.up();\n        }\n        \n        return builder\n            .withDetail(\"active\", active)\n            .withDetail(\"idle\", idle)\n            .withDetail(\"total\", total)\n            .withDetail(\"max\", max)\n            .withDetail(\"waiting\", waiting)\n            .withDetail(\"utilization\", String.format(\"%.1f%%\", utilization))\n            .build();\n    }\n}\n\n// 6. Load testing pool configuration\n@SpringBootTest\nclass ConnectionPoolLoadTest {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Test\n    void testPoolUnderLoad() throws Exception {\n        int threads = 50;\n        int iterations = 100;\n        \n        ExecutorService executor = Executors.newFixedThreadPool(threads);\n        CountDownLatch latch = new CountDownLatch(threads * iterations);\n        \n        long start = System.currentTimeMillis();\n        \n        for (int i = 0; i < threads; i++) {\n            executor.submit(() -> {\n                for (int j = 0; j < iterations; j++) {\n                    try (Connection conn = dataSource.getConnection();\n                         PreparedStatement stmt = conn.prepareStatement(\n                             \"SELECT 1\")) {\n                        \n                        stmt.executeQuery();\n                        \n                    } catch (SQLException e) {\n                        fail(\"Connection failed: \" + e.getMessage());\n                    } finally {\n                        latch.countDown();\n                    }\n                }\n            });\n        }\n        \n        latch.await(60, TimeUnit.SECONDS);\n        long duration = System.currentTimeMillis() - start;\n        \n        System.out.println(\"Total time: \" + duration + \"ms\");\n        System.out.println(\"Requests/sec: \" + \n            (threads * iterations * 1000.0 / duration));\n        \n        executor.shutdown();\n    }\n}"
    },
    {
      "id": 87,
      "question": "How do you implement database monitoring and observability in JPA?",
      "answer": "Monitoring provides visibility into database operations:\n\nMetrics to Track:\n• Query execution time\n• Connection pool stats\n• Transaction duration\n• Slow queries\n• Error rates\n• Cache hit ratio\n\nTools:\n• Spring Boot Actuator\n• Micrometer metrics\n• Hibernate statistics\n• Database query logs\n• APM tools (New Relic, DataDog)\n\nImplementation:\n• Custom interceptors\n• @Timed annotations\n• Logging aspects\n• Health indicators",
      "explanation": "Comprehensive monitoring enables proactive issue detection, performance optimization, and capacity planning for database operations.",
      "difficulty": "Medium",
      "code": "// 1. Enable Hibernate statistics\nspring.jpa.properties.hibernate.generate_statistics=true\nspring.jpa.properties.hibernate.session.events.log=true\n\n@Configuration\npublic class HibernateStatisticsConfig {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @PostConstruct\n    public void enableStatistics() {\n        SessionFactory sessionFactory = entityManager\n            .getEntityManagerFactory()\n            .unwrap(SessionFactory.class);\n        \n        sessionFactory.getStatistics().setStatisticsEnabled(true);\n    }\n}\n\n@Service\npublic class DatabaseMetricsService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public Statistics getHibernateStatistics() {\n        SessionFactory sf = entityManager\n            .getEntityManagerFactory()\n            .unwrap(SessionFactory.class);\n        \n        return sf.getStatistics();\n    }\n    \n    @Scheduled(fixedRate = 60000)\n    public void logStatistics() {\n        Statistics stats = getHibernateStatistics();\n        \n        logger.info(\"=== Hibernate Statistics ===\");\n        logger.info(\"Queries executed: {}\", stats.getQueryExecutionCount());\n        logger.info(\"Cache hits: {}, misses: {}\",\n            stats.getSecondLevelCacheHitCount(),\n            stats.getSecondLevelCacheMissCount());\n        logger.info(\"Connections obtained: {}\", \n            stats.getConnectCount());\n        logger.info(\"Transactions: {}\", \n            stats.getTransactionCount());\n        logger.info(\"Optimistic lock failures: {}\",\n            stats.getOptimisticFailureCount());\n    }\n}\n\n// 2. Micrometer metrics\n@Configuration\npublic class MetricsConfig {\n    \n    @Bean\n    public MeterBinder hibernateMetrics(\n            EntityManagerFactory emf) {\n        return new HibernateMetrics(\n            emf.unwrap(SessionFactory.class),\n            \"hibernate\",\n            Collections.emptyList()\n        );\n    }\n}\n\n@Service\npublic class MetricsCollectorService {\n    \n    private final MeterRegistry meterRegistry;\n    \n    @Autowired\n    public MetricsCollectorService(MeterRegistry meterRegistry) {\n        this.meterRegistry = meterRegistry;\n    }\n    \n    public void recordQueryExecution(String queryName, long durationMs) {\n        Timer.builder(\"database.query.execution\")\n            .tag(\"query\", queryName)\n            .description(\"Query execution time\")\n            .register(meterRegistry)\n            .record(durationMs, TimeUnit.MILLISECONDS);\n    }\n    \n    public void recordSlowQuery(String query, long duration) {\n        Counter.builder(\"database.query.slow\")\n            .tag(\"query\", sanitizeQuery(query))\n            .description(\"Slow query count\")\n            .register(meterRegistry)\n            .increment();\n    }\n}\n\n// 3. Query execution monitoring\n@Aspect\n@Component\npublic class QueryMonitoringAspect {\n    \n    @Autowired\n    private MetricsCollectorService metricsService;\n    \n    private static final long SLOW_QUERY_THRESHOLD = 1000; // 1 second\n    \n    @Around(\"@annotation(org.springframework.data.jpa.repository.Query)\")\n    public Object monitorQuery(ProceedingJoinPoint joinPoint) throws Throwable {\n        \n        String methodName = joinPoint.getSignature().getName();\n        long start = System.currentTimeMillis();\n        \n        try {\n            Object result = joinPoint.proceed();\n            return result;\n            \n        } finally {\n            long duration = System.currentTimeMillis() - start;\n            \n            // Record metric\n            metricsService.recordQueryExecution(methodName, duration);\n            \n            // Log slow queries\n            if (duration > SLOW_QUERY_THRESHOLD) {\n                logger.warn(\n                    \"Slow query detected: {} took {}ms\",\n                    methodName,\n                    duration\n                );\n                \n                metricsService.recordSlowQuery(methodName, duration);\n            }\n        }\n    }\n}\n\n// 4. Custom health indicators\n@Component\npublic class DatabaseHealthIndicator implements HealthIndicator {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Override\n    public Health health() {\n        try {\n            // Execute simple query\n            long start = System.currentTimeMillis();\n            entityManager.createNativeQuery(\"SELECT 1\").getSingleResult();\n            long duration = System.currentTimeMillis() - start;\n            \n            // Check response time\n            Health.Builder builder = duration < 100 \n                ? Health.up() \n                : Health.degraded();\n            \n            // Add statistics\n            Statistics stats = getHibernateStatistics();\n            \n            return builder\n                .withDetail(\"responseTime\", duration + \"ms\")\n                .withDetail(\"queries\", stats.getQueryExecutionCount())\n                .withDetail(\"cacheHitRatio\", \n                    calculateCacheHitRatio(stats))\n                .withDetail(\"connections\", stats.getConnectCount())\n                .build();\n                \n        } catch (Exception e) {\n            return Health.down()\n                .withDetail(\"error\", e.getMessage())\n                .withException(e)\n                .build();\n        }\n    }\n    \n    private double calculateCacheHitRatio(Statistics stats) {\n        long hits = stats.getSecondLevelCacheHitCount();\n        long misses = stats.getSecondLevelCacheMissCount();\n        long total = hits + misses;\n        \n        return total > 0 ? (double) hits / total * 100 : 0;\n    }\n}\n\n// 5. Query logging with parameters\nspring.jpa.show-sql=true\nspring.jpa.properties.hibernate.format_sql=true\nlogging.level.org.hibernate.SQL=DEBUG\nlogging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE\n\n@Component\npublic class SqlStatementLogger {\n    \n    @Around(\"execution(* javax.persistence.EntityManager.*(..))\")\n    public Object logSqlExecution(ProceedingJoinPoint joinPoint) throws Throwable {\n        \n        String methodName = joinPoint.getSignature().getName();\n        Object[] args = joinPoint.getArgs();\n        \n        logger.debug(\"Executing: {} with args: {}\", methodName, args);\n        \n        long start = System.nanoTime();\n        Object result = joinPoint.proceed();\n        long duration = System.nanoTime() - start;\n        \n        logger.debug(\"Completed: {} in {}Î¼s\", \n            methodName, \n            duration / 1000);\n        \n        return result;\n    }\n}\n\n// 6. Slow query detector\n@Component\npublic class SlowQueryDetector {\n    \n    private final ConcurrentHashMap<String, QueryStats> queryStats = \n        new ConcurrentHashMap<>();\n    \n    public void recordQuery(String sql, long durationMs) {\n        String normalizedSql = normalizeSql(sql);\n        \n        queryStats.compute(normalizedSql, (key, stats) -> {\n            if (stats == null) {\n                stats = new QueryStats();\n            }\n            stats.addExecution(durationMs);\n            return stats;\n        });\n    }\n    \n    @Scheduled(fixedRate = 300000) // Every 5 minutes\n    public void reportSlowQueries() {\n        logger.info(\"=== Top Slow Queries ===\");\n        \n        queryStats.entrySet().stream()\n            .sorted((e1, e2) -> \n                Double.compare(e2.getValue().getAvgDuration(), \n                              e1.getValue().getAvgDuration()))\n            .limit(10)\n            .forEach(entry -> {\n                QueryStats stats = entry.getValue();\n                logger.info(\n                    \"Query: {} | Avg: {}ms | Max: {}ms | Count: {}\",\n                    entry.getKey(),\n                    stats.getAvgDuration(),\n                    stats.getMaxDuration(),\n                    stats.getCount()\n                );\n            });\n    }\n    \n    private String normalizeSql(String sql) {\n        // Remove parameter values for grouping\n        return sql.replaceAll(\"'[^']*'\", \"?\");\n    }\n}\n\nclass QueryStats {\n    private long totalDuration;\n    private long maxDuration;\n    private int count;\n    \n    public synchronized void addExecution(long duration) {\n        totalDuration += duration;\n        maxDuration = Math.max(maxDuration, duration);\n        count++;\n    }\n    \n    public double getAvgDuration() {\n        return count > 0 ? (double) totalDuration / count : 0;\n    }\n}"
    },
    {
      "id": 88,
      "question": "How do you implement database security best practices in JPA?",
      "answer": "Security practices protect data and prevent attacks:\n\nKey Practices:\n• Prevent SQL injection: Use parameterized queries\n• Encrypt sensitive data: At rest and in transit\n• Least privilege: Minimal DB permissions\n• Audit logging: Track data access\n• Secure credentials: Use secrets management\n\nImplementation:\n• Never concatenate SQL\n• Use @Query with :params\n• Encrypt PII fields\n• SSL/TLS connections\n• Row-level security\n• Prepared statements",
      "explanation": "Database security best practices prevent unauthorized access, data breaches, and injection attacks while maintaining compliance with regulations.",
      "difficulty": "Hard",
      "code": "// 1. Prevent SQL injection - CORRECT way\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // âœ… SAFE: Parameterized query\n    @Query(\"SELECT u FROM User u WHERE u.email = :email\")\n    Optional<User> findByEmail(@Param(\"email\") String email);\n    \n    // âœ… SAFE: Named parameter in native query\n    @Query(value = \n        \"SELECT * FROM users WHERE username = :username\",\n        nativeQuery = true)\n    Optional<User> findByUsername(@Param(\"username\") String username);\n    \n    // âŒ UNSAFE: String concatenation (NEVER DO THIS)\n    // @Query(value = \n    //     \"SELECT * FROM users WHERE email = '\" + email + \"'\",\n    //     nativeQuery = true)\n    // List<User> findUnsafe(String email);\n}\n\n// 2. Encrypt sensitive data\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String username;\n    \n    // Encrypt email at rest\n    @Convert(converter = EncryptedStringConverter.class)\n    @Column(name = \"email\")\n    private String email;\n    \n    // Encrypt SSN\n    @Convert(converter = EncryptedStringConverter.class)\n    @Column(name = \"ssn\")\n    private String ssn;\n    \n    // Hash password (never store plain text)\n    @Column(name = \"password_hash\")\n    private String passwordHash;\n}\n\n@Converter\npublic class EncryptedStringConverter \n        implements AttributeConverter<String, String> {\n    \n    @Autowired\n    private EncryptionService encryptionService;\n    \n    @Override\n    public String convertToDatabaseColumn(String attribute) {\n        if (attribute == null) return null;\n        \n        try {\n            return encryptionService.encrypt(attribute);\n        } catch (Exception e) {\n            throw new RuntimeException(\"Encryption failed\", e);\n        }\n    }\n    \n    @Override\n    public String convertToEntityAttribute(String dbData) {\n        if (dbData == null) return null;\n        \n        try {\n            return encryptionService.decrypt(dbData);\n        } catch (Exception e) {\n            throw new RuntimeException(\"Decryption failed\", e);\n        }\n    }\n}\n\n@Service\npublic class EncryptionService {\n    \n    private static final String ALGORITHM = \"AES/GCM/NoPadding\";\n    \n    @Value(\"${encryption.key}\")\n    private String encryptionKey;\n    \n    public String encrypt(String plaintext) throws Exception {\n        Cipher cipher = Cipher.getInstance(ALGORITHM);\n        SecretKeySpec keySpec = new SecretKeySpec(\n            encryptionKey.getBytes(),\n            \"AES\"\n        );\n        \n        cipher.init(Cipher.ENCRYPT_MODE, keySpec);\n        byte[] encrypted = cipher.doFinal(plaintext.getBytes());\n        \n        return Base64.getEncoder().encodeToString(encrypted);\n    }\n    \n    public String decrypt(String ciphertext) throws Exception {\n        Cipher cipher = Cipher.getInstance(ALGORITHM);\n        SecretKeySpec keySpec = new SecretKeySpec(\n            encryptionKey.getBytes(),\n            \"AES\"\n        );\n        \n        cipher.init(Cipher.DECRYPT_MODE, keySpec);\n        byte[] decrypted = cipher.doFinal(\n            Base64.getDecoder().decode(ciphertext)\n        );\n        \n        return new String(decrypted);\n    }\n}\n\n// 3. Secure database credentials\n// Use environment variables\nspring.datasource.url=${DB_URL}\nspring.datasource.username=${DB_USERNAME}\nspring.datasource.password=${DB_PASSWORD}\n\n// Or AWS Secrets Manager\n@Configuration\npublic class SecretsManagerConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        // Retrieve credentials from AWS Secrets Manager\n        AWSSecretsManager client = AWSSecretsManagerClientBuilder\n            .standard()\n            .withRegion(region)\n            .build();\n        \n        GetSecretValueRequest request = new GetSecretValueRequest()\n            .withSecretId(\"prod/database/credentials\");\n        \n        GetSecretValueResult result = client.getSecretValue(request);\n        String secret = result.getSecretString();\n        \n        // Parse JSON secret\n        JSONObject credentials = new JSONObject(secret);\n        String username = credentials.getString(\"username\");\n        String password = credentials.getString(\"password\");\n        \n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(jdbcUrl);\n        config.setUsername(username);\n        config.setPassword(password);\n        \n        return new HikariDataSource(config);\n    }\n}\n\n// 4. SSL/TLS connection\nspring.datasource.url=jdbc:postgresql://localhost:5432/mydb?ssl=true&sslmode=require\nspring.datasource.hikari.data-source-properties.ssl=true\nspring.datasource.hikari.data-source-properties.sslmode=require\n\n// 5. Audit logging\n@Entity\n@EntityListeners(AuditingEntityListener.class)\npublic class SensitiveData {\n    @Id\n    private Long id;\n    \n    private String data;\n    \n    @CreatedBy\n    private String createdBy;\n    \n    @CreatedDate\n    private LocalDateTime createdAt;\n    \n    @LastModifiedBy\n    private String modifiedBy;\n    \n    @LastModifiedDate\n    private LocalDateTime modifiedAt;\n}\n\n@Component\npublic class DataAccessAuditor implements AuditorAware<String> {\n    \n    @Override\n    public Optional<String> getCurrentAuditor() {\n        // Get from security context\n        Authentication auth = SecurityContextHolder\n            .getContext()\n            .getAuthentication();\n        \n        if (auth == null) {\n            return Optional.of(\"SYSTEM\");\n        }\n        \n        return Optional.of(auth.getName());\n    }\n}\n\n// Track all data access\n@Aspect\n@Component\npublic class DataAccessLogger {\n    \n    @Autowired\n    private AuditLogRepository auditLogRepository;\n    \n    @AfterReturning(\n        pointcut = \"execution(* com.example.repository.*.*(..))\",\n        returning = \"result\"\n    )\n    public void logDataAccess(JoinPoint joinPoint, Object result) {\n        String username = SecurityContextHolder\n            .getContext()\n            .getAuthentication()\n            .getName();\n        \n        String method = joinPoint.getSignature().getName();\n        String args = Arrays.toString(joinPoint.getArgs());\n        \n        AuditLog log = new AuditLog();\n        log.setUsername(username);\n        log.setAction(method);\n        log.setParameters(args);\n        log.setTimestamp(LocalDateTime.now());\n        log.setIpAddress(getClientIp());\n        \n        auditLogRepository.save(log);\n    }\n}\n\n// 6. Row-level security (PostgreSQL)\n/*\n-- Enable row-level security\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\n\n-- Policy: Users can only see their own orders\nCREATE POLICY order_isolation ON orders\n    FOR ALL\n    TO application_user\n    USING (user_id = current_setting('app.current_user_id')::bigint);\n*/\n\n@Service\npublic class RowLevelSecurityService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void setCurrentUser(Long userId) {\n        // Set session variable for row-level security\n        entityManager.createNativeQuery(\n            \"SET LOCAL app.current_user_id = :userId\"\n        )\n        .setParameter(\"userId\", userId)\n        .executeUpdate();\n    }\n}\n\n// 7. Input validation\n@Entity\npublic class Product {\n    @Id\n    private Long id;\n    \n    @NotBlank\n    @Size(max = 255)\n    private String name;\n    \n    @Email\n    private String contactEmail;\n    \n    @Pattern(regexp = \"^[A-Z]{2}\\\\d{8}$\")\n    private String productCode;\n}"
    },
    {
      "id": 89,
      "question": "How do you implement database performance tuning in JPA?",
      "answer": "Performance tuning optimizes database operations:\n\nKey Areas:\n• Query optimization: Reduce execution time\n• Indexing: Speed up lookups\n• Connection pooling: Reduce overhead\n• Caching: Minimize queries\n• Batch operations: Bulk processing\n• Lazy loading: On-demand fetching\n\nTechniques:\n• Query profiling\n• EXPLAIN ANALYZE\n• Index tuning\n• N+1 prevention\n• Pagination\n• Projections\n• Database hints",
      "explanation": "Systematic performance tuning identifies bottlenecks and applies targeted optimizations to improve application response times and throughput.",
      "difficulty": "Hard",
      "code": "// 1. Query profiling and analysis\n@Aspect\n@Component\npublic class QueryProfiler {\n    \n    private static final long SLOW_QUERY_THRESHOLD = 100; // ms\n    \n    @Around(\"execution(* com.example.repository.*.*(..))\")\n    public Object profileQuery(ProceedingJoinPoint joinPoint) throws Throwable {\n        \n        String methodName = joinPoint.getSignature().toShortString();\n        long start = System.nanoTime();\n        \n        Object result = joinPoint.proceed();\n        \n        long durationMs = (System.nanoTime() - start) / 1_000_000;\n        \n        if (durationMs > SLOW_QUERY_THRESHOLD) {\n            logger.warn(\n                \"SLOW QUERY: {} took {}ms\",\n                methodName,\n                durationMs\n            );\n            \n            // Get SQL from Hibernate\n            logActualSql();\n        }\n        \n        return result;\n    }\n    \n    private void logActualSql() {\n        // Hibernate logs the actual SQL when show-sql is enabled\n        // Can also use P6Spy for detailed SQL logging\n    }\n}\n\n// 2. Optimize with EXPLAIN ANALYZE\n@Service\npublic class QueryOptimizationService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public void analyzeQuery(String sql) {\n        // PostgreSQL EXPLAIN ANALYZE\n        String explainSql = \"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) \" + sql;\n        \n        Object result = entityManager\n            .createNativeQuery(explainSql)\n            .getSingleResult();\n        \n        logger.info(\"Query plan: {}\", result);\n        \n        // Parse and analyze\n        analyzeQueryPlan(result.toString());\n    }\n    \n    private void analyzeQueryPlan(String plan) {\n        // Check for:\n        // - Sequential scans (should use index)\n        // - High cost estimates\n        // - Many rows processed\n        // - Missing indexes\n        \n        if (plan.contains(\"Seq Scan\")) {\n            logger.warn(\"Query using sequential scan - consider adding index\");\n        }\n    }\n}\n\n// 3. Batch operations optimization\n@Service\npublic class BatchOptimizationService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void batchInsertOptimized(List<Product> products) {\n        int batchSize = 50;\n        \n        for (int i = 0; i < products.size(); i++) {\n            entityManager.persist(products.get(i));\n            \n            if (i % batchSize == 0 && i > 0) {\n                // Flush batch to database\n                entityManager.flush();\n                entityManager.clear();\n            }\n        }\n    }\n    \n    @Transactional\n    public void batchUpdateOptimized(List<Long> ids) {\n        // Use bulk update instead of loading entities\n        entityManager.createQuery(\n            \"UPDATE Product p SET p.status = :status \" +\n            \"WHERE p.id IN :ids\"\n        )\n        .setParameter(\"status\", \"ACTIVE\")\n        .setParameter(\"ids\", ids)\n        .executeUpdate();\n    }\n}\n\nspring.jpa.properties.hibernate.jdbc.batch_size=50\nspring.jpa.properties.hibernate.order_inserts=true\nspring.jpa.properties.hibernate.order_updates=true\nspring.jpa.properties.hibernate.jdbc.batch_versioned_data=true\n\n// 4. Fetch strategy optimization\n@Entity\npublic class Order {\n    @Id\n    private Long id;\n    \n    // Default: Lazy load items only when accessed\n    @OneToMany(mappedBy = \"order\", fetch = FetchType.LAZY)\n    private List<OrderItem> items;\n    \n    // Eager load customer (always needed)\n    @ManyToOne(fetch = FetchType.EAGER)\n    private Customer customer;\n}\n\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    // Solve N+1 with JOIN FETCH\n    @Query(\"SELECT o FROM Order o \" +\n           \"JOIN FETCH o.items \" +\n           \"JOIN FETCH o.customer \" +\n           \"WHERE o.id = :id\")\n    Optional<Order> findByIdWithDetails(@Param(\"id\") Long id);\n    \n    // Batch fetch to avoid N+1\n    @QueryHints(@QueryHint(\n        name = \"hibernate.default_batch_fetch_size\",\n        value = \"10\"\n    ))\n    List<Order> findByStatus(String status);\n}\n\nspring.jpa.properties.hibernate.default_batch_fetch_size=10\n\n// 5. Projection optimization\n// Don't fetch entire entity if you only need few fields\n\npublic interface OrderSummary {\n    Long getId();\n    String getOrderNumber();\n    BigDecimal getTotal();\n}\n\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    // Projection returns only selected fields\n    @Query(\"SELECT o.id as id, o.orderNumber as orderNumber, \" +\n           \"o.total as total FROM Order o\")\n    List<OrderSummary> findAllSummaries();\n    \n    // Constructor expression\n    @Query(\"SELECT new com.example.dto.OrderDTO(\" +\n           \"o.id, o.orderNumber, o.total) FROM Order o\")\n    List<OrderDTO> findAllDTOs();\n}\n\n// 6. Pagination for large datasets\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    Page<Order> findByStatus(\n        String status,\n        Pageable pageable\n    );\n}\n\n@Service\npublic class OrderService {\n    \n    public Page<Order> getOrders(int page, int size) {\n        // Only fetch one page at a time\n        Pageable pageable = PageRequest.of(\n            page,\n            size,\n            Sort.by(\"createdAt\").descending()\n        );\n        \n        return orderRepository.findByStatus(\"ACTIVE\", pageable);\n    }\n}\n\n// 7. Database hints (Oracle example)\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    @Query(value = \n        \"SELECT /*+ INDEX(products idx_product_name) */ * \" +\n        \"FROM products WHERE name LIKE :name\",\n        nativeQuery = true)\n    List<Product> findByNameWithHint(@Param(\"name\") String name);\n}\n\n// 8. Monitor and tune\n@Component\npublic class PerformanceMonitor {\n    \n    @Scheduled(fixedRate = 60000)\n    public void checkPerformance() {\n        Statistics stats = getHibernateStatistics();\n        \n        long queries = stats.getQueryExecutionCount();\n        long maxTime = stats.getQueryExecutionMaxTime();\n        String slowestQuery = stats.getQueryExecutionMaxTimeQueryString();\n        \n        logger.info(\"Queries: {}, Slowest: {}ms\", queries, maxTime);\n        \n        if (maxTime > 1000) {\n            logger.warn(\"Very slow query detected: {}\", slowestQuery);\n        }\n        \n        // Cache hit ratio\n        double hitRatio = calculateCacheHitRatio(stats);\n        if (hitRatio < 0.8) {\n            logger.warn(\"Low cache hit ratio: {}%\", hitRatio * 100);\n        }\n    }\n}"
    },
    {
      "id": 90,
      "question": "How do you implement JPA in microservices architecture?",
      "answer": "JPA in microservices requires special considerations:\n\nPatterns:\n• Database per service: Each service owns data\n• Saga pattern: Distributed transactions\n• CQRS: Command/Query separation\n• Event sourcing: Event-driven state\n• API composition: Join across services\n\nChallenges:\n• No distributed transactions\n• Data consistency\n• Joins across services\n• Schema evolution\n\nSolutions:\n• Eventual consistency\n• Compensating transactions\n• Event-driven architecture\n• Service mesh",
      "explanation": "Microservices architecture demands different data management strategies, moving from traditional ACID transactions to eventual consistency and event-driven patterns.",
      "difficulty": "Hard",
      "code": "// 1. Database per service\n// Order Service\n@Entity\n@Table(name = \"orders\")\npublic class Order {\n    @Id\n    private Long id;\n    \n    private Long customerId; // Reference, not @ManyToOne\n    private String status;\n    private BigDecimal total;\n    \n    // No direct join to Customer entity\n    // Customer data is in different service\n}\n\n@Service\npublic class OrderService {\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @Autowired\n    private CustomerServiceClient customerClient;\n    \n    public OrderDTO getOrderWithCustomer(Long orderId) {\n        Order order = orderRepository.findById(orderId)\n            .orElseThrow();\n        \n        // Call customer service via REST/gRPC\n        CustomerDTO customer = customerClient\n            .getCustomer(order.getCustomerId());\n        \n        return OrderDTO.builder()\n            .order(order)\n            .customer(customer)\n            .build();\n    }\n}\n\n// 2. Saga pattern for distributed transactions\n@Entity\npublic class OrderSaga {\n    @Id\n    private String sagaId;\n    \n    private String status; // PENDING, COMPLETED, COMPENSATING, FAILED\n    private String currentStep;\n    \n    @ElementCollection\n    private List<String> completedSteps;\n}\n\n@Service\npublic class OrderSagaOrchestrator {\n    \n    @Transactional\n    public void createOrder(CreateOrderRequest request) {\n        // 1. Create saga\n        OrderSaga saga = new OrderSaga();\n        saga.setSagaId(UUID.randomUUID().toString());\n        saga.setStatus(\"PENDING\");\n        sagaRepository.save(saga);\n        \n        try {\n            // 2. Reserve inventory (compensatable)\n            inventoryService.reserveItems(request.getItems());\n            saga.addCompletedStep(\"INVENTORY_RESERVED\");\n            \n            // 3. Process payment (compensatable)\n            paymentService.processPayment(request.getPayment());\n            saga.addCompletedStep(\"PAYMENT_PROCESSED\");\n            \n            // 4. Create order\n            Order order = createOrder(request);\n            saga.addCompletedStep(\"ORDER_CREATED\");\n            \n            // 5. Mark saga complete\n            saga.setStatus(\"COMPLETED\");\n            sagaRepository.save(saga);\n            \n        } catch (Exception e) {\n            // Compensate (rollback)\n            compensateSaga(saga);\n            throw new SagaFailedException(\"Order creation failed\", e);\n        }\n    }\n    \n    @Transactional\n    public void compensateSaga(OrderSaga saga) {\n        saga.setStatus(\"COMPENSATING\");\n        \n        // Undo in reverse order\n        List<String> steps = saga.getCompletedSteps();\n        Collections.reverse(steps);\n        \n        for (String step : steps) {\n            switch (step) {\n                case \"INVENTORY_RESERVED\":\n                    inventoryService.releaseInventory(saga.getSagaId());\n                    break;\n                case \"PAYMENT_PROCESSED\":\n                    paymentService.refundPayment(saga.getSagaId());\n                    break;\n                case \"ORDER_CREATED\":\n                    orderService.cancelOrder(saga.getSagaId());\n                    break;\n            }\n        }\n        \n        saga.setStatus(\"FAILED\");\n        sagaRepository.save(saga);\n    }\n}\n\n// 3. Event-driven with outbox pattern\n@Entity\npublic class OutboxEvent {\n    @Id\n    private String id;\n    \n    private String aggregateType; // Order, Payment, etc.\n    private String aggregateId;\n    private String eventType; // ORDER_CREATED, PAYMENT_COMPLETED\n    \n    @Column(columnDefinition = \"jsonb\")\n    private String payload;\n    \n    private LocalDateTime createdAt;\n    private Boolean published = false;\n}\n\n@Service\npublic class OrderService {\n    \n    @Transactional\n    public Order createOrder(CreateOrderRequest request) {\n        // 1. Create order (same transaction)\n        Order order = new Order();\n        order.setCustomerId(request.getCustomerId());\n        order.setStatus(\"PENDING\");\n        orderRepository.save(order);\n        \n        // 2. Store event in outbox (same transaction)\n        OutboxEvent event = new OutboxEvent();\n        event.setAggregateType(\"Order\");\n        event.setAggregateId(order.getId().toString());\n        event.setEventType(\"ORDER_CREATED\");\n        event.setPayload(toJson(order));\n        outboxRepository.save(event);\n        \n        // 3. Both saved atomically\n        return order;\n    }\n}\n\n// Separate process publishes events\n@Service\npublic class OutboxPublisher {\n    \n    @Scheduled(fixedDelay = 5000)\n    @Transactional\n    public void publishEvents() {\n        List<OutboxEvent> unpublished = outboxRepository\n            .findByPublishedFalse();\n        \n        for (OutboxEvent event : unpublished) {\n            try {\n                // Publish to message broker\n                kafkaTemplate.send(\n                    event.getEventType(),\n                    event.getPayload()\n                );\n                \n                // Mark as published\n                event.setPublished(true);\n                outboxRepository.save(event);\n                \n            } catch (Exception e) {\n                logger.error(\"Failed to publish event\", e);\n                // Retry on next run\n            }\n        }\n    }\n}\n\n// 4. CQRS pattern\n// Command side (write)\n@Service\npublic class OrderCommandService {\n    \n    @Transactional\n    public void createOrder(CreateOrderCommand command) {\n        Order order = new Order();\n        // ... create order\n        orderRepository.save(order);\n        \n        // Publish event\n        eventPublisher.publish(new OrderCreatedEvent(order));\n    }\n}\n\n// Query side (read) - separate database\n@Entity\n@Table(name = \"order_view\")\npublic class OrderView {\n    @Id\n    private Long orderId;\n    \n    // Denormalized data from multiple services\n    private String customerName;\n    private String customerEmail;\n    private BigDecimal totalAmount;\n    private Integer itemCount;\n    private String status;\n}\n\n@Service\npublic class OrderViewProjection {\n    \n    @KafkaListener(topics = \"order-events\")\n    public void handleOrderCreated(OrderCreatedEvent event) {\n        // Update read model\n        OrderView view = new OrderView();\n        view.setOrderId(event.getOrderId());\n        // ... populate from event\n        orderViewRepository.save(view);\n    }\n}\n\n// 5. Service communication\n@FeignClient(name = \"customer-service\")\npublic interface CustomerServiceClient {\n    \n    @GetMapping(\"/api/customers/{id}\")\n    CustomerDTO getCustomer(@PathVariable Long id);\n}\n\n// With circuit breaker\n@Service\npublic class ResilientOrderService {\n    \n    @CircuitBreaker(\n        name = \"customerService\",\n        fallbackMethod = \"getCustomerFallback\"\n    )\n    public CustomerDTO getCustomer(Long customerId) {\n        return customerClient.getCustomer(customerId);\n    }\n    \n    private CustomerDTO getCustomerFallback(Long customerId, Exception e) {\n        // Return cached data or default\n        return customerCache.get(customerId)\n            .orElse(CustomerDTO.anonymous());\n    }\n}"
    },
    {
      "id": 91,
      "question": "How do you implement database testing strategies in JPA?",
      "answer": "Testing ensures database code correctness:\n\nTesting Levels:\n• Unit tests: Repository logic\n• Integration tests: Database interaction\n• Contract tests: API contracts\n\nTools:\n• @DataJpaTest: JPA slice testing\n• TestContainers: Real database in Docker\n• H2: In-memory database\n• DBUnit: Dataset management\n\nStrategies:\n• Test isolation\n• Clean database per test\n• Test data builders\n• Transaction rollback",
      "explanation": "Comprehensive database testing validates repository behavior, query correctness, and data integrity using real or in-memory databases.",
      "difficulty": "Medium",
      "code": "// 1. @DataJpaTest for repository testing\n@DataJpaTest\nclass OrderRepositoryTest {\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @Autowired\n    private TestEntityManager entityManager;\n    \n    @Test\n    void testFindByStatus() {\n        // Given\n        Order order = new Order();\n        order.setStatus(\"PENDING\");\n        order.setTotal(BigDecimal.valueOf(100));\n        entityManager.persist(order);\n        entityManager.flush();\n        \n        // When\n        List<Order> found = orderRepository.findByStatus(\"PENDING\");\n        \n        // Then\n        assertThat(found).hasSize(1);\n        assertThat(found.get(0).getStatus()).isEqualTo(\"PENDING\");\n    }\n    \n    @Test\n    void testCustomQuery() {\n        // Given\n        Order order1 = createOrder(\"PENDING\", 100);\n        Order order2 = createOrder(\"COMPLETED\", 200);\n        entityManager.persist(order1);\n        entityManager.persist(order2);\n        entityManager.flush();\n        \n        // When\n        BigDecimal total = orderRepository.sumTotalByStatus(\"COMPLETED\");\n        \n        // Then\n        assertThat(total).isEqualByComparingTo(BigDecimal.valueOf(200));\n    }\n}\n\n// 2. TestContainers for integration testing\n@SpringBootTest\n@Testcontainers\nclass OrderServiceIntegrationTest {\n    \n    @Container\n    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\n        \"postgres:15-alpine\"\n    )\n    .withDatabaseName(\"testdb\")\n    .withUsername(\"test\")\n    .withPassword(\"test\");\n    \n    @DynamicPropertySource\n    static void configureProperties(DynamicPropertyRegistry registry) {\n        registry.add(\"spring.datasource.url\", postgres::getJdbcUrl);\n        registry.add(\"spring.datasource.username\", postgres::getUsername);\n        registry.add(\"spring.datasource.password\", postgres::getPassword);\n    }\n    \n    @Autowired\n    private OrderService orderService;\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @Test\n    void testCreateOrder() {\n        // Given\n        CreateOrderRequest request = CreateOrderRequest.builder()\n            .customerId(1L)\n            .items(List.of(/* items */))\n            .build();\n        \n        // When\n        Order order = orderService.createOrder(request);\n        \n        // Then\n        assertThat(order.getId()).isNotNull();\n        \n        // Verify in database\n        Order found = orderRepository.findById(order.getId())\n            .orElseThrow();\n        assertThat(found.getStatus()).isEqualTo(\"PENDING\");\n    }\n    \n    @Test\n    void testComplexScenario() {\n        // Test with real PostgreSQL\n        // Full transaction support\n        // Test database constraints\n        // Test triggers and functions\n    }\n}\n\n// 3. Test data builders\npublic class OrderTestBuilder {\n    private Order order = new Order();\n    \n    public static OrderTestBuilder anOrder() {\n        return new OrderTestBuilder();\n    }\n    \n    public OrderTestBuilder withId(Long id) {\n        order.setId(id);\n        return this;\n    }\n    \n    public OrderTestBuilder withStatus(String status) {\n        order.setStatus(status);\n        return this;\n    }\n    \n    public OrderTestBuilder withTotal(BigDecimal total) {\n        order.setTotal(total);\n        return this;\n    }\n    \n    public OrderTestBuilder withCustomerId(Long customerId) {\n        order.setCustomerId(customerId);\n        return this;\n    }\n    \n    public Order build() {\n        return order;\n    }\n}\n\n// Usage in tests\n@Test\nvoid testWithBuilder() {\n    Order order = anOrder()\n        .withStatus(\"PENDING\")\n        .withTotal(BigDecimal.valueOf(100))\n        .withCustomerId(1L)\n        .build();\n    \n    orderRepository.save(order);\n    // assertions...\n}\n\n// 4. Database cleanup between tests\n@SpringBootTest\nclass DatabaseCleanupTest {\n    \n    @Autowired\n    private EntityManager entityManager;\n    \n    @Autowired\n    private List<JpaRepository<?, ?>> repositories;\n    \n    @BeforeEach\n    void cleanDatabase() {\n        // Delete all data from all repositories\n        repositories.forEach(JpaRepository::deleteAll);\n        \n        // Or truncate tables\n        entityManager.createNativeQuery(\"TRUNCATE TABLE orders CASCADE\")\n            .executeUpdate();\n        entityManager.createNativeQuery(\"TRUNCATE TABLE order_items CASCADE\")\n            .executeUpdate();\n    }\n    \n    @AfterEach\n    void verifyCleanup() {\n        // Verify database is clean\n        long count = entityManager\n            .createQuery(\"SELECT COUNT(o) FROM Order o\", Long.class)\n            .getSingleResult();\n        assertThat(count).isZero();\n    }\n}\n\n// 5. Test SQL scripts\n@SpringBootTest\n@Sql(scripts = \"/test-data.sql\", executionPhase = Sql.ExecutionPhase.BEFORE_TEST_METHOD)\n@Sql(scripts = \"/cleanup.sql\", executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD)\nclass SqlScriptTest {\n    \n    @Test\n    void testWithPreparedData() {\n        // Data loaded from test-data.sql\n        List<Order> orders = orderRepository.findAll();\n        assertThat(orders).isNotEmpty();\n    }\n}\n\n// test-data.sql\n/*\nINSERT INTO orders (id, status, total, customer_id) \nVALUES \n    (1, 'PENDING', 100.00, 1),\n    (2, 'COMPLETED', 200.00, 2);\n\nINSERT INTO order_items (id, order_id, product_id, quantity)\nVALUES\n    (1, 1, 101, 2),\n    (2, 1, 102, 1);\n*/\n\n// 6. Parameterized tests\n@DataJpaTest\nclass ParameterizedRepositoryTest {\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @ParameterizedTest\n    @CsvSource({\n        \"PENDING, 1\",\n        \"COMPLETED, 2\",\n        \"CANCELLED, 0\"\n    })\n    void testFindByStatus(String status, int expectedCount) {\n        // Setup\n        createOrder(\"PENDING\");\n        createOrder(\"COMPLETED\");\n        createOrder(\"COMPLETED\");\n        \n        // Test\n        List<Order> orders = orderRepository.findByStatus(status);\n        \n        assertThat(orders).hasSize(expectedCount);\n    }\n}\n\n// 7. Test transaction behavior\n@SpringBootTest\nclass TransactionTest {\n    \n    @Autowired\n    private OrderService orderService;\n    \n    @Autowired\n    private OrderRepository orderRepository;\n    \n    @Test\n    void testRollbackOnException() {\n        // Given\n        CreateOrderRequest request = invalidRequest();\n        \n        // When/Then\n        assertThrows(\n            ValidationException.class,\n            () -> orderService.createOrder(request)\n        );\n        \n        // Verify rollback\n        assertThat(orderRepository.findAll()).isEmpty();\n    }\n    \n    @Test\n    void testOptimisticLockingException() {\n        // Create order\n        Order order = new Order();\n        order.setStatus(\"PENDING\");\n        orderRepository.save(order);\n        entityManager.flush();\n        entityManager.clear();\n        \n        // Load in two transactions\n        Order order1 = orderRepository.findById(order.getId()).get();\n        Order order2 = orderRepository.findById(order.getId()).get();\n        \n        // Update first\n        order1.setStatus(\"PROCESSING\");\n        orderRepository.save(order1);\n        \n        // Update second - should fail\n        order2.setStatus(\"COMPLETED\");\n        assertThrows(\n            OptimisticLockingFailureException.class,\n            () -> orderRepository.save(order2)\n        );\n    }\n}\n\n// 8. Performance testing\n@SpringBootTest\nclass PerformanceTest {\n    \n    @Test\n    void testQueryPerformance() {\n        // Insert test data\n        for (int i = 0; i < 10000; i++) {\n            orderRepository.save(createOrder());\n        }\n        \n        // Measure query time\n        long start = System.currentTimeMillis();\n        List<Order> orders = orderRepository.findByStatus(\"PENDING\");\n        long duration = System.currentTimeMillis() - start;\n        \n        assertThat(duration).isLessThan(100); // < 100ms\n        assertThat(orders).isNotEmpty();\n    }\n}"
    },
    {
      "id": 92,
      "question": "How do you implement database disaster recovery in JPA applications?",
      "answer": "Disaster recovery ensures business continuity:\n\nComponents:\n• Backup strategy: Regular backups\n• Replication: Real-time data copy\n• Failover: Automatic switch\n• Recovery procedures: Documented steps\n• Testing: Regular DR drills\n\nMetrics:\n• RTO: Recovery Time Objective\n• RPO: Recovery Point Objective\n\nTechnologies:\n• Database replication\n• WAL archiving\n• Cloud backups\n• Multi-region deployment\n• Read replicas",
      "explanation": "Disaster recovery plans with automated backups, replication, and tested procedures ensure rapid recovery from catastrophic failures.",
      "difficulty": "Hard",
      "code": "// 1. Multi-region configuration\n@Configuration\npublic class MultiRegionDataSourceConfig {\n    \n    @Bean\n    @Primary\n    @ConfigurationProperties(\"spring.datasource.primary\")\n    public DataSource primaryDataSource() {\n        // Primary region (e.g., us-east-1)\n        return DataSourceBuilder.create().build();\n    }\n    \n    @Bean\n    @ConfigurationProperties(\"spring.datasource.secondary\")\n    public DataSource secondaryDataSource() {\n        // Secondary region (e.g., us-west-2)\n        return DataSourceBuilder.create().build();\n    }\n    \n    @Bean\n    public DataSource routingDataSource(\n            @Qualifier(\"primaryDataSource\") DataSource primary,\n            @Qualifier(\"secondaryDataSource\") DataSource secondary) {\n        \n        return new DisasterRecoveryDataSource(primary, secondary);\n    }\n}\n\npublic class DisasterRecoveryDataSource extends AbstractRoutingDataSource {\n    \n    private final DataSource primary;\n    private final DataSource secondary;\n    private volatile boolean primaryAvailable = true;\n    \n    @Scheduled(fixedRate = 30000) // Check every 30 seconds\n    public void checkPrimaryHealth() {\n        try (Connection conn = primary.getConnection()) {\n            Statement stmt = conn.createStatement();\n            stmt.executeQuery(\"SELECT 1\");\n            \n            if (!primaryAvailable) {\n                logger.info(\"Primary database recovered!\");\n                primaryAvailable = true;\n            }\n            \n        } catch (SQLException e) {\n            logger.error(\"Primary database unavailable\", e);\n            primaryAvailable = false;\n        }\n    }\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return primaryAvailable ? \"primary\" : \"secondary\";\n    }\n}\n\n// 2. Automated backup system\n@Service\npublic class DisasterRecoveryService {\n    \n    @Value(\"${dr.backup.local.path}\")\n    private String localBackupPath;\n    \n    @Value(\"${dr.backup.remote.bucket}\")\n    private String s3Bucket;\n    \n    @Autowired\n    private AmazonS3 s3Client;\n    \n    // Daily full backup\n    @Scheduled(cron = \"0 0 2 * * *\")\n    public void performFullBackup() {\n        String timestamp = LocalDateTime.now()\n            .format(DateTimeFormatter.ofPattern(\"yyyyMMdd_HHmmss\"));\n        \n        String backupFile = String.format(\n            \"%s/full_backup_%s.dump\",\n            localBackupPath,\n            timestamp\n        );\n        \n        try {\n            // Create backup\n            createDatabaseBackup(backupFile);\n            \n            // Verify backup integrity\n            if (!verifyBackup(backupFile)) {\n                throw new BackupException(\"Backup verification failed\");\n            }\n            \n            // Upload to S3 (multiple regions)\n            uploadToMultipleRegions(backupFile);\n            \n            // Store metadata\n            recordBackupMetadata(backupFile, \"FULL\");\n            \n            logger.info(\"Full backup completed: {}\", backupFile);\n            \n        } catch (Exception e) {\n            logger.error(\"Full backup failed\", e);\n            alertDRTeam(\"Full backup failure: \" + e.getMessage());\n        }\n    }\n    \n    // Hourly incremental backup (WAL archiving)\n    @Scheduled(cron = \"0 0 * * * *\")\n    public void archiveWALFiles() {\n        try {\n            // Archive PostgreSQL WAL files\n            List<File> walFiles = findUnbackedWALFiles();\n            \n            for (File wal : walFiles) {\n                String s3Key = \"wal/\" + wal.getName();\n                \n                // Upload to S3\n                s3Client.putObject(\n                    s3Bucket,\n                    s3Key,\n                    wal\n                );\n                \n                // Mark as archived\n                markWALAsArchived(wal);\n            }\n            \n            logger.info(\"Archived {} WAL files\", walFiles.size());\n            \n        } catch (Exception e) {\n            logger.error(\"WAL archiving failed\", e);\n        }\n    }\n    \n    private void uploadToMultipleRegions(String backupFile) {\n        List<String> regions = List.of(\"us-east-1\", \"us-west-2\", \"eu-west-1\");\n        \n        for (String region : regions) {\n            try {\n                AmazonS3 regionalClient = AmazonS3ClientBuilder\n                    .standard()\n                    .withRegion(region)\n                    .build();\n                \n                String bucket = String.format(\"%s-%s\", s3Bucket, region);\n                \n                regionalClient.putObject(\n                    new PutObjectRequest(\n                        bucket,\n                        new File(backupFile).getName(),\n                        new File(backupFile)\n                    )\n                    .withStorageClass(StorageClass.StandardInfrequentAccess)\n                );\n                \n                logger.info(\"Backup uploaded to region: {}\", region);\n                \n            } catch (Exception e) {\n                logger.error(\"Failed to upload to region: {}\", region, e);\n            }\n        }\n    }\n}\n\n// 3. Point-in-time recovery\n@Service\npublic class PointInTimeRecoveryService {\n    \n    public void recoverToPointInTime(LocalDateTime targetTime) {\n        logger.warn(\"Starting point-in-time recovery to: {}\", targetTime);\n        \n        try {\n            // 1. Stop application\n            stopApplication();\n            \n            // 2. Find base backup before target time\n            BackupMetadata baseBackup = findBaseBackup(targetTime);\n            \n            // 3. Restore base backup\n            restoreBaseBackup(baseBackup.getPath());\n            \n            // 4. Replay WAL files up to target time\n            replayWALFiles(baseBackup.getTimestamp(), targetTime);\n            \n            // 5. Verify recovery\n            verifyRecovery(targetTime);\n            \n            // 6. Start application\n            startApplication();\n            \n            logger.info(\"Point-in-time recovery completed\");\n            \n        } catch (Exception e) {\n            logger.error(\"Recovery failed\", e);\n            throw new RecoveryException(\"PITR failed\", e);\n        }\n    }\n    \n    private void replayWALFiles(\n            LocalDateTime from,\n            LocalDateTime to) throws Exception {\n        \n        // PostgreSQL recovery.conf\n        String recoveryConf = String.format(\n            \"restore_command = 'aws s3 cp s3://%s/wal/%%f %%p'\\n\" +\n            \"recovery_target_time = '%s'\\n\" +\n            \"recovery_target_action = 'promote'\",\n            s3Bucket,\n            to.format(DateTimeFormatter.ISO_LOCAL_DATE_TIME)\n        );\n        \n        Files.writeString(\n            Paths.get(dataDirectory, \"recovery.conf\"),\n            recoveryConf\n        );\n        \n        // Start PostgreSQL in recovery mode\n        startPostgreSQLInRecoveryMode();\n    }\n}\n\n// 4. Disaster recovery drill\n@Service\npublic class DisasterRecoveryDrillService {\n    \n    @Scheduled(cron = \"0 0 0 1 * *\") // Monthly\n    public void performDRDrill() {\n        logger.info(\"Starting disaster recovery drill\");\n        \n        DrillReport report = new DrillReport();\n        report.setStartTime(LocalDateTime.now());\n        \n        try {\n            // 1. Test backup availability\n            testBackupAccess(report);\n            \n            // 2. Test restore to staging\n            testRestoreToStaging(report);\n            \n            // 3. Test failover to secondary\n            testFailoverMechanism(report);\n            \n            // 4. Measure RTO/RPO\n            measureRTORPO(report);\n            \n            // 5. Generate report\n            report.setStatus(\"SUCCESS\");\n            report.setEndTime(LocalDateTime.now());\n            \n            saveDrillReport(report);\n            notifyDRTeam(report);\n            \n        } catch (Exception e) {\n            report.setStatus(\"FAILED\");\n            report.setError(e.getMessage());\n            alertDRTeam(\"DR drill failed: \" + e.getMessage());\n        }\n    }\n    \n    private void testRestoreToStaging(DrillReport report) {\n        // Test restore on staging environment\n        String latestBackup = findLatestBackup();\n        \n        long startTime = System.currentTimeMillis();\n        \n        // Restore to staging database\n        restoreToDatabase(latestBackup, stagingDataSource);\n        \n        long restoreTime = System.currentTimeMillis() - startTime;\n        report.setRestoreTimeSeconds(restoreTime / 1000);\n        \n        // Verify data\n        verifyDataIntegrity(stagingDataSource);\n    }\n    \n    private void measureRTORPO(DrillReport report) {\n        // RTO: Time to restore service\n        report.setRtoMinutes(report.getRestoreTimeSeconds() / 60);\n        \n        // RPO: Potential data loss\n        LocalDateTime lastBackup = getLastBackupTime();\n        LocalDateTime now = LocalDateTime.now();\n        long rpoMinutes = Duration.between(lastBackup, now).toMinutes();\n        report.setRpoMinutes(rpoMinutes);\n        \n        // Alert if exceeds target\n        if (report.getRtoMinutes() > TARGET_RTO_MINUTES) {\n            logger.warn(\"RTO exceeds target: {} > {}\",\n                report.getRtoMinutes(), TARGET_RTO_MINUTES);\n        }\n    }\n}\n\n// 5. Monitoring and alerting\n@Component\npublic class DisasterRecoveryMonitor {\n    \n    @Autowired\n    private MeterRegistry metrics;\n    \n    @Scheduled(fixedRate = 60000)\n    public void monitorDRReadiness() {\n        // Check backup age\n        Duration backupAge = getLastBackupAge();\n        metrics.gauge(\"dr.backup.age.hours\", backupAge.toHours());\n        \n        if (backupAge.toHours() > 24) {\n            alertDRTeam(\"Backup older than 24 hours\");\n        }\n        \n        // Check replication lag\n        Duration replicationLag = getReplicationLag();\n        metrics.gauge(\"dr.replication.lag.seconds\", \n            replicationLag.getSeconds());\n        \n        if (replicationLag.getSeconds() > 300) {\n            alertDRTeam(\"High replication lag: \" + replicationLag);\n        }\n        \n        // Check secondary availability\n        boolean secondaryHealthy = checkSecondaryHealth();\n        metrics.gauge(\"dr.secondary.healthy\", secondaryHealthy ? 1 : 0);\n    }\n}"
    },
    {
      "id": 93,
      "question": "How do you implement database compliance and audit requirements in JPA?",
      "answer": "Compliance ensures regulatory requirements are met:\n\nRequirements:\n• GDPR: Data privacy, right to deletion\n• HIPAA: Healthcare data protection\n• SOX: Financial audit trails\n• PCI-DSS: Payment card security\n\nImplementation:\n• Audit logging (who, when, what)\n• Data encryption\n• Access controls\n• Data retention policies\n• Anonymization/pseudonymization\n• Audit trail immutability\n\nTools:\n• Envers (Hibernate)\n• Custom audit tables\n• Event listeners",
      "explanation": "Compliance features track all data access and modifications, encrypt sensitive data, and maintain immutable audit trails for regulatory requirements.",
      "difficulty": "Hard",
      "code": "// 1. Hibernate Envers for audit history\n/*\n<dependency>\n    <groupId>org.hibernate</groupId>\n    <artifactId>hibernate-envers</artifactId>\n</dependency>\n*/\n\n@Entity\n@Audited // Enable auditing for this entity\npublic class Patient {\n    @Id\n    private Long id;\n    \n    private String name;\n    \n    @Audited(targetAuditMode = RelationTargetAuditMode.NOT_AUDITED)\n    @ManyToOne\n    private Hospital hospital;\n    \n    @NotAudited // Don't audit this field\n    private String internalNotes;\n}\n\n@Service\npublic class AuditQueryService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public List<PatientRevision> getPatientHistory(Long patientId) {\n        AuditReader reader = AuditReaderFactory.get(entityManager);\n        \n        // Get all revisions\n        List<Number> revisions = reader.getRevisions(Patient.class, patientId);\n        \n        List<PatientRevision> history = new ArrayList<>();\n        \n        for (Number revision : revisions) {\n            Patient patient = reader.find(\n                Patient.class,\n                patientId,\n                revision\n            );\n            \n            RevisionEntity revEntity = reader.findRevision(\n                RevisionEntity.class,\n                revision\n            );\n            \n            history.add(new PatientRevision(\n                patient,\n                revEntity.getRevisionDate(),\n                revEntity.getUsername()\n            ));\n        }\n        \n        return history;\n    }\n    \n    public Patient getPatientAtDate(Long patientId, LocalDateTime date) {\n        AuditReader reader = AuditReaderFactory.get(entityManager);\n        \n        // Query for state at specific time\n        return reader.find(\n            Patient.class,\n            patientId,\n            Date.from(date.atZone(ZoneId.systemDefault()).toInstant())\n        );\n    }\n}\n\n// 2. Custom audit entity with details\n@Entity\n@Table(name = \"audit_log\")\npublic class AuditLog {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    @Column(nullable = false)\n    private String username;\n    \n    @Column(nullable = false)\n    private String entityType; // e.g., \"Patient\", \"Order\"\n    \n    @Column(nullable = false)\n    private Long entityId;\n    \n    @Column(nullable = false)\n    private String action; // CREATE, UPDATE, DELETE, READ\n    \n    @Column(columnDefinition = \"jsonb\")\n    private String oldValue;\n    \n    @Column(columnDefinition = \"jsonb\")\n    private String newValue;\n    \n    @Column(nullable = false)\n    private LocalDateTime timestamp;\n    \n    private String ipAddress;\n    private String userAgent;\n    \n    @Column(columnDefinition = \"jsonb\")\n    private String additionalData;\n}\n\n@Aspect\n@Component\npublic class AuditAspect {\n    \n    @Autowired\n    private AuditLogRepository auditLogRepository;\n    \n    @AfterReturning(\n        pointcut = \"@annotation(auditable)\",\n        returning = \"result\"\n    )\n    public void auditMethod(JoinPoint joinPoint, Auditable auditable, Object result) {\n        \n        Authentication auth = SecurityContextHolder\n            .getContext()\n            .getAuthentication();\n        \n        AuditLog log = new AuditLog();\n        log.setUsername(auth != null ? auth.getName() : \"SYSTEM\");\n        log.setAction(auditable.action());\n        log.setEntityType(auditable.entityType());\n        log.setTimestamp(LocalDateTime.now());\n        log.setIpAddress(getCurrentIpAddress());\n        \n        // Capture method parameters\n        Object[] args = joinPoint.getArgs();\n        log.setAdditionalData(toJson(args));\n        \n        auditLogRepository.save(log);\n    }\n}\n\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.METHOD)\npublic @interface Auditable {\n    String action();\n    String entityType();\n}\n\n// Usage\n@Service\npublic class PatientService {\n    \n    @Auditable(action = \"UPDATE\", entityType = \"Patient\")\n    public Patient updatePatient(Long id, PatientDTO dto) {\n        // Method automatically audited\n    }\n}\n\n// 3. GDPR compliance - Right to deletion\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String email;\n    \n    @Column(name = \"gdpr_deleted\")\n    private Boolean gdprDeleted = false;\n    \n    @Column(name = \"gdpr_deleted_at\")\n    private LocalDateTime gdprDeletedAt;\n}\n\n@Service\npublic class GDPRComplianceService {\n    \n    @Transactional\n    public void anonymizeUser(Long userId) {\n        User user = userRepository.findById(userId)\n            .orElseThrow();\n        \n        // Create audit trail before deletion\n        createGDPRDeletionAudit(user);\n        \n        // Anonymize personal data\n        user.setEmail(\"deleted-\" + userId + \"@anonymized.com\");\n        user.setName(\"[DELETED]\");\n        user.setPhone(null);\n        user.setAddress(null);\n        user.setGdprDeleted(true);\n        user.setGdprDeletedAt(LocalDateTime.now());\n        \n        userRepository.save(user);\n        \n        // Also delete from all related tables\n        deleteUserPreferences(userId);\n        anonymizeUserOrders(userId);\n    }\n    \n    @Scheduled(cron = \"0 0 2 * * *\") // Daily\n    public void enforceDataRetention() {\n        // Delete old data per retention policy\n        LocalDateTime cutoff = LocalDateTime.now()\n            .minusYears(7); // 7-year retention\n        \n        List<AuditLog> oldLogs = auditLogRepository\n            .findByTimestampBefore(cutoff);\n        \n        // Archive before deletion\n        archiveAuditLogs(oldLogs);\n        \n        // Delete\n        auditLogRepository.deleteAll(oldLogs);\n    }\n}\n\n// 4. PCI-DSS compliance - Protect payment data\n@Entity\npublic class Payment {\n    @Id\n    private Long id;\n    \n    // Only store last 4 digits\n    @Column(name = \"card_last_four\")\n    private String cardLastFour;\n    \n    // Never store full card number\n    // Never store CVV\n    \n    // Tokenize with payment processor\n    @Column(name = \"payment_token\")\n    private String paymentToken;\n    \n    @Convert(converter = EncryptedStringConverter.class)\n    @Column(name = \"billing_address\")\n    private String billingAddress;\n}\n\n@Service\npublic class PaymentService {\n    \n    @Auditable(action = \"PAYMENT_PROCESSED\", entityType = \"Payment\")\n    public Payment processPayment(PaymentRequest request) {\n        // Tokenize card with payment processor\n        String token = paymentProcessor.tokenize(request.getCardNumber());\n        \n        Payment payment = new Payment();\n        payment.setCardLastFour(request.getCardNumber().substring(12));\n        payment.setPaymentToken(token);\n        \n        // Don't log full card number\n        logger.info(\"Payment processed for card ending: {}\",\n            payment.getCardLastFour());\n        \n        return paymentRepository.save(payment);\n    }\n}\n\n// 5. SOX compliance - Immutable audit trail\n@Entity\n@Table(name = \"financial_audit_log\")\n@Immutable // Prevent updates\npublic class FinancialAuditLog {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    @Column(nullable = false, updatable = false)\n    private String transactionId;\n    \n    @Column(nullable = false, updatable = false)\n    private String action;\n    \n    @Column(nullable = false, updatable = false)\n    private String username;\n    \n    @Column(nullable = false, updatable = false)\n    private LocalDateTime timestamp;\n    \n    // Digital signature for integrity\n    @Column(nullable = false, updatable = false)\n    private String signature;\n}\n\n@Service\npublic class FinancialAuditService {\n    \n    public void logFinancialTransaction(\n            String transactionId,\n            String action,\n            Map<String, Object> details) {\n        \n        String username = getCurrentUsername();\n        LocalDateTime timestamp = LocalDateTime.now();\n        \n        // Create signature for integrity\n        String signature = createSignature(\n            transactionId,\n            action,\n            username,\n            timestamp\n        );\n        \n        FinancialAuditLog log = new FinancialAuditLog();\n        log.setTransactionId(transactionId);\n        log.setAction(action);\n        log.setUsername(username);\n        log.setTimestamp(timestamp);\n        log.setSignature(signature);\n        \n        financialAuditRepository.save(log);\n    }\n    \n    public boolean verifyAuditIntegrity(FinancialAuditLog log) {\n        String expectedSignature = createSignature(\n            log.getTransactionId(),\n            log.getAction(),\n            log.getUsername(),\n            log.getTimestamp()\n        );\n        \n        return expectedSignature.equals(log.getSignature());\n    }\n}"
    },
    {
      "id": 94,
      "question": "How do you implement database sharding strategies in JPA?",
      "answer": "Sharding distributes data across multiple databases:\n\nSharding Strategies:\n• Range-based: By ID ranges\n• Hash-based: Hash of key\n• Geographic: By location\n• Tenant-based: By customer\n• Time-based: By date\n\nImplementation:\n• AbstractRoutingDataSource\n• Shard key selection\n• Cross-shard queries\n• Rebalancing strategy\n\nChallenges:\n• Cross-shard joins\n• Distributed transactions\n• Data migration\n• Complexity",
      "explanation": "Sharding enables horizontal scaling by partitioning data across multiple databases, improving performance and capacity for large-scale applications.",
      "difficulty": "Hard",
      "code": "// 1. Hash-based sharding\n@Configuration\npublic class ShardingConfig {\n    \n    private static final int SHARD_COUNT = 4;\n    \n    @Bean\n    public DataSource shard0() {\n        return createDataSource(\"shard0\");\n    }\n    \n    @Bean\n    public DataSource shard1() {\n        return createDataSource(\"shard1\");\n    }\n    \n    @Bean\n    public DataSource shard2() {\n        return createDataSource(\"shard2\");\n    }\n    \n    @Bean\n    public DataSource shard3() {\n        return createDataSource(\"shard3\");\n    }\n    \n    @Bean\n    @Primary\n    public DataSource shardedDataSource() {\n        ShardedDataSource dataSource = new ShardedDataSource();\n        \n        Map<Object, Object> shards = new HashMap<>();\n        shards.put(0, shard0());\n        shards.put(1, shard1());\n        shards.put(2, shard2());\n        shards.put(3, shard3());\n        \n        dataSource.setTargetDataSources(shards);\n        dataSource.setDefaultTargetDataSource(shard0());\n        dataSource.afterPropertiesSet();\n        \n        return dataSource;\n    }\n}\n\npublic class ShardedDataSource extends AbstractRoutingDataSource {\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return ShardContext.getCurrentShard();\n    }\n}\n\npublic class ShardContext {\n    private static final ThreadLocal<Integer> currentShard = \n        new ThreadLocal<>();\n    \n    public static void setCurrentShard(Integer shardId) {\n        currentShard.set(shardId);\n    }\n    \n    public static Integer getCurrentShard() {\n        return currentShard.get();\n    }\n    \n    public static void clear() {\n        currentShard.remove();\n    }\n}\n\n// 2. Shard resolver\n@Component\npublic class ShardResolver {\n    \n    private static final int SHARD_COUNT = 4;\n    \n    public int getShardForUser(Long userId) {\n        // Hash-based sharding\n        return Math.abs(userId.hashCode() % SHARD_COUNT);\n    }\n    \n    public int getShardForTenant(String tenantId) {\n        // Consistent hashing\n        return Math.abs(tenantId.hashCode() % SHARD_COUNT);\n    }\n    \n    public int getShardForTime(LocalDate date) {\n        // Time-based sharding (by year)\n        int year = date.getYear();\n        return year % SHARD_COUNT;\n    }\n}\n\n// 3. Sharded repository\n@Service\npublic class ShardedUserService {\n    \n    @Autowired\n    private ShardResolver shardResolver;\n    \n    @Autowired\n    private UserRepository userRepository;\n    \n    public User findUser(Long userId) {\n        int shardId = shardResolver.getShardForUser(userId);\n        \n        try {\n            ShardContext.setCurrentShard(shardId);\n            return userRepository.findById(userId).orElse(null);\n        } finally {\n            ShardContext.clear();\n        }\n    }\n    \n    @Transactional\n    public User createUser(User user) {\n        int shardId = shardResolver.getShardForUser(user.getId());\n        \n        try {\n            ShardContext.setCurrentShard(shardId);\n            return userRepository.save(user);\n        } finally {\n            ShardContext.clear();\n        }\n    }\n    \n    // Cross-shard query (fan-out)\n    public List<User> findUsersByEmail(String email) {\n        List<User> allUsers = new ArrayList<>();\n        \n        // Query all shards in parallel\n        List<CompletableFuture<List<User>>> futures = new ArrayList<>();\n        \n        for (int shardId = 0; shardId < 4; shardId++) {\n            final int shard = shardId;\n            \n            CompletableFuture<List<User>> future = CompletableFuture\n                .supplyAsync(() -> {\n                    try {\n                        ShardContext.setCurrentShard(shard);\n                        return userRepository.findByEmail(email);\n                    } finally {\n                        ShardContext.clear();\n                    }\n                });\n            \n            futures.add(future);\n        }\n        \n        // Collect results from all shards\n        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))\n            .join();\n        \n        futures.forEach(f -> {\n            try {\n                allUsers.addAll(f.get());\n            } catch (Exception e) {\n                logger.error(\"Error querying shard\", e);\n            }\n        });\n        \n        return allUsers;\n    }\n}\n\n// 4. Tenant-based sharding\n@Entity\npublic class Order {\n    @Id\n    private Long id;\n    \n    @Column(name = \"tenant_id\", nullable = false)\n    private String tenantId; // Shard key\n    \n    private String orderNumber;\n    private BigDecimal total;\n}\n\n@Aspect\n@Component\npublic class TenantShardingAspect {\n    \n    @Autowired\n    private ShardResolver shardResolver;\n    \n    @Around(\"@annotation(org.springframework.transaction.annotation.Transactional)\")\n    public Object routeToShard(ProceedingJoinPoint joinPoint) throws Throwable {\n        \n        // Extract tenant from security context or method args\n        String tenantId = getCurrentTenantId();\n        \n        if (tenantId != null) {\n            int shardId = shardResolver.getShardForTenant(tenantId);\n            ShardContext.setCurrentShard(shardId);\n        }\n        \n        try {\n            return joinPoint.proceed();\n        } finally {\n            ShardContext.clear();\n        }\n    }\n}\n\n// 5. Shard rebalancing\n@Service\npublic class ShardRebalancingService {\n    \n    @Transactional\n    public void rebalanceUser(Long userId, int targetShard) {\n        int currentShard = shardResolver.getShardForUser(userId);\n        \n        if (currentShard == targetShard) {\n            return; // Already on target shard\n        }\n        \n        logger.info(\"Rebalancing user {} from shard {} to {}\",\n            userId, currentShard, targetShard);\n        \n        try {\n            // 1. Read from current shard\n            ShardContext.setCurrentShard(currentShard);\n            User user = userRepository.findById(userId).orElseThrow();\n            List<Order> orders = orderRepository.findByUserId(userId);\n            \n            // 2. Write to target shard\n            ShardContext.setCurrentShard(targetShard);\n            userRepository.save(user);\n            orderRepository.saveAll(orders);\n            \n            // 3. Delete from current shard\n            ShardContext.setCurrentShard(currentShard);\n            orderRepository.deleteAll(orders);\n            userRepository.delete(user);\n            \n            logger.info(\"Rebalancing completed for user {}\", userId);\n            \n        } finally {\n            ShardContext.clear();\n        }\n    }\n}\n\n// 6. Shard monitoring\n@Component\npublic class ShardMonitoringService {\n    \n    @Scheduled(fixedRate = 300000) // Every 5 minutes\n    public void monitorShardDistribution() {\n        Map<Integer, Long> distribution = new HashMap<>();\n        \n        for (int shardId = 0; shardId < 4; shardId++) {\n            try {\n                ShardContext.setCurrentShard(shardId);\n                long count = userRepository.count();\n                distribution.put(shardId, count);\n            } finally {\n                ShardContext.clear();\n            }\n        }\n        \n        logger.info(\"Shard distribution: {}\", distribution);\n        \n        // Check for imbalance\n        long max = Collections.max(distribution.values());\n        long min = Collections.min(distribution.values());\n        \n        if (max > min * 1.5) {\n            logger.warn(\"Shard imbalance detected: max={}, min={}\", \n                max, min);\n        }\n    }\n}"
    },
    {
      "id": 95,
      "question": "What are the best practices and common pitfalls in JPA?",
      "answer": "Summary of JPA best practices and things to avoid:\n\nBest Practices:\n• Use projections for read-only queries\n• Implement proper equals()/hashCode()\n• Use batch operations for bulk processing\n• Enable query logging in development\n• Index foreign keys\n• Use @Transactional appropriately\n• Implement auditing\n• Use connection pooling (HikariCP)\n\nCommon Pitfalls:\n• N+1 query problem\n• Missing @Transactional\n• Cartesian product with multiple joins\n• Large batch operations without flush/clear\n• Forgetting to close EntityManager\n• Using equals() on unmanaged entities\n• Bi-directional relationships without proper management",
      "explanation": "Following JPA best practices and avoiding common pitfalls ensures optimal performance, maintainability, and data consistency in production applications.",
      "difficulty": "Medium",
      "code": "// âœ… BEST PRACTICES\n\n// 1. Proper entity design\n@Entity\n@Table(name = \"users\", indexes = {\n    @Index(name = \"idx_email\", columnList = \"email\"),\n    @Index(name = \"idx_username\", columnList = \"username\")\n})\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    \n    @Column(unique = true, nullable = false)\n    private String email;\n    \n    @Version // Optimistic locking\n    private Long version;\n    \n    // Proper equals/hashCode\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (!(o instanceof User)) return false;\n        User user = (User) o;\n        return id != null && id.equals(user.id);\n    }\n    \n    @Override\n    public int hashCode() {\n        return getClass().hashCode();\n    }\n}\n\n// 2. Use projections\npublic interface UserSummary {\n    Long getId();\n    String getUsername();\n}\n\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    // âœ… GOOD: Only fetch needed fields\n    List<UserSummary> findAllProjectedBy();\n    \n    // âŒ BAD: Fetch entire entity\n    // List<User> findAll();\n}\n\n// 3. Prevent N+1 with JOIN FETCH\n@Repository\npublic interface OrderRepository extends JpaRepository<Order, Long> {\n    \n    // âœ… GOOD: Single query with JOIN FETCH\n    @Query(\"SELECT o FROM Order o \" +\n           \"JOIN FETCH o.items \" +\n           \"JOIN FETCH o.customer \" +\n           \"WHERE o.id = :id\")\n    Optional<Order> findByIdWithDetails(@Param(\"id\") Long id);\n    \n    // âŒ BAD: Causes N+1 queries\n    // Optional<Order> findById(Long id);\n    // Then accessing o.getItems() triggers N queries\n}\n\n// 4. Batch operations properly\n@Service\npublic class BulkOperationService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    // âœ… GOOD: Batch with flush/clear\n    @Transactional\n    public void batchInsertOptimized(List<Product> products) {\n        int batchSize = 50;\n        \n        for (int i = 0; i < products.size(); i++) {\n            entityManager.persist(products.get(i));\n            \n            if (i % batchSize == 0 && i > 0) {\n                entityManager.flush();\n                entityManager.clear(); // Clear persistence context\n            }\n        }\n    }\n    \n    // âŒ BAD: No flush/clear, memory issues\n    // @Transactional\n    // public void batchInsertBad(List<Product> products) {\n    //     products.forEach(entityManager::persist);\n    // }\n}\n\n// 5. Proper transaction management\n@Service\npublic class OrderService {\n    \n    // âœ… GOOD: Single transaction for entire operation\n    @Transactional\n    public Order createOrder(OrderRequest request) {\n        Order order = new Order();\n        order.setCustomerId(request.getCustomerId());\n        \n        List<OrderItem> items = createOrderItems(request.getItems());\n        order.setItems(items);\n        \n        return orderRepository.save(order);\n    }\n    \n    // âŒ BAD: Missing @Transactional\n    // public Order createOrderBad(OrderRequest request) {\n    //     // Each repository call is separate transaction\n    //     // Partial failure possible\n    // }\n}\n\n// âŒ COMMON PITFALLS\n\n// Pitfall 1: Cartesian product\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    \n    // âŒ BAD: Creates cartesian product\n    // @Query(\"SELECT u FROM User u \" +\n    //        \"JOIN FETCH u.orders \" +\n    //        \"JOIN FETCH u.addresses\")\n    // List<User> findAllWithDetails();\n    \n    // âœ… FIX: Use separate queries or @EntityGraph\n    @EntityGraph(attributePaths = {\"orders\", \"addresses\"})\n    List<User> findAll();\n}\n\n// Pitfall 2: Lazy loading outside transaction\n@RestController\npublic class UserController {\n    \n    // âŒ BAD: Lazy loading fails\n    // @GetMapping(\"/users/{id}\")\n    // public UserDTO getUser(@PathVariable Long id) {\n    //     User user = userRepository.findById(id).orElseThrow();\n    //     // LazyInitializationException when accessing orders\n    //     return new UserDTO(user, user.getOrders());\n    // }\n    \n    // âœ… FIX: Fetch eagerly or use @Transactional\n    @GetMapping(\"/users/{id}\")\n    @Transactional(readOnly = true)\n    public UserDTO getUser(@PathVariable Long id) {\n        User user = userRepository.findById(id).orElseThrow();\n        Hibernate.initialize(user.getOrders());\n        return new UserDTO(user, user.getOrders());\n    }\n}\n\n// Pitfall 3: Bi-directional relationship mismanagement\n@Entity\npublic class Order {\n    @OneToMany(mappedBy = \"order\", cascade = CascadeType.ALL)\n    private List<OrderItem> items = new ArrayList<>();\n    \n    // âœ… GOOD: Helper method maintains both sides\n    public void addItem(OrderItem item) {\n        items.add(item);\n        item.setOrder(this);\n    }\n    \n    public void removeItem(OrderItem item) {\n        items.remove(item);\n        item.setOrder(null);\n    }\n}\n\n// âŒ Pitfall 4: Not closing EntityManager\npublic class ManualEntityManagerBad {\n    // âŒ BAD: EntityManager not closed\n    // public void doSomething() {\n    //     EntityManager em = emf.createEntityManager();\n    //     em.getTransaction().begin();\n    //     // ... operations\n    //     em.getTransaction().commit();\n    //     // MISSING: em.close();\n    // }\n    \n    // âœ… GOOD: Use try-with-resources\n    public void doSomethingGood() {\n        try (EntityManager em = emf.createEntityManager()) {\n            em.getTransaction().begin();\n            // ... operations\n            em.getTransaction().commit();\n        } // Auto-closed\n    }\n}\n\n// Pitfall 5: Inefficient pagination\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    // âŒ BAD: Loads all, then pages in memory\n    // List<Product> findByCategory(String category);\n    \n    // âœ… GOOD: Database-level pagination\n    Page<Product> findByCategory(\n        String category,\n        Pageable pageable\n    );\n}\n\n// PRODUCTION CHECKLIST\n@Configuration\npublic class ProductionJPAConfiguration {\n    \n    // âœ… Production settings\n    /*\n    spring.jpa.hibernate.ddl-auto=validate\n    spring.jpa.show-sql=false\n    spring.jpa.properties.hibernate.format_sql=false\n    \n    # Connection Pool\n    spring.datasource.hikari.maximum-pool-size=10\n    spring.datasource.hikari.minimum-idle=5\n    spring.datasource.hikari.connection-timeout=30000\n    \n    # Batch\n    spring.jpa.properties.hibernate.jdbc.batch_size=50\n    spring.jpa.properties.hibernate.order_inserts=true\n    spring.jpa.properties.hibernate.order_updates=true\n    \n    # Cache\n    spring.jpa.properties.hibernate.cache.use_second_level_cache=true\n    spring.jpa.properties.hibernate.cache.region.factory_class=org.hibernate.cache.jcache.JCacheRegionFactory\n    \n    # Statistics (monitoring)\n    spring.jpa.properties.hibernate.generate_statistics=true\n    */\n}"
    },
    {
      "id": 96,
      "question": "How do you troubleshoot common JPA performance issues?",
      "answer": "Systematic approach to identify and fix JPA performance problems:\n\nDiagnostic Steps:\n1. Enable SQL logging\n2. Analyze query patterns\n3. Check connection pool usage\n4. Monitor cache hit rates\n5. Profile slow queries\n\nCommon Issues:\n• N+1 queries â†’ Use JOIN FETCH\n• Slow queries â†’ Add indexes\n• Connection exhaustion â†’ Tune pool\n• Memory leaks â†’ Clear EntityManager\n• Cartesian products â†’ Split queries\n\nTools:\n• Hibernate statistics\n• Database query logs\n• APM tools\n• EXPLAIN ANALYZE",
      "explanation": "Effective troubleshooting combines logging, monitoring, and systematic analysis to identify root causes of JPA performance issues.",
      "difficulty": "Hard",
      "code": "// 1. Enable comprehensive logging\n# application.properties\nlogging.level.org.hibernate.SQL=DEBUG\nlogging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE\nlogging.level.org.hibernate.stat=DEBUG\n\nspring.jpa.show-sql=true\nspring.jpa.properties.hibernate.format_sql=true\nspring.jpa.properties.hibernate.use_sql_comments=true\nspring.jpa.properties.hibernate.generate_statistics=true\n\n// 2. Performance monitoring interceptor\n@Component\npublic class PerformanceMonitoringInterceptor extends EmptyInterceptor {\n    \n    private static final long SLOW_QUERY_THRESHOLD = 100; // ms\n    private ThreadLocal<Long> queryStartTime = new ThreadLocal<>();\n    \n    @Override\n    public String onPrepareStatement(String sql) {\n        queryStartTime.set(System.currentTimeMillis());\n        return super.onPrepareStatement(sql);\n    }\n    \n    @Override\n    public void afterTransactionCompletion(Transaction tx) {\n        Long start = queryStartTime.get();\n        if (start != null) {\n            long duration = System.currentTimeMillis() - start;\n            \n            if (duration > SLOW_QUERY_THRESHOLD) {\n                logger.warn(\n                    \"Slow query detected: {}ms\\nSQL: {}\",\n                    duration,\n                    getCurrentSQL()\n                );\n            }\n            \n            queryStartTime.remove();\n        }\n    }\n}\n\n// 3. Diagnostic service\n@Service\npublic class JPADiagnosticService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public DiagnosticReport generateReport() {\n        DiagnosticReport report = new DiagnosticReport();\n        \n        // 1. Check Hibernate statistics\n        Statistics stats = getHibernateStatistics();\n        report.setQueryCount(stats.getQueryExecutionCount());\n        report.setSlowestQuery(stats.getQueryExecutionMaxTimeQueryString());\n        report.setSlowestQueryTime(stats.getQueryExecutionMaxTime());\n        \n        // 2. Cache statistics\n        report.setCacheHitRate(\n            calculateCacheHitRate(stats)\n        );\n        \n        // 3. Connection pool status\n        if (dataSource instanceof HikariDataSource) {\n            HikariDataSource hikari = (HikariDataSource) dataSource;\n            HikariPoolMXBean pool = hikari.getHikariPoolMXBean();\n            \n            report.setActiveConnections(pool.getActiveConnections());\n            report.setIdleConnections(pool.getIdleConnections());\n            report.setWaitingThreads(pool.getThreadsAwaitingConnection());\n        }\n        \n        // 4. Entity statistics\n        report.setEntityLoadCount(stats.getEntityLoadCount());\n        report.setEntityInsertCount(stats.getEntityInsertCount());\n        report.setEntityUpdateCount(stats.getEntityUpdateCount());\n        report.setEntityDeleteCount(stats.getEntityDeleteCount());\n        \n        // 5. Session statistics\n        report.setSessionOpenCount(stats.getSessionOpenCount());\n        report.setSessionCloseCount(stats.getSessionCloseCount());\n        report.setFlushCount(stats.getFlushCount());\n        \n        return report;\n    }\n    \n    public List<SlowQuery> findSlowQueries() {\n        Statistics stats = getHibernateStatistics();\n        String[] queryStrings = stats.getQueries();\n        \n        List<SlowQuery> slowQueries = new ArrayList<>();\n        \n        for (String query : queryStrings) {\n            QueryStatistics queryStats = stats.getQueryStatistics(query);\n            \n            if (queryStats.getExecutionAvgTime() > 100) {\n                SlowQuery sq = new SlowQuery();\n                sq.setQuery(query);\n                sq.setAvgTime(queryStats.getExecutionAvgTime());\n                sq.setMaxTime(queryStats.getExecutionMaxTime());\n                sq.setExecutionCount(queryStats.getExecutionCount());\n                \n                slowQueries.add(sq);\n            }\n        }\n        \n        return slowQueries.stream()\n            .sorted(Comparator.comparing(SlowQuery::getAvgTime).reversed())\n            .collect(Collectors.toList());\n    }\n}\n\n// 4. N+1 detector\n@Aspect\n@Component\npublic class NPlusOneDetector {\n    \n    private ThreadLocal<Set<String>> queriesInTransaction = \n        ThreadLocal.withInitial(HashSet::new);\n    \n    @Before(\"@annotation(org.springframework.transaction.annotation.Transactional)\")\n    public void beforeTransaction() {\n        queriesInTransaction.get().clear();\n    }\n    \n    @AfterReturning(\"@annotation(org.springframework.transaction.annotation.Transactional)\")\n    public void afterTransaction() {\n        Set<String> queries = queriesInTransaction.get();\n        \n        // Detect similar queries (potential N+1)\n        Map<String, Long> queryPatterns = queries.stream()\n            .map(this::normalizeQuery)\n            .collect(Collectors.groupingBy(\n                Function.identity(),\n                Collectors.counting()\n            ));\n        \n        queryPatterns.forEach((pattern, count) -> {\n            if (count > 10) {\n                logger.warn(\n                    \"Potential N+1 detected: {} similar queries executed\\nPattern: {}\",\n                    count,\n                    pattern\n                );\n            }\n        });\n        \n        queriesInTransaction.remove();\n    }\n    \n    private String normalizeQuery(String sql) {\n        // Remove parameter values to group similar queries\n        return sql.replaceAll(\"= \\\\d+\", \"= ?\");\n    }\n}\n\n// 5. Query plan analyzer\n@Service\npublic class QueryPlanAnalyzer {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public QueryPlan analyzeQuery(String jpql) {\n        // Convert JPQL to SQL\n        Query query = entityManager.createQuery(jpql);\n        String sql = query.unwrap(org.hibernate.query.Query.class)\n            .getQueryString();\n        \n        // Get PostgreSQL query plan\n        String explainSql = \"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) \" + sql;\n        \n        String planJson = (String) entityManager\n            .createNativeQuery(explainSql)\n            .getSingleResult();\n        \n        return parseQueryPlan(planJson);\n    }\n    \n    private QueryPlan parseQueryPlan(String json) {\n        QueryPlan plan = new QueryPlan();\n        \n        // Parse JSON plan\n        // Check for issues:\n        if (json.contains(\"Seq Scan\")) {\n            plan.addWarning(\"Sequential scan detected - missing index?\");\n        }\n        \n        if (json.contains(\"Nested Loop\")) {\n            plan.addWarning(\"Nested loop join - consider JOIN FETCH\");\n        }\n        \n        // Extract cost\n        Matcher costMatcher = Pattern\n            .compile(\"\\\"Total Cost\\\":(\\\\d+\\\\.\\\\d+)\")\n            .matcher(json);\n        if (costMatcher.find()) {\n            plan.setCost(Double.parseDouble(costMatcher.group(1)));\n        }\n        \n        return plan;\n    }\n}\n\n// 6. Memory leak detector\n@Component\npublic class EntityManagerLeakDetector {\n    \n    private final Map<Long, StackTraceElement[]> openEntityManagers = \n        new ConcurrentHashMap<>();\n    \n    @Around(\"execution(* javax.persistence.EntityManagerFactory.createEntityManager(..))\")\n    public Object trackEntityManager(ProceedingJoinPoint pjp) throws Throwable {\n        EntityManager em = (EntityManager) pjp.proceed();\n        \n        long emId = System.identityHashCode(em);\n        openEntityManagers.put(\n            emId,\n            Thread.currentThread().getStackTrace()\n        );\n        \n        // Wrap to track close\n        return Proxy.newProxyInstance(\n            em.getClass().getClassLoader(),\n            new Class<?>[]{EntityManager.class},\n            (proxy, method, args) -> {\n                if (\"close\".equals(method.getName())) {\n                    openEntityManagers.remove(emId);\n                }\n                return method.invoke(em, args);\n            }\n        );\n    }\n    \n    @Scheduled(fixedRate = 60000)\n    public void checkForLeaks() {\n        if (openEntityManagers.size() > 10) {\n            logger.error(\n                \"Potential EntityManager leak: {} unclosed instances\",\n                openEntityManagers.size()\n            );\n            \n            openEntityManagers.forEach((id, stackTrace) -> {\n                logger.error(\n                    \"Unclosed EntityManager {} created at:\",\n                    id\n                );\n                Arrays.stream(stackTrace)\n                    .limit(10)\n                    .forEach(e -> logger.error(\"  {}\", e));\n            });\n        }\n    }\n}\n\n// 7. Auto-tuning suggestions\n@Service\npublic class AutoTuningService {\n    \n    public List<TuningSuggestion> generateSuggestions() {\n        List<TuningSuggestion> suggestions = new ArrayList<>();\n        Statistics stats = getHibernateStatistics();\n        \n        // Check cache hit rate\n        double cacheHitRate = calculateCacheHitRate(stats);\n        if (cacheHitRate < 0.7) {\n            suggestions.add(new TuningSuggestion(\n                \"LOW_CACHE_HIT_RATE\",\n                \"Cache hit rate is \" + cacheHitRate + \n                \". Consider enabling second-level cache.\",\n                \"HIGH\"\n            ));\n        }\n        \n        // Check query count\n        long queryCount = stats.getQueryExecutionCount();\n        long entityLoadCount = stats.getEntityLoadCount();\n        if (queryCount > entityLoadCount * 2) {\n            suggestions.add(new TuningSuggestion(\n                \"EXCESSIVE_QUERIES\",\n                \"High query-to-entity ratio. Possible N+1 problem.\",\n                \"HIGH\"\n            ));\n        }\n        \n        // Check connection pool\n        if (dataSource instanceof HikariDataSource) {\n            HikariPoolMXBean pool = \n                ((HikariDataSource) dataSource).getHikariPoolMXBean();\n            \n            if (pool.getThreadsAwaitingConnection() > 0) {\n                suggestions.add(new TuningSuggestion(\n                    \"CONNECTION_POOL_EXHAUSTION\",\n                    \"Threads waiting for connections. Increase pool size.\",\n                    \"CRITICAL\"\n                ));\n            }\n        }\n        \n        return suggestions;\n    }\n}"
    },
    {
      "id": 97,
      "question": "How do you implement database versioning and schema evolution in JPA?",
      "answer": "Schema evolution manages database changes over time:\n\nStrategies:\n• Expand-Contract: Add new, migrate, remove old\n• Blue-Green: Parallel schemas\n• Backward compatible: Non-breaking changes\n• Breaking changes: Coordinated deployment\n\nTools:\n• Flyway/Liquibase migrations\n• Version control for DDL\n• Rollback scripts\n• Testing migrations\n\nTechniques:\n• Add columns with defaults\n• Nullable before required\n• Dual-write during transition\n• Gradual rollout",
      "explanation": "Schema evolution enables safe database changes in production through versioned migrations, backward compatibility, and coordinated rollout strategies.",
      "difficulty": "Hard",
      "code": "// 1. Expand-Contract pattern\n// Phase 1: EXPAND - Add new column\n-- V1__add_email_verified.sql\nALTER TABLE users \nADD COLUMN email_verified BOOLEAN DEFAULT false;\n\nUPDATE users SET email_verified = false;\n\n// Entity supports both states\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String email;\n    \n    // New field, nullable during transition\n    @Column(name = \"email_verified\")\n    private Boolean emailVerified = false;\n}\n\n// Phase 2: CONTRACT - Migrate data, make required\n-- V2__make_email_verified_required.sql\n-- Ensure all data is migrated\nUPDATE users SET email_verified = false WHERE email_verified IS NULL;\n\n-- Now make it NOT NULL\nALTER TABLE users ALTER COLUMN email_verified SET NOT NULL;\n\n// Update entity\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    private String email;\n    \n    @Column(name = \"email_verified\", nullable = false)\n    private Boolean emailVerified = false;\n}\n\n// 2. Backward compatible column rename\n// Step 1: Add new column\n-- V1__add_full_name.sql\nALTER TABLE users ADD COLUMN full_name VARCHAR(255);\n\nUPDATE users SET full_name = CONCAT(first_name, ' ', last_name);\n\n// Step 2: Dual-write to both columns\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    // Keep old columns during transition\n    @Column(name = \"first_name\")\n    private String firstName;\n    \n    @Column(name = \"last_name\")\n    private String lastName;\n    \n    // New column\n    @Column(name = \"full_name\")\n    private String fullName;\n    \n    public void setFirstName(String firstName) {\n        this.firstName = firstName;\n        updateFullName();\n    }\n    \n    public void setLastName(String lastName) {\n        this.lastName = lastName;\n        updateFullName();\n    }\n    \n    private void updateFullName() {\n        if (firstName != null && lastName != null) {\n            this.fullName = firstName + \" \" + lastName;\n        }\n    }\n}\n\n// Step 3: Remove old columns (after all apps updated)\n-- V3__remove_name_columns.sql\nALTER TABLE users DROP COLUMN first_name;\nALTER TABLE users DROP COLUMN last_name;\n\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    \n    @Column(name = \"full_name\", nullable = false)\n    private String fullName;\n}\n\n// 3. Table split with data migration\n-- V1__split_user_profile.sql\nCREATE TABLE user_profiles (\n    id BIGSERIAL PRIMARY KEY,\n    user_id BIGINT NOT NULL REFERENCES users(id),\n    bio TEXT,\n    avatar_url VARCHAR(500),\n    preferences JSONB,\n    CONSTRAINT uk_user_profile_user_id UNIQUE (user_id)\n);\n\n-- Migrate existing data\nINSERT INTO user_profiles (user_id, bio, avatar_url)\nSELECT id, bio, avatar_url FROM users;\n\n// Java migration for complex logic\n@Component\npublic class V2__MigrateUserPreferences implements JavaMigration {\n    \n    @Override\n    public void migrate(Context context) throws Exception {\n        try (Statement stmt = context.getConnection().createStatement()) {\n            \n            // Read from old structure\n            ResultSet rs = stmt.executeQuery(\n                \"SELECT id, settings FROM users WHERE settings IS NOT NULL\"\n            );\n            \n            PreparedStatement updateStmt = context.getConnection()\n                .prepareStatement(\n                    \"UPDATE user_profiles SET preferences = ?::jsonb \" +\n                    \"WHERE user_id = ?\"\n                );\n            \n            while (rs.next()) {\n                long userId = rs.getLong(\"id\");\n                String oldSettings = rs.getString(\"settings\");\n                \n                // Transform to new format\n                String newPreferences = transformSettings(oldSettings);\n                \n                updateStmt.setString(1, newPreferences);\n                updateStmt.setLong(2, userId);\n                updateStmt.addBatch();\n            }\n            \n            updateStmt.executeBatch();\n        }\n    }\n    \n    private String transformSettings(String oldSettings) {\n        // Complex transformation logic\n        JSONObject old = new JSONObject(oldSettings);\n        JSONObject newFormat = new JSONObject();\n        \n        // Map old structure to new\n        newFormat.put(\"theme\", old.optString(\"ui_theme\", \"light\"));\n        newFormat.put(\"locale\", old.optString(\"language\", \"en\"));\n        \n        return newFormat.toString();\n    }\n}\n\n// 4. Zero-downtime deployment\n@Service\npublic class VersionedDataService {\n    \n    @Value(\"${schema.version}\")\n    private int schemaVersion;\n    \n    public User saveUser(User user) {\n        if (schemaVersion >= 2) {\n            // Use new schema\n            return saveUserV2(user);\n        } else {\n            // Use old schema\n            return saveUserV1(user);\n        }\n    }\n    \n    private User saveUserV1(User user) {\n        // Write to old columns\n        user.setFirstName(extractFirstName(user.getFullName()));\n        user.setLastName(extractLastName(user.getFullName()));\n        return userRepository.save(user);\n    }\n    \n    private User saveUserV2(User user) {\n        // Write only to new column\n        user.setFullName(user.getFullName());\n        return userRepository.save(user);\n    }\n}\n\n// 5. Migration testing\n@SpringBootTest\nclass MigrationTest {\n    \n    @Autowired\n    private Flyway flyway;\n    \n    @Test\n    void testMigrationForward() {\n        // Clean database\n        flyway.clean();\n        \n        // Get all migrations\n        MigrationInfo[] migrations = flyway.info().all();\n        \n        // Apply migrations one by one\n        for (MigrationInfo migration : migrations) {\n            flyway.migrate();\n            \n            // Verify database state after each migration\n            verifySchemaState(migration.getVersion());\n        }\n    }\n    \n    @Test\n    void testMigrationRollback() {\n        // Apply all migrations\n        flyway.migrate();\n        \n        // Test rollback scripts\n        for (int version = getCurrentVersion(); version > 0; version--) {\n            rollbackToVersion(version - 1);\n            verifySchemaState(version - 1);\n        }\n    }\n    \n    private void verifySchemaState(MigrationVersion version) {\n        // Verify tables exist\n        // Verify columns\n        // Verify constraints\n        // Verify indexes\n    }\n}\n\n// 6. Feature flags for schema changes\n@Service\npublic class FeatureFlagService {\n    \n    public boolean isNewSchemaEnabled() {\n        return featureToggle.isEnabled(\"new_user_schema\");\n    }\n}\n\n@Service\npublic class UserService {\n    \n    @Autowired\n    private FeatureFlagService featureFlags;\n    \n    public User getUser(Long id) {\n        if (featureFlags.isNewSchemaEnabled()) {\n            // Read from new schema\n            return userRepositoryV2.findById(id).orElseThrow();\n        } else {\n            // Read from old schema\n            return userRepositoryV1.findById(id).orElseThrow();\n        }\n    }\n}"
    },
    {
      "id": 98,
      "question": "How do you implement multi-tenancy patterns in JPA?",
      "answer": "Multi-tenancy isolates data between customers/tenants:\n\nPatterns:\n1. Separate Database: Complete isolation\n2. Separate Schema: Shared DB, separate schemas\n3. Shared Schema: Discriminator column\n\nImplementation:\n• AbstractRoutingDataSource\n• Hibernate MultiTenantConnectionProvider\n• @Filter for row-level filtering\n• Tenant context\n\nTrade-offs:\n• Separate DB: Max isolation, complex\n• Separate Schema: Good balance\n• Shared: Simple, less isolation",
      "explanation": "Multi-tenancy patterns enable SaaS applications to serve multiple customers with appropriate data isolation, scalability, and cost efficiency.",
      "difficulty": "Hard",
      "code": "// 1. Shared schema with discriminator (simplest)\n@Entity\n@Table(name = \"orders\")\n@FilterDef(\n    name = \"tenantFilter\",\n    parameters = @ParamDef(name = \"tenantId\", type = \"string\")\n)\n@Filter(\n    name = \"tenantFilter\",\n    condition = \"tenant_id = :tenantId\"\n)\npublic class Order {\n    @Id\n    private Long id;\n    \n    @Column(name = \"tenant_id\", nullable = false, updatable = false)\n    private String tenantId;\n    \n    private String orderNumber;\n    private BigDecimal total;\n}\n\n// Tenant context\npublic class TenantContext {\n    private static final ThreadLocal<String> currentTenant = \n        new ThreadLocal<>();\n    \n    public static void setCurrentTenant(String tenantId) {\n        currentTenant.set(tenantId);\n    }\n    \n    public static String getCurrentTenant() {\n        return currentTenant.get();\n    }\n    \n    public static void clear() {\n        currentTenant.remove();\n    }\n}\n\n// Interceptor to set tenant\n@Component\npublic class TenantInterceptor implements HandlerInterceptor {\n    \n    @Override\n    public boolean preHandle(\n            HttpServletRequest request,\n            HttpServletResponse response,\n            Object handler) {\n        \n        // Extract tenant from header or JWT\n        String tenantId = request.getHeader(\"X-Tenant-ID\");\n        \n        if (tenantId == null) {\n            // Extract from JWT token\n            tenantId = extractTenantFromToken(request);\n        }\n        \n        if (tenantId == null) {\n            response.setStatus(HttpStatus.BAD_REQUEST.value());\n            return false;\n        }\n        \n        TenantContext.setCurrentTenant(tenantId);\n        return true;\n    }\n    \n    @Override\n    public void afterCompletion(\n            HttpServletRequest request,\n            HttpServletResponse response,\n            Object handler,\n            Exception ex) {\n        TenantContext.clear();\n    }\n}\n\n// Entity listener to auto-set tenant\n@Component\npublic class TenantEntityListener {\n    \n    @PrePersist\n    @PreUpdate\n    public void setTenant(Object entity) {\n        if (entity instanceof TenantAware) {\n            TenantAware tenantAware = (TenantAware) entity;\n            \n            if (tenantAware.getTenantId() == null) {\n                String tenantId = TenantContext.getCurrentTenant();\n                tenantAware.setTenantId(tenantId);\n            }\n        }\n    }\n}\n\n// Enable filter in repository\n@Aspect\n@Component\npublic class TenantFilterAspect {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Before(\"execution(* org.springframework.data.repository.Repository+.*(..))\")\n    public void enableTenantFilter() {\n        String tenantId = TenantContext.getCurrentTenant();\n        \n        if (tenantId != null) {\n            Session session = entityManager.unwrap(Session.class);\n            Filter filter = session.enableFilter(\"tenantFilter\");\n            filter.setParameter(\"tenantId\", tenantId);\n        }\n    }\n}\n\n// 2. Separate schema per tenant\n@Configuration\npublic class MultiTenantConfiguration {\n    \n    @Bean\n    public DataSource dataSource() {\n        // Single database, multiple schemas\n        return DataSourceBuilder.create()\n            .url(\"jdbc:postgresql://localhost:5432/saas_db\")\n            .build();\n    }\n    \n    @Bean\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory(\n            DataSource dataSource) {\n        \n        LocalContainerEntityManagerFactoryBean emf = \n            new LocalContainerEntityManagerFactoryBean();\n        \n        emf.setDataSource(dataSource);\n        emf.setPackagesToScan(\"com.example.entities\");\n        \n        JpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter();\n        emf.setJpaVendorAdapter(vendorAdapter);\n        \n        Map<String, Object> properties = new HashMap<>();\n        properties.put(\n            \"hibernate.multiTenancy\",\n            MultiTenancyStrategy.SCHEMA\n        );\n        properties.put(\n            \"hibernate.multi_tenant_connection_provider\",\n            multiTenantConnectionProvider()\n        );\n        properties.put(\n            \"hibernate.tenant_identifier_resolver\",\n            tenantIdentifierResolver()\n        );\n        \n        emf.setJpaPropertyMap(properties);\n        return emf;\n    }\n}\n\npublic class SchemaMultiTenantConnectionProvider \n        implements MultiTenantConnectionProvider {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Override\n    public Connection getAnyConnection() throws SQLException {\n        return dataSource.getConnection();\n    }\n    \n    @Override\n    public Connection getConnection(String tenantIdentifier) \n            throws SQLException {\n        \n        Connection connection = getAnyConnection();\n        \n        // Set schema for this connection\n        connection.createStatement()\n            .execute(\"SET search_path TO \" + tenantIdentifier);\n        \n        return connection;\n    }\n    \n    @Override\n    public void releaseAnyConnection(Connection connection) \n            throws SQLException {\n        connection.close();\n    }\n    \n    @Override\n    public void releaseConnection(String tenantIdentifier, Connection connection)\n            throws SQLException {\n        // Reset schema\n        connection.createStatement()\n            .execute(\"SET search_path TO public\");\n        connection.close();\n    }\n}\n\npublic class TenantIdentifierResolver \n        implements CurrentTenantIdentifierResolver {\n    \n    @Override\n    public String resolveCurrentTenantIdentifier() {\n        String tenant = TenantContext.getCurrentTenant();\n        return tenant != null ? tenant : \"public\";\n    }\n    \n    @Override\n    public boolean validateExistingCurrentSessions() {\n        return true;\n    }\n}\n\n// 3. Separate database per tenant\n@Configuration\npublic class DatabasePerTenantConfiguration {\n    \n    @Bean\n    public DataSource routingDataSource() {\n        return new TenantRoutingDataSource();\n    }\n}\n\npublic class TenantRoutingDataSource extends AbstractRoutingDataSource {\n    \n    @Override\n    protected Object determineCurrentLookupKey() {\n        return TenantContext.getCurrentTenant();\n    }\n}\n\n@Service\npublic class TenantDataSourceService {\n    \n    private final Map<String, DataSource> dataSources = \n        new ConcurrentHashMap<>();\n    \n    public DataSource getDataSource(String tenantId) {\n        return dataSources.computeIfAbsent(tenantId, this::createDataSource);\n    }\n    \n    private DataSource createDataSource(String tenantId) {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(\n            \"jdbc:postgresql://localhost:5432/tenant_\" + tenantId\n        );\n        config.setUsername(\"app_user\");\n        config.setPassword(\"password\");\n        config.setMaximumPoolSize(5);\n        \n        return new HikariDataSource(config);\n    }\n}\n\n// 4. Tenant provisioning\n@Service\npublic class TenantProvisioningService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Transactional\n    public void provisionTenant(String tenantId) {\n        // Create schema\n        entityManager.createNativeQuery(\n            \"CREATE SCHEMA IF NOT EXISTS \" + tenantId\n        ).executeUpdate();\n        \n        // Run migrations for new tenant\n        Flyway flyway = Flyway.configure()\n            .dataSource(dataSource)\n            .schemas(tenantId)\n            .locations(\"classpath:db/migration\")\n            .load();\n        \n        flyway.migrate();\n        \n        logger.info(\"Tenant provisioned: {}\", tenantId);\n    }\n    \n    @Transactional\n    public void deprovisionTenant(String tenantId) {\n        // Archive data first\n        archiveTenantData(tenantId);\n        \n        // Drop schema\n        entityManager.createNativeQuery(\n            \"DROP SCHEMA \" + tenantId + \" CASCADE\"\n        ).executeUpdate();\n        \n        logger.info(\"Tenant deprovisioned: {}\", tenantId);\n    }\n}"
    },
    {
      "id": 99,
      "question": "How do you implement database caching strategies in JPA?",
      "answer": "Caching reduces database load and improves performance:\n\nCache Levels:\n• First-level: EntityManager session cache\n• Second-level: SessionFactory cache (shared)\n• Query cache: Query result cache\n\nProviders:\n• EhCache\n• Redis\n• Hazelcast\n• Caffeine\n\nStrategies:\n• @Cacheable on entities\n• Query hints for caching\n• Cache eviction policies\n• Read-through/Write-through\n\nConsiderations:\n• Cache invalidation\n• Memory usage\n• Cache coherence\n• TTL settings",
      "explanation": "Effective caching strategies balance performance gains with consistency requirements, using appropriate cache levels and eviction policies.",
      "difficulty": "Medium",
      "code": "// 1. Enable second-level cache\n/*\n<dependency>\n    <groupId>org.hibernate</groupId>\n    <artifactId>hibernate-jcache</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.ehcache</groupId>\n    <artifactId>ehcache</artifactId>\n</dependency>\n*/\n\n// application.properties\nspring.jpa.properties.hibernate.cache.use_second_level_cache=true\nspring.jpa.properties.hibernate.cache.region.factory_class=org.hibernate.cache.jcache.JCacheRegionFactory\nspring.jpa.properties.hibernate.cache.use_query_cache=true\nspring.javax.cache.provider=org.ehcache.jsr107.EhcacheCachingProvider\n\n// 2. Cacheable entities\n@Entity\n@Cacheable\n@org.hibernate.annotations.Cache(\n    usage = CacheConcurrencyStrategy.READ_WRITE,\n    region = \"products\"\n)\npublic class Product {\n    @Id\n    private Long id;\n    \n    private String name;\n    private BigDecimal price;\n    \n    @ManyToOne\n    @org.hibernate.annotations.Cache(\n        usage = CacheConcurrencyStrategy.READ_WRITE\n    )\n    private Category category;\n    \n    @OneToMany(mappedBy = \"product\")\n    @org.hibernate.annotations.Cache(\n        usage = CacheConcurrencyStrategy.READ_WRITE\n    )\n    private List<Review> reviews;\n}\n\n// 3. EhCache configuration\n// ehcache.xml\n/*\n<config>\n    <cache alias=\"products\">\n        <key-type>java.lang.Long</key-type>\n        <value-type>com.example.entity.Product</value-type>\n        <expiry>\n            <ttl unit=\"minutes\">30</ttl>\n        </expiry>\n        <resources>\n            <heap unit=\"entries\">1000</heap>\n            <offheap unit=\"MB\">10</offheap>\n        </resources>\n    </cache>\n    \n    <cache alias=\"default-query-results-region\">\n        <expiry>\n            <ttl unit=\"minutes\">5</ttl>\n        </expiry>\n        <resources>\n            <heap unit=\"entries\">100</heap>\n        </resources>\n    </cache>\n</config>\n*/\n\n// 4. Query cache\n@Repository\npublic interface ProductRepository extends JpaRepository<Product, Long> {\n    \n    // Enable query cache for this query\n    @QueryHints({\n        @QueryHint(\n            name = \"org.hibernate.cacheable\",\n            value = \"true\"\n        ),\n        @QueryHint(\n            name = \"org.hibernate.cacheRegion\",\n            value = \"product_queries\"\n        )\n    })\n    @Query(\"SELECT p FROM Product p WHERE p.category.id = :categoryId\")\n    List<Product> findByCategoryId(@Param(\"categoryId\") Long categoryId);\n}\n\n// 5. Redis cache integration\n@Configuration\n@EnableCaching\npublic class RedisCacheConfig {\n    \n    @Bean\n    public RedisTemplate<String, Object> redisTemplate(\n            RedisConnectionFactory connectionFactory) {\n        \n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        template.setConnectionFactory(connectionFactory);\n        template.setKeySerializer(new StringRedisSerializer());\n        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());\n        return template;\n    }\n    \n    @Bean\n    public CacheManager cacheManager(\n            RedisConnectionFactory connectionFactory) {\n        \n        RedisCacheConfiguration config = RedisCacheConfiguration\n            .defaultCacheConfig()\n            .entryTtl(Duration.ofMinutes(30))\n            .serializeKeysWith(\n                RedisSerializationContext.SerializationPair\n                    .fromSerializer(new StringRedisSerializer())\n            )\n            .serializeValuesWith(\n                RedisSerializationContext.SerializationPair\n                    .fromSerializer(new GenericJackson2JsonRedisSerializer())\n            );\n        \n        return RedisCacheManager.builder(connectionFactory)\n            .cacheDefaults(config)\n            .build();\n    }\n}\n\n@Service\npublic class ProductService {\n    \n    @Cacheable(value = \"products\", key = \"#id\")\n    public Product getProduct(Long id) {\n        return productRepository.findById(id).orElseThrow();\n    }\n    \n    @CachePut(value = \"products\", key = \"#product.id\")\n    public Product updateProduct(Product product) {\n        return productRepository.save(product);\n    }\n    \n    @CacheEvict(value = \"products\", key = \"#id\")\n    public void deleteProduct(Long id) {\n        productRepository.deleteById(id);\n    }\n    \n    @CacheEvict(value = \"products\", allEntries = true)\n    public void clearCache() {\n        // Clears entire cache\n    }\n}\n\n// 6. Cache statistics\n@Service\npublic class CacheStatisticsService {\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    public CacheStatistics getStatistics() {\n        Statistics stats = entityManager\n            .getEntityManagerFactory()\n            .unwrap(SessionFactory.class)\n            .getStatistics();\n        \n        CacheStatistics cacheStats = new CacheStatistics();\n        \n        // Second-level cache stats\n        cacheStats.setSecondLevelCacheHitCount(\n            stats.getSecondLevelCacheHitCount()\n        );\n        cacheStats.setSecondLevelCacheMissCount(\n            stats.getSecondLevelCacheMissCount()\n        );\n        cacheStats.setSecondLevelCachePutCount(\n            stats.getSecondLevelCachePutCount()\n        );\n        \n        // Query cache stats\n        cacheStats.setQueryCacheHitCount(\n            stats.getQueryCacheHitCount()\n        );\n        cacheStats.setQueryCacheMissCount(\n            stats.getQueryCacheMissCount()\n        );\n        \n        // Calculate hit ratio\n        long totalHits = stats.getSecondLevelCacheHitCount() +\n                        stats.getQueryCacheHitCount();\n        long totalMisses = stats.getSecondLevelCacheMissCount() +\n                          stats.getQueryCacheMissCount();\n        \n        double hitRatio = totalHits + totalMisses > 0\n            ? (double) totalHits / (totalHits + totalMisses)\n            : 0;\n        \n        cacheStats.setHitRatio(hitRatio);\n        \n        return cacheStats;\n    }\n}\n\n// 7. Cache warming\n@Component\npublic class CacheWarmer {\n    \n    @Autowired\n    private ProductService productService;\n    \n    @EventListener(ApplicationReadyEvent.class)\n    public void warmCache() {\n        logger.info(\"Warming cache...\");\n        \n        // Load frequently accessed products\n        List<Long> popularProductIds = getPopularProductIds();\n        \n        popularProductIds.forEach(id -> {\n            try {\n                productService.getProduct(id);\n            } catch (Exception e) {\n                logger.error(\"Failed to warm cache for product {}\", id, e);\n            }\n        });\n        \n        logger.info(\"Cache warmed with {} products\", \n            popularProductIds.size());\n    }\n}"
    },
    {
      "id": 100,
      "question": "What are the key considerations for JPA in production environments?",
      "answer": "Production readiness checklist for JPA applications:\n\nPerformance:\n• Connection pooling configured\n• Indexes on foreign keys\n• Query optimization\n• Batch operations\n• Caching enabled\n\nReliability:\n• Transaction management\n• Proper error handling\n• Connection leak prevention\n• Failover strategy\n\nSecurity:\n• SQL injection prevention\n• Encrypted sensitive data\n• Audit logging\n• Least privilege DB user\n\nMonitoring:\n• Query performance metrics\n• Connection pool stats\n• Slow query alerts\n• Health checks\n\nOperations:\n• Database migrations\n• Backup strategy\n• Disaster recovery\n• Scaling plan",
      "explanation": "Production JPA applications require careful attention to performance, security, monitoring, and operational concerns to ensure reliability and maintainability.",
      "difficulty": "Hard",
      "code": "// PRODUCTION JPA CONFIGURATION\n\n// 1. application-prod.properties\n/*\n# Production JPA Settings\nspring.jpa.hibernate.ddl-auto=validate\nspring.jpa.show-sql=false\nspring.jpa.properties.hibernate.format_sql=false\nspring.jpa.open-in-view=false\n\n# Connection Pool (HikariCP)\nspring.datasource.hikari.maximum-pool-size=20\nspring.datasource.hikari.minimum-idle=5\nspring.datasource.hikari.connection-timeout=30000\nspring.datasource.hikari.idle-timeout=600000\nspring.datasource.hikari.max-lifetime=1800000\nspring.datasource.hikari.connection-test-query=SELECT 1\nspring.datasource.hikari.leak-detection-threshold=60000\n\n# Performance\nspring.jpa.properties.hibernate.jdbc.batch_size=50\nspring.jpa.properties.hibernate.order_inserts=true\nspring.jpa.properties.hibernate.order_updates=true\nspring.jpa.properties.hibernate.jdbc.batch_versioned_data=true\nspring.jpa.properties.hibernate.query.in_clause_parameter_padding=true\n\n# Caching\nspring.jpa.properties.hibernate.cache.use_second_level_cache=true\nspring.jpa.properties.hibernate.cache.region.factory_class=org.hibernate.cache.jcache.JCacheRegionFactory\nspring.jpa.properties.hibernate.cache.use_query_cache=true\n\n# Statistics (for monitoring)\nspring.jpa.properties.hibernate.generate_statistics=true\n\n# SSL Connection\nspring.datasource.url=jdbc:postgresql://db.example.com:5432/proddb?ssl=true&sslmode=require\n*/\n\n// 2. Production configuration class\n@Configuration\n@Profile(\"prod\")\npublic class ProductionJPAConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        HikariConfig config = new HikariConfig();\n        \n        // Connection settings\n        config.setJdbcUrl(env.getProperty(\"DB_URL\"));\n        config.setUsername(env.getProperty(\"DB_USER\"));\n        config.setPassword(env.getProperty(\"DB_PASSWORD\"));\n        \n        // Pool settings\n        config.setMaximumPoolSize(20);\n        config.setMinimumIdle(5);\n        config.setConnectionTimeout(30000);\n        config.setIdleTimeout(600000);\n        config.setMaxLifetime(1800000);\n        \n        // Health checks\n        config.setConnectionTestQuery(\"SELECT 1\");\n        config.setValidationTimeout(5000);\n        \n        // Leak detection\n        config.setLeakDetectionThreshold(60000);\n        \n        // Monitoring\n        config.setRegisterMbeans(true);\n        config.setHealthCheckRegistry(healthCheckRegistry);\n        config.setMetricRegistry(metricRegistry);\n        \n        return new HikariDataSource(config);\n    }\n    \n    @Bean\n    public PlatformTransactionManager transactionManager(\n            EntityManagerFactory emf) {\n        \n        JpaTransactionManager txManager = new JpaTransactionManager(emf);\n        txManager.setDefaultTimeout(30); // 30 seconds\n        return txManager;\n    }\n}\n\n// 3. Health indicators\n@Component\npublic class DatabaseHealthIndicator implements HealthIndicator {\n    \n    @Autowired\n    private DataSource dataSource;\n    \n    @Override\n    public Health health() {\n        try (Connection conn = dataSource.getConnection()) {\n            // Test query\n            long start = System.currentTimeMillis();\n            Statement stmt = conn.createStatement();\n            stmt.executeQuery(\"SELECT 1\");\n            long duration = System.currentTimeMillis() - start;\n            \n            Health.Builder builder = duration < 1000\n                ? Health.up()\n                : Health.degraded();\n            \n            // Add metrics\n            if (dataSource instanceof HikariDataSource) {\n                HikariPoolMXBean pool = \n                    ((HikariDataSource) dataSource).getHikariPoolMXBean();\n                \n                builder.withDetail(\"pool.active\", pool.getActiveConnections())\n                       .withDetail(\"pool.idle\", pool.getIdleConnections())\n                       .withDetail(\"pool.total\", pool.getTotalConnections())\n                       .withDetail(\"pool.waiting\", pool.getThreadsAwaitingConnection());\n            }\n            \n            return builder\n                .withDetail(\"responseTime\", duration + \"ms\")\n                .withDetail(\"database\", conn.getMetaData().getDatabaseProductName())\n                .build();\n                \n        } catch (Exception e) {\n            return Health.down()\n                .withDetail(\"error\", e.getMessage())\n                .withException(e)\n                .build();\n        }\n    }\n}\n\n// 4. Monitoring and metrics\n@Component\npublic class JPAMetricsExporter {\n    \n    @Autowired\n    private MeterRegistry meterRegistry;\n    \n    @PersistenceContext\n    private EntityManager entityManager;\n    \n    @Scheduled(fixedRate = 60000)\n    public void exportMetrics() {\n        Statistics stats = entityManager\n            .getEntityManagerFactory()\n            .unwrap(SessionFactory.class)\n            .getStatistics();\n        \n        // Query metrics\n        meterRegistry.gauge(\"jpa.queries.executed\",\n            stats.getQueryExecutionCount());\n        meterRegistry.gauge(\"jpa.queries.max_time\",\n            stats.getQueryExecutionMaxTime());\n        \n        // Cache metrics\n        long hits = stats.getSecondLevelCacheHitCount();\n        long misses = stats.getSecondLevelCacheMissCount();\n        double hitRatio = (hits + misses > 0) \n            ? (double) hits / (hits + misses) \n            : 0;\n        \n        meterRegistry.gauge(\"jpa.cache.hit_ratio\", hitRatio);\n        \n        // Connection metrics\n        meterRegistry.gauge(\"jpa.connections.count\",\n            stats.getConnectCount());\n        \n        // Transaction metrics\n        meterRegistry.gauge(\"jpa.transactions.count\",\n            stats.getTransactionCount());\n    }\n}\n\n// 5. Error handling\n@RestControllerAdvice\npublic class DatabaseExceptionHandler {\n    \n    @ExceptionHandler(DataAccessException.class)\n    public ResponseEntity<?> handleDataAccessException(\n            DataAccessException ex) {\n        \n        logger.error(\"Database error\", ex);\n        \n        if (ex instanceof OptimisticLockingFailureException) {\n            return ResponseEntity.status(HttpStatus.CONFLICT)\n                .body(new ErrorResponse(\n                    \"Resource was modified by another user\"\n                ));\n        }\n        \n        if (ex instanceof TransientDataAccessException) {\n            return ResponseEntity.status(HttpStatus.SERVICE_UNAVAILABLE)\n                .body(new ErrorResponse(\n                    \"Database temporarily unavailable, please retry\"\n                ));\n        }\n        \n        // Don't expose internal errors\n        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)\n            .body(new ErrorResponse(\n                \"An error occurred processing your request\"\n            ));\n    }\n}\n\n// 6. Automated testing in CI/CD\n@SpringBootTest\n@Testcontainers\nclass ProductionReadinessTest {\n    \n    @Test\n    void testDatabasePerformance() {\n        // Load test\n        ExecutorService executor = Executors.newFixedThreadPool(10);\n        \n        for (int i = 0; i < 1000; i++) {\n            executor.submit(() -> {\n                productService.getProduct(1L);\n            });\n        }\n        \n        executor.shutdown();\n        executor.awaitTermination(30, TimeUnit.SECONDS);\n        \n        // Verify no connection leaks\n        HikariPoolMXBean pool = \n            ((HikariDataSource) dataSource).getHikariPoolMXBean();\n        \n        assertThat(pool.getActiveConnections()).isLessThan(5);\n    }\n    \n    @Test\n    void testGracefulDegradation() {\n        // Simulate database slowdown\n        // Verify circuit breaker opens\n        // Verify fallback behavior\n    }\n}\n\n// CHECKLIST:\n/*\nâœ… Connection pooling optimized\nâœ… SQL injection prevention (parameterized queries)\nâœ… Indexes on foreign keys\nâœ… Query optimization (no N+1)\nâœ… Batch operations for bulk updates\nâœ… Second-level cache enabled\nâœ… Transaction timeouts configured\nâœ… Monitoring and alerting\nâœ… Health checks\nâœ… Error handling\nâœ… Database migrations (Flyway)\nâœ… Backup strategy\nâœ… SSL/TLS connections\nâœ… Least privilege database user\nâœ… Audit logging\nâœ… Performance testing\nâœ… Documentation\n*/"
    }
  ]
}
